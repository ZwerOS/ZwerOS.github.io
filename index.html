<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.4.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="记录学习的日常">
<meta name="keywords" content="zwer">
<meta property="og:type" content="website">
<meta property="og:title" content="zwer 的博客空间">
<meta property="og:url" content="http://zwer.xyz/index.html">
<meta property="og:site_name" content="zwer 的博客空间">
<meta property="og:description" content="记录学习的日常">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="zwer 的博客空间">
<meta name="twitter:description" content="记录学习的日常">
  <link rel="canonical" href="http://zwer.xyz/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false,
    isPage: false,
    isArchive: false
  };
</script>

  <title>zwer 的博客空间</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">zwer 的博客空间</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">上善若水 自强不息</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
  </ul>

    

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <div id="posts" class="posts-expand">
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://zwer.xyz/2019/10/31/20191031 Storm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zwer">
      <meta itemprop="description" content="记录学习的日常">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zwer 的博客空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/10/31/20191031 Storm/" class="post-title-link" itemprop="url">20191031 Storm</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-10-31 00:00:00" itemprop="dateCreated datePublished" datetime="2019-10-31T00:00:00+08:00">2019-10-31</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-11-04 17:39:29" itemprop="dateModified" datetime="2019-11-04T17:39:29+08:00">2019-11-04</time>
              </span>
            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h2 id="Storm-简介"><a href="#Storm-简介" class="headerlink" title="Storm 简介"></a>Storm 简介</h2><blockquote>
<p>Storm 是个实时的、分布式以及具备高容错(协调 )的计算系统</p>
</blockquote>
<ul>
<li>Storm 进程常驻内存</li>
<li>Storm 数据不经过磁盘，在内存中处理</li>
</ul>
<p>官网对 Storm 的解释：</p>
<p>Apache Storm is a free and open source distributed realtime computation system. Apache Storm makes it easy to reliably process unbounded streams of data, doing for realtime processing what Hadoop did for batch processing. Apache Storm is simple, can be used with any programming language, and is a lot of fun to use!</p>
<p>Apache Storm has many use cases: realtime analytics, online machine learning, continuous computation, distributed RPC, ETL, and more. Apache Storm is fast: a benchmark clocked it at over <strong>a million tuples processed per second per node</strong>. It is scalable, fault-tolerant, guarantees your data will be processed, and is easy to set up and operate.</p>
<p>Apache Storm integrates with the queueing and database technologies you already use. An Apache Storm topology consumes streams of data and processes those streams in arbitrarily complex ways, repartitioning the streams between each stage of the computation however needed. Read more in the tutorial.</p>
<p>官网地址: <a href="http://storm.apache.org/" target="_blank" rel="noopener">http://storm.apache.org/</a></p>
<h3 id="Storm-与-MapReduce-的区别"><a href="#Storm-与-MapReduce-的区别" class="headerlink" title="Storm 与 MapReduce 的区别"></a>Storm 与 MapReduce 的区别</h3><table>
<thead>
<tr>
<th align="left">计算框架</th>
<th align="left">Storm</th>
<th>MapReduce</th>
</tr>
</thead>
<tbody><tr>
<td align="left">概念</td>
<td align="left">分布式实时流式计算</td>
<td>批处理离线计算</td>
</tr>
<tr>
<td align="left">处理方式</td>
<td align="left">realtime processing</td>
<td>batch processing</td>
</tr>
<tr>
<td align="left">处理数据量的级别</td>
<td align="left">MB 、KB</td>
<td>TB级 PB级</td>
</tr>
<tr>
<td align="left">单位时间处理数据量</td>
<td align="left">小</td>
<td>大</td>
</tr>
<tr>
<td align="left">速度</td>
<td align="left">快</td>
<td>慢</td>
</tr>
<tr>
<td align="left">模型</td>
<td align="left">DAG 、Spout、Bolt 模型</td>
<td>Map+Reduce  模式</td>
</tr>
<tr>
<td align="left">生命周期</td>
<td align="left">常驻运行</td>
<td>反复启停</td>
</tr>
</tbody></table>
<p>分布式承载数据的方式： 1、切片 2、径向全量     -&gt;  ？？？</p>
<h3 id="Storm-计算模型"><a href="#Storm-计算模型" class="headerlink" title="Storm 计算模型"></a>Storm 计算模型</h3><p><img src="http://storm.apache.org/images/storm-flow.png" alt></p>
<ul>
<li><p>整个图是 DAG（Directed Acyclic Graph）有向无环图</p>
</li>
<li><p>水龙头： 表示数据源 spout</p>
</li>
<li><p>小水滴： 表示一次数据量的大小 tuple</p>
</li>
<li><p>大水滴： 表示一个计算单元 bolt</p>
</li>
<li><p>闪电： 表示计算速度快，就像闪电一样</p>
</li>
</ul>
<h3 id="Storm-应用场景"><a href="#Storm-应用场景" class="headerlink" title="Storm 应用场景"></a>Storm 应用场景</h3><ul>
<li>阿里巴巴的 JStorm 项目- 双 11 大屏幕</li>
<li>腾讯的 QQ 同时在线人数图</li>
</ul>
<h2 id="Storm-特点"><a href="#Storm-特点" class="headerlink" title="Storm 特点"></a>Storm 特点</h2><ul>
<li><p>架构<br>Nimbus<br>Supervisor<br>Worker</p>
</li>
<li><p>编程模型<br>DAG （Topology）<br>Spout<br>Bolt</p>
</li>
<li><p>数据传输<br>ZMQ（twitter早期产品）-ZeroMQ 开源的消息传递框架，并不是一个MessageQueue</p>
<p>Netty-Netty 是基于 NIO 的网络框架，更加高效。</p>
</li>
</ul>
<p>之所以Storm 0.9版本之后使用Netty，是因为ZMQ的license和Storm的license不兼容。</p>
<ul>
<li><p>高可靠性<br>异常处理<br>消息可靠性保障机制(ACK)</p>
</li>
<li><p>可维护性<br>StormUI 图形化监控接口</p>
<p><img src="http://img.zwer.xyz/blog/20191101105526.png" alt></p>
</li>
</ul>
<h2 id="Storm-计算模型详述"><a href="#Storm-计算模型详述" class="headerlink" title="Storm 计算模型详述"></a>Storm 计算模型详述</h2><p>spout 将一个个 tuple 通过流的方式， 发送给一个或多个 blot 处理</p>
<p><img src="http://img.zwer.xyz/blog/20191101113512.png" alt></p>
<ul>
<li>Topology – DAG 有向无环图的实现<br>对于Storm实时计算逻辑的封装<br>即，由一系列通过数据流相互关联的 Spout、Bolt 所组成的拓扑结构<br>生命周期：此拓扑只要启动就会一直在集群中运行，直到手动将其kill，否则不会终止<pre><code>（区别于MapReduce当中的 Job，MR当中的Job在计算执行完成就会终止）</code></pre></li>
<li>Tuple – 元组<br>Stream 中最小数据组成单元</li>
<li>Stream – 数据流<br>从Spout中源源不断传递数据给Bolt、以及上一个Bolt传递数据给下一个Bolt，所形成的这些数据通道即叫做Stream<br>Stream声明时需给其指定一个Id（默认为Default）<br>实际开发场景中，多使用单一数据流，此时不需要单独指定StreamId</li>
</ul>
<p><img src="http://img.zwer.xyz/blog/20191101113545.png" alt></p>
<ul>
<li>Spout – 数据源<br>拓扑中数据流的来源。一般会从指定外部的数据源读取元组（Tuple）发送到拓扑（Topology）中<br>一个 Spout 可以发送多个数据流（Stream）<br>可先通过 OutputFieldsDeclarer 中的 declare 方法声明定义的不同数据流，发送数据时通过SpoutOutputCollector 中的 emit 方法指定数据流Id（streamId）参数将数据发送出去<br>Spout中最核心的方法是 nextTuple，该方法会被Storm线程不断调用、主动从数据源拉取数据，再通过emit方法将数据生成元组（Tuple）发送给之后的Bolt计算</li>
<li>Bolt – 数据流处理组件<ul>
<li>拓扑中数据处理均有 <code>Bolt</code> 完成。对于简单的任务或者数据流转换，单个 <code>Bolt</code> 可以简单实现；更加复杂场景往往需要多个 <code>Bolt</code> 分多个步骤完成</li>
<li>一个 <code>Bolt</code> 可以发送多个数据流（Stream）<br>可先通过 <code>OutputFieldsDeclarer</code> 中的 <code>declare</code> 方法声明定义的不同数据流，发送数据时通过<code>SpoutOutputCollector</code> 中的 <code>emit</code> 方法指定数据流  Id（streamId）参数将数据发送出去</li>
<li>Bolt 中最核心的方法是 <code>execute</code> 方法，该方法负责接收到一个元组（Tuple）数据、真正实现核心的业务逻辑</li>
</ul>
</li>
<li>Stream Grouping – 数据流分组（即数据分发策略）</li>
</ul>
<h2 id="Storm-案例"><a href="#Storm-案例" class="headerlink" title="Storm 案例"></a>Storm 案例</h2><h3 id="Storm-数据累加"><a href="#Storm-数据累加" class="headerlink" title="Storm 数据累加"></a>Storm 数据累加</h3><ul>
<li><p>WsSpout.java: 将消息发送给 Blot</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WsSpout</span> <span class="keyword">extends</span> <span class="title">BaseRichSpout</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">	Map conf;</span><br><span class="line">	TopologyContext context;</span><br><span class="line">	SpoutOutputCollector collector;</span><br><span class="line">	<span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 初始化</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Map conf, TopologyContext context</span></span></span><br><span class="line"><span class="function"><span class="params">                     , SpoutOutputCollector collector)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.conf = conf;</span><br><span class="line">		<span class="keyword">this</span>.context = context;</span><br><span class="line">		<span class="keyword">this</span>.collector = collector;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 获取和发送消息</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nextTuple</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		i++;</span><br><span class="line">		List val = <span class="keyword">new</span> Values(i);</span><br><span class="line">		<span class="keyword">this</span>.collector.emit(val);</span><br><span class="line">		System.err.println(<span class="string">"spout----------:"</span> + i);</span><br><span class="line">		Utils.sleep(<span class="number">1000</span>); <span class="comment">// 休眠一秒</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 声明字段名称</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">		declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"nums"</span>));</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>WsBlot.java: 接收消息并处理</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WsBlot</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	Map stormConf;</span><br><span class="line">	TopologyContext context;</span><br><span class="line">	OutputCollector collector;</span><br><span class="line">	<span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map stormConf, TopologyContext context, OutputCollector collector)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.stormConf = stormConf;</span><br><span class="line">		<span class="keyword">this</span>.context = context;</span><br><span class="line">		<span class="keyword">this</span>.collector = collector;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple input)</span> </span>&#123;</span><br><span class="line">		Integer num = input.getIntegerByField(<span class="string">"nums"</span>);</span><br><span class="line">		sum += num;</span><br><span class="line">		System.err.println(<span class="string">"nums--------:"</span>+sum);</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">		&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">		declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"nums"</span>));</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>MainTest.java: 测试类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MainTest</span> </span>&#123;</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 测试</span></span><br><span class="line"><span class="comment">	 * </span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> args 命令行参数</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		<span class="comment">// 创建拓扑构建者对象</span></span><br><span class="line">		TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">		<span class="comment">// 设置 spout</span></span><br><span class="line">		builder.setSpout(<span class="string">"wsspout"</span>, <span class="keyword">new</span> WsSpout());</span><br><span class="line">		<span class="comment">// 设置 blot</span></span><br><span class="line">		builder.setBolt(<span class="string">"wsbolt"</span>, <span class="keyword">new</span> WsBlot()).shuffleGrouping(<span class="string">"wsspout"</span>);</span><br><span class="line">		<span class="comment">// 创建本地集群</span></span><br><span class="line">		LocalCluster locCluster = <span class="keyword">new</span> LocalCluster();</span><br><span class="line">		<span class="comment">// 提交拓扑</span></span><br><span class="line">		locCluster.submitTopology(<span class="string">"ws"</span>, <span class="keyword">new</span> Config(), builder.createTopology());</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="Storm-Word-Count"><a href="#Storm-Word-Count" class="headerlink" title="Storm Word Count"></a>Storm Word Count</h3><ul>
<li><p>WcSpout.java: 发送消息</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WcSpout</span> <span class="keyword">extends</span> <span class="title">BaseRichSpout</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	SpoutOutputCollector collector;</span><br><span class="line"></span><br><span class="line">	String[] artile = &#123; <span class="string">"WelCome to Bejing"</span>, <span class="string">"WelCome to AnHui"</span>, <span class="string">"WelCome to Lujiang"</span> &#125;;</span><br><span class="line"></span><br><span class="line">	Random random = <span class="keyword">new</span> Random();</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Map conf, TopologyContext context, SpoutOutputCollector collector)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.collector = collector;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nextTuple</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		List val = <span class="keyword">new</span> Values(artile[<span class="keyword">this</span>.random.nextInt(artile.length)]);</span><br><span class="line">		<span class="keyword">this</span>.collector.emit(val);</span><br><span class="line">		System.err.println(<span class="string">"line--------:"</span>+val.get(<span class="number">0</span>));</span><br><span class="line">		Utils.sleep(<span class="number">2000</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">		declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"line"</span>));</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>WcBolt1.java: 对一行数据进行切分，分别发送给下一个 bolt</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WcBolt1</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	OutputCollector collector;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map stormConf, TopologyContext context, OutputCollector collector)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.collector = collector;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple input)</span> </span>&#123;</span><br><span class="line">		String line = input.getString(<span class="number">0</span>);</span><br><span class="line">		String[] words = line.split(<span class="string">" "</span>);</span><br><span class="line">		<span class="keyword">for</span> (String wd : words) &#123;</span><br><span class="line">			List val = <span class="keyword">new</span> Values(wd);</span><br><span class="line">			<span class="keyword">this</span>.collector.emit(val);</span><br><span class="line">			<span class="comment">//System.err.println("wcbolt1.......:"+wd);</span></span><br><span class="line">		&#125;</span><br><span class="line">		Utils.sleep(<span class="number">200</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">		declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"wd"</span>));</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>WcBolt2.java:统计单词的次数，并放入 Map 集合中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WcBolt2</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	OutputCollector collector;</span><br><span class="line"></span><br><span class="line">	Map&lt;String, Integer&gt; wordCount =<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map stormConf, TopologyContext context, OutputCollector collector)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.collector = collector;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple input)</span> </span>&#123;</span><br><span class="line">		<span class="comment">// Welcome</span></span><br><span class="line">		String wd = input.getStringByField(<span class="string">"wd"</span>);</span><br><span class="line">		<span class="keyword">if</span> (<span class="keyword">this</span>.wordCount.containsKey(wd)) &#123;</span><br><span class="line">			<span class="keyword">int</span> count = <span class="keyword">this</span>.wordCount.get(wd);</span><br><span class="line">			<span class="keyword">this</span>.wordCount.put(wd, ++count);</span><br><span class="line"></span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="keyword">this</span>.wordCount.put(wd, <span class="number">1</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		System.err.println(<span class="keyword">this</span>.wordCount);</span><br><span class="line">		Utils.sleep(<span class="number">500</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">		declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"w"</span>));</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>WordCountMainTest.java: 测试类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountMainTest</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">		builder.setSpout(<span class="string">"wcspout"</span>, <span class="keyword">new</span> WcSpout());</span><br><span class="line">		builder.setBolt(<span class="string">"wcbolt1"</span>, <span class="keyword">new</span> WcBolt1()).shuffleGrouping(<span class="string">"wcspout"</span>);</span><br><span class="line">		<span class="comment">// fieldGrouping: 数据分发策略</span></span><br><span class="line">		builder.setBolt(<span class="string">"wcbolt2"</span>, <span class="keyword">new</span> WcBolt2(),<span class="number">3</span>).fieldsGrouping(<span class="string">"wcbolt1"</span>, <span class="keyword">new</span> Fields(<span class="string">"wd"</span>));</span><br><span class="line">		<span class="comment">// builder.setBolt("wcbolt2", new WcBolt2()).shuffleGrouping("wcbolt1");</span></span><br><span class="line">		LocalCluster cluster = <span class="keyword">new</span> LocalCluster();</span><br><span class="line">		cluster.submitTopology(<span class="string">"wordcount"</span>, <span class="keyword">new</span> Config(), builder.createTopology());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Storm-数据分发策略"><a href="#Storm-数据分发策略" class="headerlink" title="Storm 数据分发策略*"></a>Storm 数据分发策略*</h2><ol>
<li><p><strong>Shuffle Grouping*</strong><br>随机分组，随机派发stream里面的tuple，保证每个bolt task接收到的tuple数目大致相同。<br>轮询，平均分配 </p>
</li>
<li><p><strong>Fields Grouping*</strong><br>按字段分组，比如，按”user-id”这个字段来分组，那么具有同样”user-id”的 tuple 会被分到相同的Bolt里的一个task， 而不同的”user-id”则可能会被分配到不同的task。 </p>
</li>
<li><p><strong>All Grouping*</strong><br>广播发送，对于每一个tuple，所有的bolts都会收到 </p>
</li>
<li><p><strong>Global Grouping</strong><br>全局分组，把tuple分配给task id最低的task 。</p>
</li>
<li><p><strong>None Grouping</strong><br>不分组，这个分组的意思是说stream不关心到底怎样分组。目前这种分组和Shuffle grouping是一样的效果。 有一点不同的是storm会把使用none grouping的这个bolt放到这个bolt的订阅者同一个线程里面去执行（未来Storm如果可能的话会这样设计）。 </p>
</li>
<li><p><strong>Direct Grouping</strong><br>指向型分组， 这是一种比较特别的分组方法，用这种分组意味着消息（tuple）的发送者指定由消息接收者的哪个task处理这个消息。只有被声明为 Direct Stream 的消息流可以声明这种分组方法。而且这种消息tuple必须使用 emitDirect 方法来发射。消息处理者可以通过 TopologyContext 来获取处理它的消息的task的id (OutputCollector.emit方法也会返回task的id)  </p>
</li>
<li><p><strong>Local or shuffle grouping</strong><br>本地或随机分组。如果目标bolt有一个或者多个task与源bolt的task在同一个工作进程中，tuple将会被随机发送给这些同进程中的tasks。否则，和普通的Shuffle Grouping行为一致</p>
</li>
<li><p><strong>customGrouping</strong><br>自定义，相当于mapreduce那里自己去实现一个partition一样。</p>
</li>
</ol>
<h2 id="Storm-架构设计"><a href="#Storm-架构设计" class="headerlink" title="Storm 架构设计*"></a>Storm 架构设计*</h2><p><img src="http://img.zwer.xyz/blog/20191101200812.png" alt></p>
<h3 id="角色作用"><a href="#角色作用" class="headerlink" title="角色作用"></a>角色作用</h3><ul>
<li><code>Nimbus</code><ul>
<li>资源调度</li>
<li>任务分配</li>
<li>接收 jar 包</li>
</ul>
</li>
<li><code>Supervisor</code><ul>
<li>接收<code>nimbus</code>分配的任务</li>
<li>启动、停止自己管理的 worker 进程（当前 supervisor 上 worker 数量由配置文件设定）</li>
</ul>
</li>
<li><code>Worker</code><ul>
<li>运行具体处理运算组件的进程（每个Worker对应执行一个Topology的子集）</li>
<li>worker 任务类型，即 spout 任务、bolt 任务两种</li>
<li>启动 executor<pre><code>（executor即worker JVM进程中的一个java线程，一般默认每个executor负责执行一个task任务）</code></pre></li>
</ul>
</li>
<li><code>Zookeeper</code><ul>
<li>负责角色的健康检查</li>
</ul>
</li>
</ul>
<h3 id="Storm-架构与-Hadoop-架构比较"><a href="#Storm-架构与-Hadoop-架构比较" class="headerlink" title="Storm 架构与 Hadoop 架构比较"></a>Storm 架构与 Hadoop 架构比较</h3><table>
<thead>
<tr>
<th align="center"></th>
<th align="center">Hadoop</th>
<th align="center">Storm</th>
</tr>
</thead>
<tbody><tr>
<td align="center">主节点</td>
<td align="center">ResourceManager</td>
<td align="center">Nimbus</td>
</tr>
<tr>
<td align="center">从节点</td>
<td align="center">NodeManager</td>
<td align="center">Supervisor</td>
</tr>
<tr>
<td align="center">应用程序</td>
<td align="center">Job</td>
<td align="center">Topology</td>
</tr>
<tr>
<td align="center">工作进程</td>
<td align="center">Child</td>
<td align="center">Worker</td>
</tr>
<tr>
<td align="center">计算模型</td>
<td align="center">Map/Reduce(split,map,shuffle,reduce)</td>
<td align="center">Spout/Bolt</td>
</tr>
</tbody></table>
<h3 id="Storm-任务提交流程"><a href="#Storm-任务提交流程" class="headerlink" title="Storm 任务提交流程"></a>Storm 任务提交流程</h3><p><img src="http://img.zwer.xyz/blog/20191101204814.png" alt></p>
<h2 id="Storm-并发机制"><a href="#Storm-并发机制" class="headerlink" title="Storm 并发机制*"></a>Storm 并发机制*</h2><h3 id="Worker-Executor-Task-之间的联系"><a href="#Worker-Executor-Task-之间的联系" class="headerlink" title="Worker Executor Task 之间的联系"></a>Worker Executor Task 之间的联系</h3><ul>
<li><strong>Work Process</strong>  进程<br>一个 Topology 拓扑会包含一个或多个 Worker（每个Worker进程只能从属于一个特定的Topology）</li>
</ul>
<p>这些Worker进程会并行跑在集群中不同的服务器上，即一个Topology拓扑其实是由并行运行在Storm集群中</p>
<p>  多台服务器上的进程所组成</p>
<ul>
<li><p><strong>Executor （Threads）</strong> 线程</p>
<p>Executor 是由 Worker 进程中生成的一个线程</p>
<p>每个 Worker 进程中会运行拓扑当中的一个或多个 Executor 线程</p>
<p>一个 Executor 线程中可以执行一个或多个 Task 任务（默认每个Executor只执行一个Task任务），但是这些</p>
<p>Task 任务都是对应着同一个组件（Spout、Bolt）。</p>
</li>
<li><p><strong>Task</strong> 任务</p>
<p>实际执行数据处理的最小单元，每个 task 即为一个 Spout 或者一个 Bolt</p>
<p><font color="red">Task 数量在整个 Topology 生命周期中保持不变，Executor 数量可以变化或手动调整</font></p>
<p>默认情况下，Task 数量和 Executor 是相同的，即每个 Executor 线程中默认运行一个 Task 任务</p>
</li>
</ul>
<p><img src="http://img.zwer.xyz/blog/20191102105206.png" alt></p>
<h3 id="调整-Worker-Executor-Task-的数量"><a href="#调整-Worker-Executor-Task-的数量" class="headerlink" title="调整 Worker Executor Task 的数量"></a>调整 Worker Executor Task 的数量</h3><ul>
<li><p><strong>设置 Worker 进程数</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Config.setNumWorkers(<span class="keyword">int</span> workers)</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>设置 Executor 线程数</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">TopologyBuilder.setSpout(String id, IRichSpout spout, Number parallelism_hint)</span><br><span class="line">TopologyBuilder.setBolt(String id, IRichBolt bolt, Number parallelism_hint)</span><br><span class="line"></span><br><span class="line"><span class="comment">//：其中， parallelism_hint即为executor线程数</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>设置 Task 数量</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ComponentConfigurationDeclarer.setNumTasks(Number val)</span><br></pre></td></tr></table></figure>

<p>例：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Config conf = <span class="keyword">new</span> Config() ;</span><br><span class="line">conf.setNumWorkers(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">TopologyBuilder topologyBuilder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">topologyBuilder.setSpout(<span class="string">"spout"</span>, <span class="keyword">new</span> MySpout(), <span class="number">1</span>);</span><br><span class="line">topologyBuilder.setBolt(<span class="string">"green-bolt"</span>, <span class="keyword">new</span> GreenBolt(), <span class="number">2</span>)</span><br><span class="line">    .setNumTasks(<span class="number">4</span>)</span><br><span class="line">    .shuffleGrouping(<span class="string">"blue-spout);</span></span><br></pre></td></tr></table></figure>

<p><img src="http://img.zwer.xyz/blog/20191102110246.png" alt></p>
</li>
</ul>
<h3 id="rebalance-再平衡"><a href="#rebalance-再平衡" class="headerlink" title="rebalance 再平衡"></a>rebalance 再平衡</h3><blockquote>
<p>动态调整 Topology 拓扑的 Worker 进程数量、以及 Executor 线程数量</p>
</blockquote>
<p>支持两种调整方式：<br>1、通过 Storm UI<br>2、通过 Storm CLI</p>
<p>通过 Storm CLI 动态调整：</p>
<p>例：storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10</p>
<p>将mytopology拓扑worker进程数量调整为5个</p>
<p>“ blue-spout ” 所使用的线程数量调整为3个</p>
<p>“ yellow-bolt ”所使用的线程数量调整为10个</p>
<h2 id="Storm-通信机制"><a href="#Storm-通信机制" class="headerlink" title="Storm 通信机制"></a>Storm 通信机制</h2><h3 id="Worker-进程间的数据通信"><a href="#Worker-进程间的数据通信" class="headerlink" title="Worker 进程间的数据通信"></a>Worker 进程间的数据通信</h3><ul>
<li>ZMQ<br>ZeroMQ 开源的消息传递框架，并不是一个MessageQueue</li>
<li>Netty<br>Netty是基于 NIO 的网络框架，更加高效。（之所以Storm 0.9版本之后使用 Netty，是因为ZMQ的license和Storm的license不兼容。）</li>
</ul>
<h3 id="Worker内部的数据通信"><a href="#Worker内部的数据通信" class="headerlink" title="Worker内部的数据通信*"></a>Worker内部的数据通信*</h3><p>Disruptor 实现了“队列”的功能。可以理解为一种事件监听或者消息处理机制，即在队列当中一边由生产者放入消息数据，另一边消费者并行取出消息数据处理。</p>
<p><img src="http://img.zwer.xyz/blog/20191102111847.png" alt></p>
<h2 id="Storm-安装"><a href="#Storm-安装" class="headerlink" title="Storm 安装"></a>Storm 安装</h2><h3 id="伪分布式"><a href="#伪分布式" class="headerlink" title="伪分布式"></a>伪分布式</h3><ul>
<li><p><strong>系统环境</strong></p>
<ul>
<li>Java  环境</li>
</ul>
</li>
<li><p><strong>搭建</strong></p>
<p>伪分布式搭建在节点 node01(192.168.170.101)上</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>上传 storm 软件压缩包到 Linux 服务器上</span><br><span class="line">tar xf apache-storm-0.10.0.tar.gz -C /opt/sxt</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 配置 storm 环境变量</span><br><span class="line">export STORM_HOME=/opt/sxt/apache-storm-0.10.0</span><br><span class="line">export PATH=$PATH:$STORM_HOME/bin</span><br><span class="line"><span class="meta">#</span> cd $STROM_HOME 根目录</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 首先启动  dev-zookeeper</span><br><span class="line">storm dev-zookeeper &gt;&gt; ./logs/dev-zookeeper.out 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 再启动 nimbus </span><br><span class="line">storm nimbus &gt;&gt; ./logs/nimbus.out 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 再启动  spervisor</span><br><span class="line">storm supervisor &gt;&gt; ./logs/supervisor.out 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 最后启动 ui，注意：使用  jps 命令查看 ui 进程的名称为 core</span><br><span class="line">storm ui  &gt;&gt; ./logs/ui.out 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 使用 jps 命令</span><br><span class="line">[root@node01 apache-storm-0.10.0]# jps</span><br><span class="line">4661 nimbus</span><br><span class="line">3932 DFSZKFailoverController</span><br><span class="line">4998 Jps</span><br><span class="line">4895 core</span><br><span class="line">4563 dev_zookeeper</span><br><span class="line">4805 supervisor</span><br><span class="line">3790 JournalNode</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 打开 node01:8080 端口</span><br><span class="line">http://node01:8080</span><br></pre></td></tr></table></figure>

<p>小技巧： 通过 <code>storm  或者 storm help</code> 查看命令的如何使用。 <code>storm help 参数</code>查看具体命令的使用</p>
</li>
<li><p><strong>部署伪分布式任务</strong></p>
<p>在部署之前，确保 storm 中的必要的角色（zk、nimbus、supervisor）都已经启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 将 IDE 中的项目打包成 jar 文件，并上传到 Linux 服务器上</span><br><span class="line"><span class="meta">#</span> 运行 jar 包</span><br><span class="line">storm jar jar的位置 类的全限定路径名 [参数]</span><br><span class="line">若未给定参数，则在本地运行。若给定参数，则将提交给集群运行</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="完全分布式"><a href="#完全分布式" class="headerlink" title="完全分布式"></a>完全分布式</h3><ul>
<li><p><strong>节点分布</strong></p>
<table>
<thead>
<tr>
<th align="center">host/role</th>
<th align="center">192.168.170.102/node02</th>
<th align="center">192.168.170.103/node03</th>
<th align="center">192.168.170.104/node04</th>
</tr>
</thead>
<tbody><tr>
<td align="center">nimbus</td>
<td align="center">*</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">supervisor</td>
<td align="center"></td>
<td align="center">*</td>
<td align="center">*</td>
</tr>
<tr>
<td align="center">worker</td>
<td align="center">*</td>
<td align="center">*</td>
<td align="center">*</td>
</tr>
</tbody></table>
</li>
<li><p><strong>系统环境</strong></p>
<ul>
<li>安装 Java 环境 ，并保证 JDK 版本在 1.6 以上</li>
<li>安装 Python 环境，并保存 Python 在 2.6.6 以上即可</li>
</ul>
</li>
<li><p><strong>Storm 完全分布式搭建</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 上传 storm软件压缩包 到 node02 节点 上</span><br><span class="line"><span class="meta">#</span> 解压</span><br><span class="line">tar zxvf  apache-storm-0.10.0.tar.gz -C /opt/sxt</span><br><span class="line"><span class="meta">#</span> 配置 storm 环境变量</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 进入 $STROM_HOME 根目录下</span><br><span class="line"><span class="meta">#</span> cd conf </span><br><span class="line"><span class="meta">#</span> 编辑 storm.yaml 文件，内容如下：</span><br><span class="line">storm.zookeeper.servers:</span><br><span class="line">     - "node02"</span><br><span class="line">     - "node03"</span><br><span class="line">     - "node04"</span><br><span class="line"> </span><br><span class="line">nimbus.host: "node02"</span><br><span class="line"></span><br><span class="line">storm.local.dir: "/tmp/storm"</span><br><span class="line"></span><br><span class="line">supervisor.slots.ports:</span><br><span class="line">    - 6700</span><br><span class="line">    - 6701</span><br><span class="line">    - 6702</span><br><span class="line">    - 6703</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 分发到 node03、node04 节点上</span><br><span class="line">scp -r apache-storm-0.10.0/ root@node03:`pwd`</span><br><span class="line">scp -r apache-storm-0.10.0/ root@node04:`pwd</span><br><span class="line"><span class="meta">#</span>-------------------------------------------------------</span><br><span class="line"><span class="meta">#</span> 以下操作都是在  $STROM_HOME 根目录下执行的</span><br><span class="line"><span class="meta">#</span> 在 node02、node03、node04 节点上创建 logs 目录</span><br><span class="line">mkdir logs</span><br><span class="line"><span class="meta">#</span> 在 node02 启动</span><br><span class="line">storm nimbus &gt;&gt; ./logs/nimbus.out 2&gt;&amp;1 &amp;</span><br><span class="line">storm ui &gt;&gt; ./logs/ui.out 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>  node03、node04 启动</span><br><span class="line">storm supervisor &gt;&gt; supervisor.out 2&gt;&amp;1 &amp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 访问 http://node02:8080 </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 上传任务 jar </span><br><span class="line">storm jar jar的路径 主类的全限定路径名  任务名</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Storm-容错保护机制"><a href="#Storm-容错保护机制" class="headerlink" title="Storm 容错保护机制"></a>Storm 容错保护机制</h2><p>  <img src="http://img.zwer.xyz/blog/20191101200812.png" alt></p>
<h3 id="集群节点宕机"><a href="#集群节点宕机" class="headerlink" title="集群节点宕机"></a>集群节点宕机</h3><ul>
<li><p>Nimbus服务器<br>单点故障？</p>
<p>当 Nimbus 出现了宕机，并不会直接影响 Storm 的运行，因为 Nimbus 并不是直接与 Supervisor 进行交互，而是与 Zookeeper 协调者之间进行交互，即 Zookeeper 将 Nimbus 与 Supervisor 的直接关系，转为间接关系。但有一个情况下，Supervisor 中某个节点宕机了，Zookeeper 会该 Supervisor 消息传递给 Nimbus，这时 Nimbus 必须宕机后恢复重启，继续工作。</p>
</li>
<li><p>非 Nimbus 服务器<br>故障时，该节点上所有 Task 任务都会超时，Nimbus 会将这些 Task 任务重新分配到其他服务器上运行</p>
</li>
</ul>
<h3 id="进程挂掉"><a href="#进程挂掉" class="headerlink" title="进程挂掉"></a>进程挂掉</h3><ul>
<li><strong>Worker</strong><br>挂掉时，Supervisor会重新启动这个进程。如果启动过程中仍然一直失败，并且无法向Nimbus发送心跳，Nimbus会将该Worker重新分配到其他服务器上</li>
<li><strong>Supervisor</strong><br>无状态（所有的状态信息都存放在Zookeeper中来管理）<br>快速失败（每当遇到任何异常情况，都会自动毁灭）</li>
<li><strong>Nimbus</strong><br>无状态（所有的状态信息都存放在Zookeeper中来管理）<br>快速失败（每当遇到任何异常情况，都会自动毁灭）</li>
</ul>
<h3 id="消息的完整性"><a href="#消息的完整性" class="headerlink" title="消息的完整性"></a>消息的完整性</h3><blockquote>
<p>从Spout中发出的Tuple，以及基于他所产生Tuple（例如上个例子当中Spout发出的句子，以及句子当中单词的tuple等）由这些消息就构成了一棵tuple树。当这棵tuple树发送完成，并且树当中每一条消息都被正确处理，就表明spout发送消息被“完整处理”，即消息的完整性</p>
</blockquote>
<p><img src="http://img.zwer.xyz/blog/20191102151946.png" alt></p>
<ul>
<li><p><strong>ack 机制 –消息完整性的实现机制</strong></p>
<ol>
<li>Storm的拓扑当中特殊的一些任务 </li>
<li>负责跟踪每个Spout发出的Tuple的DAG（有向无环图）</li>
</ol>
<p>注意：ack 无法保证数据不被重复计算，但是可以保证数据至少被正确处理一次。</p>
<p>在实际的使用中，由于处理的整体数据量大，出现个别消息不完整，是可以容忍的。</p>
</li>
<li><p><strong>事务</strong></p>
<p> 无,后续</p>
</li>
</ul>
<h2 id="DRPC-同步实时分析"><a href="#DRPC-同步实时分析" class="headerlink" title="DRPC -同步实时分析"></a>DRPC -同步实时分析</h2><blockquote>
<p>Distributed Remote Procedure Call</p>
<p>DRPC 是通过一个 DRPC 服务端(DRPC server)来实现分布式 RPC 功能的。<br>DRPC Server 负责接收 RPC 请求，并将该请求发送到 Storm中运行的 Topology，等待接收 Topology 发送的处理结果，并将该结果返回给发送请求的客户端。<br>（其实，从客户端的角度来说，DPRC 与普通的 RPC 调用并没有什么区别。）</p>
</blockquote>
<h3 id="DRPC设计目的："><a href="#DRPC设计目的：" class="headerlink" title="DRPC设计目的："></a>DRPC设计目的：</h3><p>为了充分利用 Storm 的计算能力实现==高密度的并行实时计算==，Storm 接收若干个数据流输入，数据在 Topology 当中运行完成，然后通过 DRPC 将结果进行输出。</p>
<h3 id="DRPC架构图"><a href="#DRPC架构图" class="headerlink" title="DRPC架构图"></a>DRPC架构图</h3><p>客户端通过向 DRPC 服务器发送待执行函数的名称以及该函数的参数来获取处理结果。实现该函数的拓扑使用一个 DRPCSpout 从 DRPC 服务器中接收一个函数调用流。DRPC 服务器会为每个函数调用都标记了一个唯一的 id。随后拓扑会执行函数来计算结果，并在拓扑的最后使用一个名为 ReturnResults 的 bolt 连接到 DRPC 服务器，根据函数调用的 id 来将函数调用的结果返回。</p>
<p><img src="http://img.zwer.xyz/blog/20191102193615.png" alt></p>
<h3 id="DRPC-实现"><a href="#DRPC-实现" class="headerlink" title="DRPC 实现"></a>DRPC 实现</h3><ol>
<li>通过 LinearDRPCTopologyBuilder （该方法也过期，不建议使用）<br>该方法会自动为我们设定 Spout、将结果返回给 DRPC Server 等，我们只需要将 Topology 实现</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * This topology is a basic example of doing distributed RPC on top of Storm. It</span></span><br><span class="line"><span class="comment"> * implements a function that appends a "!" to any string you send the DRPC</span></span><br><span class="line"><span class="comment"> * function.</span></span><br><span class="line"><span class="comment"> * &lt;p/&gt;</span></span><br><span class="line"><span class="comment"> * See https://github.com/nathanmarz/storm/wiki/Distributed-RPC for more</span></span><br><span class="line"><span class="comment"> * information on doing distributed RPC on top of Storm.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BasicDRPCTopology</span> </span>&#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ExclaimBolt</span> <span class="keyword">extends</span> <span class="title">BaseBasicBolt</span> </span>&#123;</span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple, BasicOutputCollector collector)</span> </span>&#123;</span><br><span class="line">			String input = tuple.getString(<span class="number">1</span>);</span><br><span class="line">			collector.emit(<span class="keyword">new</span> Values(tuple.getValue(<span class="number">0</span>), input + <span class="string">"!"</span>));</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">			declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"id"</span>, <span class="string">"result"</span>));</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		LinearDRPCTopologyBuilder builder = <span class="keyword">new</span> LinearDRPCTopologyBuilder(<span class="string">"exclamation"</span>);</span><br><span class="line">		builder.addBolt(<span class="keyword">new</span> ExclaimBolt(), <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">		Config conf = <span class="keyword">new</span> Config();</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> (args == <span class="keyword">null</span> || args.length == <span class="number">0</span>) &#123;</span><br><span class="line">			LocalDRPC drpc = <span class="keyword">new</span> LocalDRPC();</span><br><span class="line">			LocalCluster cluster = <span class="keyword">new</span> LocalCluster();</span><br><span class="line"></span><br><span class="line">			cluster.submitTopology(<span class="string">"drpc-demo"</span>, conf, builder.createLocalTopology(drpc));</span><br><span class="line"></span><br><span class="line">			<span class="keyword">for</span> (String word : <span class="keyword">new</span> String[] &#123; <span class="string">"hello"</span>, <span class="string">"goodbye"</span> &#125;) &#123;</span><br><span class="line">				System.err.println(<span class="string">"Result for \""</span> + word + <span class="string">"\": "</span> + drpc.execute(<span class="string">"exclamation"</span>, word));</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">			cluster.shutdown();</span><br><span class="line">			drpc.shutdown();</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			conf.setNumWorkers(<span class="number">3</span>);</span><br><span class="line">			StormSubmitter.submitTopologyWithProgressBar(args[<span class="number">0</span>], conf, builder.createRemoteTopology());</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>直接通过普通的拓扑构造方法 TopologyBuilder 来创建 DRPC 拓扑，需要手动设定好开始的 DRPCSpout 以及结束的 ReturnResults</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ManualDRPC</span> </span>&#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ExclamationBolt</span> <span class="keyword">extends</span> <span class="title">BaseBasicBolt</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">			declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"result"</span>, <span class="string">"return-info"</span>));</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple, BasicOutputCollector collector)</span> </span>&#123;</span><br><span class="line">			String arg = tuple.getString(<span class="number">0</span>);</span><br><span class="line">			Object retInfo = tuple.getValue(<span class="number">1</span>);</span><br><span class="line">			collector.emit(<span class="keyword">new</span> Values(arg + <span class="string">"!!!"</span>, retInfo));</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">		LocalDRPC drpc = <span class="keyword">new</span> LocalDRPC();</span><br><span class="line"></span><br><span class="line">		DRPCSpout spout = <span class="keyword">new</span> DRPCSpout(<span class="string">"exclamation"</span>, drpc);</span><br><span class="line">		builder.setSpout(<span class="string">"drpc"</span>, spout);</span><br><span class="line">		builder.setBolt(<span class="string">"exclaim"</span>, <span class="keyword">new</span> ExclamationBolt(), <span class="number">3</span>).shuffleGrouping(<span class="string">"drpc"</span>);</span><br><span class="line">		builder.setBolt(<span class="string">"return"</span>, <span class="keyword">new</span> ReturnResults(), <span class="number">3</span>).shuffleGrouping(<span class="string">"exclaim"</span>);</span><br><span class="line"></span><br><span class="line">		LocalCluster cluster = <span class="keyword">new</span> LocalCluster();</span><br><span class="line">		Config conf = <span class="keyword">new</span> Config();</span><br><span class="line">		cluster.submitTopology(<span class="string">"exclaim"</span>, conf, builder.createTopology());</span><br><span class="line"></span><br><span class="line">		System.err.println(drpc.execute(<span class="string">"exclamation"</span>, <span class="string">"aaa"</span>));</span><br><span class="line">		System.err.println(drpc.execute(<span class="string">"exclamation"</span>, <span class="string">"bbb"</span>));</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="DRPC-远程模式"><a href="#DRPC-远程模式" class="headerlink" title="DRPC 远程模式"></a>DRPC 远程模式</h3><ul>
<li><p>节点分布</p>
<table>
<thead>
<tr>
<th>host/role</th>
<th>node02</th>
<th>node03</th>
<th>node04</th>
</tr>
</thead>
<tbody><tr>
<td>nimbus</td>
<td>*</td>
<td></td>
<td></td>
</tr>
<tr>
<td>supervisor</td>
<td></td>
<td>*</td>
<td>*</td>
</tr>
<tr>
<td>drpc</td>
<td>*</td>
<td></td>
<td></td>
</tr>
</tbody></table>
</li>
<li><p>在 storm 完全分布式的基础上，修改 storm.yarm 文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cd $STORM_HOME/conf/</span><br><span class="line"></span><br><span class="line">修改配置文件conf/storm.yaml</span><br><span class="line">drpc.servers:</span><br><span class="line">    - "node1“</span><br><span class="line"></span><br><span class="line">启动DRPC Server</span><br><span class="line">bin/storm drpc &amp;</span><br><span class="line"></span><br><span class="line">通过StormSubmitter.submitTopology提交拓扑</span><br><span class="line">StormSubmitter</span><br><span class="line">.submitTopologyWithProgressBar(args[0], conf, builder.createRemoteTopology());</span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li><p>DRPC 客户端代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyDRPCclient</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		</span><br><span class="line"></span><br><span class="line">		DRPCClient client = <span class="keyword">new</span> DRPCClient(<span class="string">"node02"</span>, <span class="number">3772</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			String result = client.execute(<span class="string">"exclamation"</span>, <span class="string">"11,22"</span>);</span><br><span class="line">			</span><br><span class="line">			System.out.println(result);</span><br><span class="line">		&#125; <span class="keyword">catch</span> (TException e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; <span class="keyword">catch</span> (DRPCExecutionException e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; </span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="kafka"><a href="#kafka" class="headerlink" title="kafka*"></a>kafka*</h2><blockquote>
<p>Kafka 是一个分布式的消息队列系统 (Message Queue)。</p>
</blockquote>
<p><img src="http://img.zwer.xyz/blog/20191102213523.png" alt></p>
<p>kafka 集群有多个 Broker 服务器组成，每个类型的消息被定义为 topic。</p>
<p>同一 topic 内部的消息按照一定的 key 和算法被分区 (partition) 存储在不同的 Broker上。</p>
<p>消息生产者 producer 和消费者 consumer 可以在多个 Broker上生产/消费 topic</p>
<h3 id="Topics-and-Logs："><a href="#Topics-and-Logs：" class="headerlink" title="Topics and Logs："></a>Topics and Logs：</h3><p>Topic 即为每条发布到 Kafka 集群的消息都有一个类别，topic 在 Kafka 中可以由多个消费者订阅、消费。</p>
<p>每个 topic 包含一个或多个partition（分区），partition 数量可以在创建 topic 时指定，每个分区日志中记录了该分区的数据以及索引信息。如下图：</p>
<p><img src="http://img.zwer.xyz/blog/20191102214534.png" alt></p>
<p><font color="red">Kafka 只保证一个分区内的消息有序，不能保证一个主题的不同分区之间的消息有序。</font></p>
<p>如果你想要保证所有的消息都绝对有序可以只为一个主题分配一个分区。</p>
<p>分区会给每个消息记录分配一个顺序 ID 号（偏移量）， 能够唯一地标识该分区中的每个记录。</p>
<p>Kafka 集群保留所有发布的记录，不管这个记录有没有被消费过，Kafka 提供相应策略通过配置从而对旧数据处理。</p>
<p><img src="http://img.zwer.xyz/blog/20191102214910.png" alt></p>
<p>实际上，每个消费者唯一保存的元数据信息就是消费者当前消费日志的位移位置。位移位置是由消费者控制，即、消费者可以通过修改偏移量读取任何位置的数据。</p>
<h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><ul>
<li><p>Distribution – 分布式</p>
</li>
<li><p>Producers – 生产者</p>
<p>指定 topic 来发送消息到 Kafka Broker</p>
</li>
<li><p>Consumers – 消费者</p>
<p>根据 topic 消费相应的消息</p>
</li>
</ul>
<h3 id="Kafka集群部署"><a href="#Kafka集群部署" class="headerlink" title="Kafka集群部署"></a>Kafka集群部署</h3><ul>
<li><p><strong>集群规划</strong></p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">node02/192.168.170.102</th>
<th align="center">node03/192.168.170.103</th>
<th align="center">node04 /192.168.170.104</th>
</tr>
</thead>
<tbody><tr>
<td align="center">zookeeper</td>
<td align="center">*</td>
<td align="center">*</td>
<td align="center">*</td>
</tr>
<tr>
<td align="center">kafka</td>
<td align="center">*</td>
<td align="center">*</td>
<td align="center">*</td>
</tr>
</tbody></table>
</li>
<li><p><strong>安装与配置</strong></p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 在 node02 节点上</span><br><span class="line"><span class="meta">#</span> 上传 kakfa 软件安装包到 Linux 服务器上</span><br><span class="line"><span class="meta">#</span> 解压到指定目录下 /opt/sxt</span><br><span class="line">tar xf  kafka_2.10-0.9.0.1.tgz  -C /opt/sxt</span><br><span class="line"><span class="meta">#</span> 配置环境变量</span><br><span class="line">export KAFKA_HOME=/opt/sxt/kafka_2.10-0.9.0.1</span><br><span class="line"><span class="meta">#</span> 进入 $KAFKA_HOME/config 下</span><br><span class="line"><span class="meta">#</span> 修改 vi  server.properties 文件</span><br><span class="line"><span class="meta">#</span> root directory for all kafka znodes.</span><br><span class="line">zookeeper.connect=node02:2181,node03:2181,node04:2181</span><br><span class="line"><span class="meta">#</span> 分发，进入 /opt/sxt 目录下</span><br><span class="line"> scp -r kafka_2.10-0.9.0.1/ node03:`pwd`</span><br><span class="line"> scp -r kafka_2.10-0.9.0.1/ node04:`pwd`</span><br><span class="line"><span class="meta">#</span> 在 node03、node04 节点上修改 server.proerties</span><br><span class="line"><span class="meta">#</span> The id of the broker. This must be set to a unique integer for each broker.</span><br><span class="line">broker.id=1</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>启动</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 进入 $KAFKA_HOME</span><br><span class="line">bin/kafka-server-start.sh config/server.properties # 阻塞当前窗口</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 新打开一个 shell 窗口，node02</span><br><span class="line"><span class="meta">#</span> 创建 topic</span><br><span class="line">kafka-topics.sh --zookeeper node02:2181,node03:2181,node04:2181 --create --replication-factor 2 --partition 3 --topic test</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 查看创建好的 topic </span><br><span class="line">kafka-topics.sh --zookeeper node02:2181,node03:2181,node04:2181 --list</span><br><span class="line">（参数说明：</span><br><span class="line">--replication-factor：指定每个分区的复制因子个数，默认1个</span><br><span class="line">--partitions：指定当前创建的kafka分区数量，默认为1个</span><br><span class="line">--topic：指定新建topic的名称）</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 查看 “test” topic 的描述</span><br><span class="line">kafka-topics.sh --zookeeper node02:2181,node03:2181,node04:2181 --describe test</span><br><span class="line">Topic:test	PartitionCount:3	ReplicationFactor:2	Configs:</span><br><span class="line">	Topic: test	Partition: 0	Leader: 0	Replicas: 0,2	Isr: 0,2</span><br><span class="line">	Topic: test	Partition: 1	Leader: 1	Replicas: 1,0	Isr: 1,0</span><br><span class="line">	Topic: test	Partition: 2	Leader: 2	Replicas: 2,1	Isr: 2,1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 创建生产者</span><br><span class="line">kafka-console-producer.sh --broker-list node02:9092,node03:9092,node04:9092 --topic test</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 创建消费者</span><br><span class="line">kafka-console-consumer.sh --zookeeper node02:2181,node03:2181,node04:2181 --from-beginning --topic test</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h3 id="kafka-与-flume-整合"><a href="#kafka-与-flume-整合" class="headerlink" title="kafka 与 flume 整合"></a>kafka 与 flume 整合</h3><ul>
<li><p><strong>安装 flume</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">解压jar包</span><br><span class="line">mv conf/flume-env.sh.template flume-env.sh</span><br><span class="line">vi flume-env.sh java环境变量</span><br><span class="line">./bin flume-ng version</span><br><span class="line">/conf/下 创建配置文件fk.conf内容如下：</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Describe/configure the source</span><br><span class="line">a1.sources.r1.type = avro</span><br><span class="line">a1.sources.r1.bind = node01</span><br><span class="line">a1.sources.r1.port = 41414</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Describe the sink</span><br><span class="line">a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink</span><br><span class="line">a1.sinks.k1.topic = testflume</span><br><span class="line">a1.sinks.k1.brokerList = node02:9092,node03:9092,node04:9092</span><br><span class="line">a1.sinks.k1.requiredAcks = 1</span><br><span class="line">a1.sinks.k1.batchSize = 20</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000000</span><br><span class="line">a1.channels.c1.transactionCapacity = 10000</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>启动</strong>  </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 启动zk集群</span><br><span class="line">A、启动Kafka集群。</span><br><span class="line">kafka-server-start.sh config/server.properties</span><br><span class="line"></span><br><span class="line">B、配置Flume集群，并启动Flume集群。 # 注意在存在 kafka.conf 的目录中启动</span><br><span class="line">flume-ng agent -n a1 -c conf -f kafka.conf -Dflume.root.logger=DEBUG,console</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 创建 topic testflume 消费者 </span><br><span class="line">kafka-console-consumer.sh --zookeeper node02:2181,node03:2181,node04:2181 --from-beginning --topic testflume</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 创建 topic LogError 消费者</span><br><span class="line">kafka-console-consumer.sh --zookeeper node02:2181,node03:2181,node04:2181 --from-beginnin --topic LogError</span><br></pre></td></tr></table></figure>
</li>
<li><p>Java 发送 RPC 到 Flume </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Flume官网案例</span></span><br><span class="line"><span class="comment"> * http://flume.apache.org/FlumeDeveloperGuide.html </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> root</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RpcClientDemo</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		MyRpcClientFacade client = <span class="keyword">new</span> MyRpcClientFacade();</span><br><span class="line">		<span class="comment">// Initialize client with the remote Flume agent's host and port</span></span><br><span class="line">		client.init(<span class="string">"node01"</span>, <span class="number">41414</span>);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// Send 10 events to the remote Flume agent. That agent should be</span></span><br><span class="line">		<span class="comment">// configured to listen with an AvroSource.</span></span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">100</span>; i &lt; <span class="number">110</span>; i++) &#123;</span><br><span class="line">			String sampleData = <span class="string">"Hello Flume! ERROR"</span> + i;</span><br><span class="line">			client.sendDataToFlume(sampleData);</span><br><span class="line">			System.out.println(<span class="string">"发送数据："</span> + sampleData);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		client.cleanUp();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyRpcClientFacade</span> </span>&#123;</span><br><span class="line">	<span class="keyword">private</span> RpcClient client;</span><br><span class="line">	<span class="keyword">private</span> String hostname;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">int</span> port;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(String hostname, <span class="keyword">int</span> port)</span> </span>&#123;</span><br><span class="line">		<span class="comment">// Setup the RPC connection</span></span><br><span class="line">		<span class="keyword">this</span>.hostname = hostname;</span><br><span class="line">		<span class="keyword">this</span>.port = port;</span><br><span class="line">		<span class="keyword">this</span>.client = RpcClientFactory.getDefaultInstance(hostname, port);</span><br><span class="line">		<span class="comment">// Use the following method to create a thrift client (instead of the</span></span><br><span class="line">		<span class="comment">// above line):</span></span><br><span class="line">		<span class="comment">// this.client = RpcClientFactory.getThriftInstance(hostname, port);</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendDataToFlume</span><span class="params">(String data)</span> </span>&#123;</span><br><span class="line">		<span class="comment">// Create a Flume Event object that encapsulates the sample data</span></span><br><span class="line">		Event event = EventBuilder.withBody(data, Charset.forName(<span class="string">"UTF-8"</span>));</span><br><span class="line"></span><br><span class="line">		<span class="comment">// Send the event</span></span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			client.append(event);</span><br><span class="line">		&#125; <span class="keyword">catch</span> (EventDeliveryException e) &#123;</span><br><span class="line">			<span class="comment">// clean up and recreate the client</span></span><br><span class="line">			client.close();</span><br><span class="line">			client = <span class="keyword">null</span>;</span><br><span class="line">			client = RpcClientFactory.getDefaultInstance(hostname, port);</span><br><span class="line">			<span class="comment">// Use the following method to create a thrift client (instead of</span></span><br><span class="line">			<span class="comment">// the above line):</span></span><br><span class="line">			<span class="comment">// this.client = RpcClientFactory.getThriftInstance(hostname, port);</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cleanUp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="comment">// Close the RPC connection</span></span><br><span class="line">		client.close();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="flume-与-Storm-整合"><a href="#flume-与-Storm-整合" class="headerlink" title="flume 与 Storm 整合"></a>flume 与 Storm 整合</h3><p><a href="http://storm.apache.org/about/integrates.html" target="_blank" rel="noopener">http://storm.apache.org/about/integrates.html</a></p>
<h3 id="Flume-、Storm-、Kafka-整合架构"><a href="#Flume-、Storm-、Kafka-整合架构" class="headerlink" title="Flume 、Storm 、Kafka 整合架构"></a>Flume 、Storm 、Kafka 整合架构</h3><p><img src="http://img.zwer.xyz/blog/20191103214301.png" alt></p>
<h2 id="项目案例"><a href="#项目案例" class="headerlink" title="项目案例"></a>项目案例</h2><h3 id="模拟电信项目"><a href="#模拟电信项目" class="headerlink" title="模拟电信项目"></a>模拟电信项目</h3><p>过</p>
<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><ul>
<li><p>事务性拓扑（Transactional Topologies）</p>
</li>
<li><p>保证消息（tuple）被且仅被处理一次</p>
</li>
</ul>
<h3 id="Design1"><a href="#Design1" class="headerlink" title="Design1"></a>Design1</h3><p>强顺序流（强有序）</p>
<img src="http://img.zwer.xyz/blog/20191104164508.png" style="zoom:50%;">

<p>引入事务（transaction）的概念，每个transaction（即每个tuple）关联一个transaction id。<br>Transaction id 从 1开始，每个 tuple 会按照顺序+1。<br>在处理 tuple 时，将处理成功的 tuple 结果以及 transaction id 同时写入数据库中进行存储。</p>
<p>两种情况：<br>1、当前transaction id与数据库中的transaction id不一致<br>2、两个transaction id相同</p>
<p>缺点：<br>一次只能处理一个tuple，无法实现分布式计算</p>
<h3 id="Design2"><a href="#Design2" class="headerlink" title="Design2"></a>Design2</h3><p>强顺序的Batch流 </p>
<p><img src="http://img.zwer.xyz/blog/20191104164628.png" alt></p>
<p>事务（transaction）以 batch 为单位，即把一批 tuple 称为一个 batch，每次处理一个 batch。<br>每个 batch（一批 tuple）关联一个 transaction id<br>每个 batch 内部可以并行计算</p>
<p>缺点：空余占用资源</p>
<p><img src="http://img.zwer.xyz/blog/20191104165303.png" alt></p>
<h3 id="Design3"><a href="#Design3" class="headerlink" title="Design3"></a>Design3</h3><ul>
<li><p><strong>Storm’s design</strong></p>
<p>将 Topology 拆分为两个阶段：</p>
<ol>
<li>Processing phase<pre><code>允许并行处理多个 batch</code></pre></li>
<li>Commit phase<pre><code>保证batch的强有序，一次只能处理一个batch</code></pre></li>
</ol>
</li>
<li><p><strong>Design details</strong></p>
<ul>
<li><p>Manages state - 状态管理<br>Storm 通过 Zookeeper 存储所有 transaction 相关信息（包含了：当前transaction id 以及batch的元数据信息）</p>
</li>
<li><p>Coordinates the transactions - 协调事务<br>Storm 会管理决定 transaction 应该处理什么阶段（processing、committing）</p>
</li>
<li><p>Fault detection - 故障检测<br>Storm 内部通过 Acker 机制保障消息被正常处理（用户不需要手动去维护）</p>
</li>
<li><p>First class batch processing API<br>Storm 提供 batch bolt 接口</p>
</li>
</ul>
</li>
</ul>
<h3 id="三种事务"><a href="#三种事务" class="headerlink" title="三种事务"></a>三种事务</h3><p>1、普通事务</p>
<p>2、Partitioned Transaction - 分区事务</p>
<p>3、Opaque Transaction - 不透明分区事务</p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://zwer.xyz/2019/10/28/20191028 CDH/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zwer">
      <meta itemprop="description" content="记录学习的日常">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zwer 的博客空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/10/28/20191028 CDH/" class="post-title-link" itemprop="url">20191028 CDH</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-10-28 00:00:00" itemprop="dateCreated datePublished" datetime="2019-10-28T00:00:00+08:00">2019-10-28</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-31 19:49:11" itemprop="dateModified" datetime="2019-10-31T19:49:11+08:00">2019-10-31</time>
              </span>
            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h2 id="CDH-简介"><a href="#CDH-简介" class="headerlink" title="CDH  简介"></a>CDH  简介</h2><p>为什么 在 Hadoop 2.x 中 HDFS 中有 ZKFC 进程，而 yarn 却没有？ </p>
<p>在 Hadoop 1.x 升级到 Hadoop 2.x 的过程中，考虑到向下兼容的问题，NameNode 进程没有嵌入 ZKFC 中的代码，而另外开辟一个进程 ZKFC 。再者由于 Hadoop 1.x 中没有 yarn 组件，Hadoop 2.x 中才出现的 yarn 组件，所以  yarn 不用考虑向下兼容的问题，即 ResourceManager 进程就直接嵌入 ZKFC 中的代码，只运行一个进程。</p>
<h3 id="Apache-Hadoop-不足之处"><a href="#Apache-Hadoop-不足之处" class="headerlink" title="Apache Hadoop 不足之处"></a>Apache Hadoop 不足之处</h3><ul>
<li>版本管理混乱</li>
<li>部署过程繁琐、升级过程复杂</li>
<li>兼容性差</li>
<li>安全性低</li>
</ul>
<h3 id="Hadoop-发行版"><a href="#Hadoop-发行版" class="headerlink" title="Hadoop 发行版"></a>Hadoop 发行版</h3><ul>
<li>Apache Hadoop</li>
<li>Cloudera’s Distribution Including Apache Hadoop（CDH）</li>
<li>Hortonworks Data Platform (HDP) </li>
<li>MapR</li>
<li>EMR</li>
</ul>
<h3 id="Cloudera’s-Distribution-including-Apache-Hadoop"><a href="#Cloudera’s-Distribution-including-Apache-Hadoop" class="headerlink" title="Cloudera’s Distribution, including Apache Hadoop"></a>Cloudera’s Distribution, including Apache Hadoop</h3><p>是Hadoop众多分支中的一种，由Cloudera维护，基于稳定版本的Apache Hadoop构建</p>
<p>提供了Hadoop的核心</p>
<ul>
<li>可扩展存储</li>
<li>分布式计算</li>
</ul>
<p>基于Web的用户界面</p>
<h2 id="CDH-框架"><a href="#CDH-框架" class="headerlink" title="CDH 框架"></a>CDH 框架</h2><h3 id="CDH-框架图"><a href="#CDH-框架图" class="headerlink" title="CDH  框架图"></a>CDH  框架图</h3><p>Impala 是基于内存计算的，执行  SQL ，速度比 Hive 要快</p>
<p><img src="http://img.zwer.xyz/blog/20191028144352.png" alt></p>
<h3 id="CDH-的优点"><a href="#CDH-的优点" class="headerlink" title="CDH 的优点"></a>CDH 的优点</h3><ul>
<li><p>版本划分清晰</p>
</li>
<li><p>版本更新速度快</p>
</li>
<li><p>支持Kerberos安全认证</p>
</li>
<li><p>文档清晰</p>
</li>
<li><p>支持多种安装方式（Cloudera Manager方式）</p>
</li>
</ul>
<h3 id="CDH-安装方式"><a href="#CDH-安装方式" class="headerlink" title="CDH 安装方式"></a>CDH 安装方式</h3><ul>
<li>Cloudera Manager</li>
<li>Yum</li>
<li>Rpm</li>
<li>Tarball</li>
</ul>
<p>CDH5.4<br><a href="http://archive.cloudera.com/cdh5/" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/</a></p>
<p>Cloudera Manager5.4.3：<br><a href="http://www.cloudera.com/downloads/manager/5-4-3.html" target="_blank" rel="noopener">http://www.cloudera.com/downloads/manager/5-4-3.html</a></p>
<h2 id="CDH-安装"><a href="#CDH-安装" class="headerlink" title="CDH  安装"></a>CDH  安装</h2><h3 id="Cloudera-Manager-简介"><a href="#Cloudera-Manager-简介" class="headerlink" title="Cloudera Manager 简介"></a>Cloudera Manager 简介</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Server</span><br><span class="line">    管理控制台服务器和应用程序逻辑</span><br><span class="line">    负责软件安装、配置</span><br><span class="line">    启动和停止服务</span><br><span class="line">    管理服务运行的群集</span><br><span class="line">Agent</span><br><span class="line">    安装在每台主机上</span><br><span class="line">    负责启动和停止进程，配置，监控主机</span><br><span class="line">Management Service</span><br><span class="line">	由一组角色组成的服务，执行各种监视、报警和报告功能</span><br><span class="line">Database</span><br><span class="line">Cloudera Repository</span><br><span class="line">Clients</span><br><span class="line">    Admin Console</span><br><span class="line">    API</span><br></pre></td></tr></table></figure>

<p><img src="http://img.zwer.xyz/blog/20191028161056.png" alt></p>
<h3 id="Cloudera-Manager-部署"><a href="#Cloudera-Manager-部署" class="headerlink" title="Cloudera Manager 部署"></a>Cloudera Manager 部署</h3><ol>
<li><p><strong>系统环境准备</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 使用 xshell 登录时</span><br><span class="line"><span class="meta">#</span> 不能 open 方式登录，可能会影响后面 ssh 免密</span><br><span class="line"><span class="meta">#</span> 而是采用 ssh 方式登录</span><br><span class="line"></span><br><span class="line">ssh 免密钥</span><br><span class="line">ssh localhost 方式创建本地目录</span><br><span class="line"></span><br><span class="line">1、网络配置</span><br><span class="line">vi /etc/sysconfig/network</span><br><span class="line">vi /etc/hosts</span><br><span class="line"></span><br><span class="line">2、SSH免密钥登录</span><br><span class="line">ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa</span><br><span class="line">ssh-copy-id</span><br><span class="line"></span><br><span class="line">3、防火墙关闭</span><br><span class="line">service iptables stop</span><br><span class="line">chkconfig iptables off</span><br><span class="line"></span><br><span class="line">4、SELINUX关闭</span><br><span class="line">setenforce 0</span><br><span class="line">vi /etc/selinux/config (SELINUX=disabled)</span><br><span class="line"></span><br><span class="line">5、安装JDK配置环境变量</span><br><span class="line">export JAVA_HOME=/usr/java/jdkXXX</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"></span><br><span class="line">6、安装NTP</span><br><span class="line"><span class="meta">#</span> 获取阿里云</span><br><span class="line">curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo</span><br><span class="line"><span class="meta">#</span> 更新 yum 缓存</span><br><span class="line">yum makecache</span><br><span class="line">yum install -y ntp</span><br><span class="line"><span class="meta">#</span> 设置开机启动 </span><br><span class="line">chkconfig ntpd on</span><br><span class="line"><span class="meta">#</span> 启动 ntpd 服务</span><br><span class="line">service ntpd start</span><br><span class="line"><span class="meta">#</span> 设置时间同步</span><br><span class="line">ntpdate ntp1.aliyun.com</span><br><span class="line"></span><br><span class="line">7、安装配置mysql</span><br><span class="line">yum install -y mysql-server</span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123' WITH GRANT OPTION;</span><br><span class="line">flush privileges</span><br><span class="line"></span><br><span class="line">8、下载第三方依赖包</span><br><span class="line">yum install -y chkconfig python bind-utils psmisc libxslt zlib sqlite cyrus-sasl-plain cyrus-sasl-gssapi fuse fuse-libs redhat-lsb</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="2">
<li><p><strong>cloudera Manager 安装</strong></p>
<blockquote>
<p>集群分发时，一定要先分发，后启动</p>
</blockquote>
<table>
<thead>
<tr>
<th align="center">HOST</th>
<th align="center">node06</th>
<th align="center">node07</th>
<th align="center">node08</th>
</tr>
</thead>
<tbody><tr>
<td align="center">IP</td>
<td align="center">192.168.170.106</td>
<td align="center">192.168.170.107</td>
<td align="center">192.168.170.108</td>
</tr>
<tr>
<td align="center">Server</td>
<td align="center">*</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">Agent</td>
<td align="center">*</td>
<td align="center">*</td>
<td align="center">*</td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">1、安装Cloudera Manager Server、Agent</span><br><span class="line">mkdir /opt/cloudera-manager # (node06,node07,node08) </span><br><span class="line">tar xvzf cloudera-manager*.tar.gz -C /opt/cloudera-manager</span><br><span class="line"></span><br><span class="line">2、创建用户cloudera-scm # (node06,node07,node08) </span><br><span class="line">useradd --system --no-create-home --shell=/bin/false --comment "Cloudera SCM User" cloudera-scm</span><br><span class="line"></span><br><span class="line">3、配置CM Agent # (node06)</span><br><span class="line">修改文件/opt/cloudera-manager/cm-5.4.3/etc/cloudera-scm-agent/config.ini中server_host</span><br><span class="line"></span><br><span class="line">4、配置CM Server数据库 # (node06)</span><br><span class="line">拷贝mysql jar文件到目录 /usr/share/java/</span><br><span class="line">注意jar包名称要修改为mysql-connector-java.jar</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> node06</span><br><span class="line">grant all on *.* to 'temp'@'%' identified by 'temp' with grant option;</span><br><span class="line">cd /opt/cloudera-manager/cm-5.4.3/share/cmf/schema/</span><br><span class="line">./scm_prepare_database.sh mysql temp -h node06 -utemp -ptemp --scm-host node06 scm scm scm</span><br><span class="line">格式：数据库类型、数据库、数据库服务器、用户名、密码、cm server服务器</span><br><span class="line"></span><br><span class="line">Server节点 #（node06）</span><br><span class="line">mkdir -p /opt/cloudera/parcel-repo</span><br><span class="line">chown cloudera-scm:cloudera-scm /opt/cloudera/parcel-repo</span><br><span class="line">Agent节点 #  (node06,node07,node08) </span><br><span class="line">mkdir -p /opt/cloudera/parcels</span><br><span class="line">chown cloudera-scm:cloudera-scm /opt/cloudera/parcels</span><br><span class="line"></span><br><span class="line">6、制作CDH本地源 #（node06）</span><br><span class="line">下载好文件CDH-5.4.0-1.cdh5.4.0.p0.27-el6.parcel以及manifest.json，将这两个文件放到server节点的/opt/cloudera/parcel-repo下。</span><br><span class="line">打开manifest.json文件，里面是json格式的配置，找到与下载版本相对应的hash码，新建文件，文件名与你的parel包名一致，并加上.sha后缀，将hash码复制到文件中保存。</span><br><span class="line"></span><br><span class="line">7、分发</span><br><span class="line">cd /opt/cloudera-manager/  </span><br><span class="line">scp -r ./*  root@node07:`pwd`</span><br><span class="line">scp -r ./*  root@node08:`pwd`</span><br><span class="line"></span><br><span class="line">8、启动CM Server、Agent</span><br><span class="line">cd /opt/cloudera-manager/cm-5.4.3/etc/init.d/</span><br><span class="line">./cloudera-scm-server start</span><br><span class="line">Sever首次启动会自动创建表以及数据，不要立即关闭或重启，否则需要删除所有表及数据重新安装</span><br><span class="line">./cloudera-scm-agent start</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>小技巧： 1. 若运行某个指令执行任务阻塞当前 shell 窗口，且想中断运行该任务，若 <code>Ctrl + C</code>不能中断停止，可使用 <code>Ctrl + Z</code> 将当前任务放到后台进行，从而不阻塞当前  shell 窗口，然后输入 <code>jobs -l</code>，显示当前任务作业的状态及进程号，由 <code>kill -9 进程号</code>，强制终止任务作业 2. <code>netstat -natp |grep 进程号</code>,查看某个进程使用的端口号</p>
<ol start="3">
<li><p>访问 Clouder-manager 的 web 界面</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">访问：http://ManagerHost:7180，</span><br><span class="line">用户名、密码：admin</span><br><span class="line">若可以访问，则CM安装成功。</span><br></pre></td></tr></table></figure>
</li>
<li><p>为什么集群个数更倾向于奇数个，而不是偶数个？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">以 3 台集群和 4 台集群举例：</span><br><span class="line">3 台集群，若其中有一台宕机了，3 / 2 = 1.5 &lt; 2,达到了过半的条件，集群可以运行。</span><br><span class="line">4 台集群，若其中有一台宕机了，4 / 2 = 2 &lt; 3,达到了过半的条件，集群也可以运行。</span><br><span class="line">但是4 台主机集群和 3台主机集群却承担相同的风险，且成本 4 台主机集群的成本比 3 台主机集群的成本高</span><br><span class="line"></span><br><span class="line">举例，若 4 台主机集群中，宕机了 2 台，剩余 2 台，不满足集群主机数量过分的条件，就不保证了集群的数据一致性，进而集群的可用性。同样 3 台主机集群中，宕机了 2台，剩余 1台，也满足集群主机数量过半的条件，即  4 台主机集群和 3台主机集群却承担相同的风险。</span><br><span class="line"></span><br><span class="line">说明： 集群中主机数量过半才能正常运行，因为集群中的网络条件等其他因素，可能会出现某台主机在一定时间内不能接受到或者发送消息，所以以集群中主机数量过半作为条件，是较为合理的。</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="Hue"><a href="#Hue" class="headerlink" title="Hue"></a>Hue</h2><blockquote>
<p>Hue是一个开源的Apache Hadoop UI系统。</p>
<p>通过使用Hue我们可以在浏览器端的Web控制台上与Hadoop集群进行交互来分析处理数据。<br>例如操作HDFS上的数据、运行Hive脚本、管理Oozie任务等等。</p>
<p>是基于Python Web框架Django实现的。</p>
<p>支持任何版本Hadoop</p>
</blockquote>
<p>Hue 的特点：<br>基于文件浏览器（File Browser）访问HDFS<br>基于web编辑器来开发和运行Hive查询<br>支持基于Solr进行搜索的应用，并提供可视化的数据视图，报表生成<br>通过web调试和开发impala交互式查询<br>spark调试和开发<br>Pig开发和调试<br>oozie任务的开发，监控，和工作流协调调度<br>Hbase数据查询和修改，数据展示<br>Hive的元数据（metastore）查询<br>MapReduce任务进度查看，日志追踪<br>创建和提交MapReduce，Streaming，Java job任务<br>Sqoop2的开发和调试<br>Zookeeper的浏览和编辑<br>数据库（MySQL，PostGres，SQlite，Oracle）的查询和展示</p>
<h2 id="ClouderaManager-使用-impala-oozie"><a href="#ClouderaManager-使用-impala-oozie" class="headerlink" title="ClouderaManager 使用 impala_oozie"></a>ClouderaManager 使用 impala_oozie</h2><h3 id="ClouderManager-功能使用"><a href="#ClouderManager-功能使用" class="headerlink" title="ClouderManager 功能使用"></a>ClouderManager 功能使用</h3><p>主机  - host<br>机架  - rack<br>集群  -  Cluster<br>服务  - service<br>服务实例  - service instance<br>角色  - role<br>角色实例  - role instance<br>角色组  - role group<br>主机模板  - host template<br>parcel<br>静态服务池  - static service pool<br>动态资源池  - dynamic resource pool</p>
<p>1、集群管理<br>    添加、删除集群<br>    启动、停止、重启集群<br>    重命名集群<br>    全体集群配置<br>    移动主机</p>
<p>2、主机管理<br>    查看主机详细<br>    主机检查<br>    集群添加主机<br>    分配机架<br>    主机模板<br>    维护模式<br>    删除主机</p>
<p>3、服务管理<br>    添加服务<br>    对比不同集群上的服务配置<br>    启动、停止、重启服务<br>    滚动重启<br>    终止客户端正在执行的命令<br>    删除服务<br>    重命名服务<br>    配置最大进程数<br>rlimit_fds</p>
<p>4、角色管理<br>    角色实例<br>    添加角色实例<br>    启动、停止、重启角色实例<br>    解除授权<br>    重新授权<br>    删除角色实例<br>    角色组<br>    创建角色组<br>    管理角色组</p>
<p>5、资源管理<br>    动态资源池<br>    静态服务池</p>
<p>6、用户管理</p>
<p>7、安全管理</p>
<h3 id="安装-Hive"><a href="#安装-Hive" class="headerlink" title="安装 Hive"></a>安装 Hive</h3><blockquote>
<p>图形化操作</p>
</blockquote>
<p>中间要 Hive 在关系型数据库建立表，并授权</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> hive     <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">on</span> hive.* <span class="keyword">TO</span> <span class="string">'hive'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'hive'</span>;</span><br></pre></td></tr></table></figure>

<h3 id="安装-OOZIE"><a href="#安装-OOZIE" class="headerlink" title="安装 OOZIE"></a>安装 OOZIE</h3><blockquote>
<p>同样图形化操作</p>
</blockquote>
<p>中间要为 OOZIE 在关系型数量库建立库，并授权</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> oozie     <span class="keyword">DEFAULT</span> <span class="built_in">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">on</span> oozie.* <span class="keyword">TO</span> <span class="string">'oozie'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'oozie'</span>;</span><br></pre></td></tr></table></figure>

<h3 id="安装-Hub"><a href="#安装-Hub" class="headerlink" title="安装 Hub"></a>安装 Hub</h3><blockquote>
<p>图形化操作，点点点…</p>
<p> 小插曲： 什么叫解耦底层技术的平台产品 ？ 直接屏蔽底层的实现</p>
</blockquote>
<ol>
<li><p>Hue 介绍</p>
<p>代理 HDFS、Hive 、OOIZE 等模块，调用他们的 API ，执行相应的操作，自己只提供了一个 Web 界面，本身并不做什么事情。</p>
</li>
<li><p>Hue 的用户模块</p>
<p>在开始使用 Hue 时，首先要进行登录，登录的用户名和密码，由自己设置。使用 Hue 登录成功后，Hue 会将登录的用户名，告诉给 HDFS ，并在 HDFS 中创建用户家目录。</p>
<p>注意： 使用 HDFS  只需要用户名，并不需要密码，需要登录的是 Hue </p>
</li>
<li><p>Hue 支持文件修改-仅针对小文件</p>
</li>
</ol>
<h2 id="Implal"><a href="#Implal" class="headerlink" title="Implal"></a>Implal</h2><blockquote>
<p>Cloudera 公司推出，提供对 HDFS 、HBase 数据的高性能、低延迟的交互式 SQL 查询功能</p>
<p><strong>基于 Hive</strong> 使用<strong>内存计算</strong>，兼顾数据仓库、具有实时、批处理、多并发等特点</p>
<p>是 CDH 平台首选的 PB 级大数据实时查询分析引擎</p>
</blockquote>
<h3 id="Shuffle"><a href="#Shuffle" class="headerlink" title="Shuffle"></a>Shuffle</h3><ul>
<li><p>MapReduce Shuffle ：</p>
<p>​     首先数据会进行序列化，然后放入环形字节数组缓冲池，当缓冲池达到阈值（默认为 80 M）后，会触发 spill 溢写操作，将缓冲池中的数据写入磁盘文件中，在过程中，会先进行二次排序、分区等操作。若相同的 key 的文件数量达到三个以上，触发 combiner 操作（归并排序），合并文件。注意： 若相同的 key 文件，spill 溢写二次产生二个文件，但不会执行 combiner 操作。从中得出：MapReduce 不能将相同的 key 文件归并到一个文件中，进而得出，MapReduce 写的时候必须采用<strong>二次排序的机制来分区有序，且分区里 key 有序（邻接排列在一起）， 才能够保证MapReduce 的原语（相同的 key 为一组，方法内迭代这一组数据)。</strong></p>
<p>MapReduce Shuffile 消耗的计算资源较多，二次排序不可避免</p>
</li>
<li><p>Spark Shuffle：</p>
<p>rpartition ： 重新分区  ….</p>
</li>
</ul>
<h3 id="Implal-架构图"><a href="#Implal-架构图" class="headerlink" title="Implal  架构图"></a>Implal  架构图</h3><ul>
<li><p>Implal 启动后会加载 Hive 的 MeataStore 元数据</p>
</li>
<li><p>Implal 运行速度比 Hive 快的多</p>
</li>
<li><p>Implal 创建元数据会持久化到 Hive 中</p>
<p>​    Hive 为 Implal 做元数据持久化的操作，而 Hive 的元数据存放在关系型数据库中（MySQL、Oracle 中）</p>
</li>
</ul>
<p><img src="http://img.zwer.xyz/blog/20191029193806.png" alt></p>
<h3 id="安装-Implal"><a href="#安装-Implal" class="headerlink" title="安装 Implal"></a>安装 Implal</h3><p>Catalog Server 安装在 node06 机器上</p>
<p>StateStore 安装在 node06 机器上</p>
<p>Daemon 安装在 node07、node08 机器上</p>
<p><img src="http://img.zwer.xyz/blog/20191029201029.png" alt></p>
<h3 id="Impala-使用"><a href="#Impala-使用" class="headerlink" title="Impala 使用"></a>Impala 使用</h3><blockquote>
<p>Impala 的使用 SQL 与 Hive 的使用类似，但是不支持 Hive 一些特殊操作，如： UDF等。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">使用  impala-shell 打开,进入 impala 交互界面</span><br><span class="line">show tables; </span><br><span class="line">refresh &lt;tablename&gt; 增量刷新元数据库</span><br><span class="line">invalidate metadata 全量刷新元数据库，将 Hive 的元数据同步刷新到 impala</span><br><span class="line">explain &lt;sql&gt;  显示查询执行计划，步骤</span><br><span class="line">shell &lt;shell&gt; 不退出 impala—shell ,执行  Linux 命令</span><br><span class="line">profile (查询完成后执行）查询最近一次查询的底层信息,[事后诸葛亮]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">impala-shell -p  显示 sql 计划</span><br><span class="line">impala-shell -i  host 登录指定 impala</span><br><span class="line">impala-shell -q sql(语句) 不进入交互界面</span><br><span class="line">-B  去掉格式化的样式</span><br><span class="line">-f  sql 文件的位置</span><br><span class="line">-o  输出文件</span><br><span class="line">-c  查询失败后继续执行</span><br></pre></td></tr></table></figure>

<p>压缩数据文件的好处: </p>
<ol>
<li>节省空间开销</li>
<li>由于数据文件压缩后，体积变小，进入内存速度变快，因为 IO 小了。</li>
</ol>
<h3 id="Impala-与-HBase-整合"><a href="#Impala-与-HBase-整合" class="headerlink" title="Impala 与 HBase 整合"></a>Impala 与 HBase 整合</h3><blockquote>
<p>与 Hive 和 HBase 整合类似</p>
</blockquote>
<h2 id="OOZIE"><a href="#OOZIE" class="headerlink" title="OOZIE"></a>OOZIE</h2><blockquote>
<p>分布式调度</p>
</blockquote>
<p>Oozie 是用于 Hadoop 平台的开源的工作流调度引擎</p>
<p>用来管理 Hadoop 作业</p>
<p>属于 web 应用程序，由 Oozie Client 和 Oozie Server  两个组件构成。</p>
<p>Oozie Server 运行于 Java Servlet 容器（tomcat） 中的 web 程序</p>
<p>官网： <a href="https://oozie.apache.org" target="_blank" rel="noopener">https://oozie.apache.org</a></p>
<p>作用： 一组任务使用一个 DAG（有向无环图） 来表示</p>
<h3 id="Oozie-使用"><a href="#Oozie-使用" class="headerlink" title="Oozie 使用"></a>Oozie 使用</h3><p>Oozie 启动成功后，打开 Web 的 UI 界面 </p>
<p><img src="http://img.zwer.xyz/blog/20191029215514.png" alt></p>
<p>解决方法：</p>
<ul>
<li>下载 <a href="http://archive.cloudera.com/gplextras/misc/ext-2.2.zip" target="_blank" rel="noopener">http://archive.cloudera.com/gplextras/misc/ext-2.2.zip</a> </li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip  ext-2.2.zip -d  /var/lib/oozie</span><br></pre></td></tr></table></figure>

<ul>
<li><p>修改 配置 Configuration，保存，重新启动 Oozie</p>
<p><img src="http://img.zwer.xyz/blog/20191029215621.png" alt></p>
</li>
</ul>
<h3 id="job-properties"><a href="#job-properties" class="headerlink" title="job.properties"></a>job.properties</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nameNode=hdfs://node06:8020</span><br><span class="line">jobTracker=node01:8032</span><br><span class="line">queueName=default</span><br><span class="line">exampleRoot=examples</span><br><span class="line"></span><br><span class="line">oozie.wf.application.path=$&#123;nameNode&#125;/user/</span><br></pre></td></tr></table></figure>

<p><img src="http://img.zwer.xyz/blog/20191029220808.png" alt></p>
<h3 id="workflow-xml"><a href="#workflow-xml" class="headerlink" title="workflow.xml"></a>workflow.xml</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">workflow-app</span> <span class="attr">xmlns</span>=<span class="string">"uri:oozie:workflow:0.3"</span> <span class="attr">name</span>=<span class="string">"shell-wf"</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">start</span> <span class="attr">to</span>=<span class="string">"shell-node"</span>/&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">action</span> <span class="attr">name</span>=<span class="string">"shell-node"</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">shell</span> <span class="attr">xmlns</span>=<span class="string">"uri:oozie:shell-action:0.1"</span>&gt;</span></span><br><span class="line">    		<span class="tag">&lt;<span class="name">job-tracker</span>&gt;</span>$&#123;jobTracker&#125;<span class="tag">&lt;/<span class="name">job-tracker</span>&gt;</span>                         </span><br><span class="line">			&lt;name-node&gt;&lt;$&#123;nameNode&#125;&lt;/name-node&gt;</span><br><span class="line">			<span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	        	<span class="tag">&lt;<span class="name">property</span>&gt;</span>	</span><br><span class="line">                   		<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.job.queue.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">						<span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;queueName&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">				<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">exec</span>&gt;</span>echo<span class="tag">&lt;/<span class="name">exec</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">argument</span>&gt;</span>hi shell in oozie<span class="tag">&lt;/<span class="name">argument</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">shell</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">ok</span> <span class="attr">to</span>=<span class="string">"end"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">error</span> <span class="attr">to</span>=<span class="string">"fail"</span>/&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">action</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">kill</span> <span class="attr">name</span>=<span class="string">"fail"</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">message</span>&gt;</span></span><br><span class="line">			Map/Reduce failed, error message [$&#123;wf:errorMessgae(wf:lastErrorNode())&#125;]</span><br><span class="line">		<span class="tag">&lt;/<span class="name">message</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">kill</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">end</span> <span class="attr">name</span>=<span class="string">"end"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">workflow-app</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><img src="http://img.zwer.xyz/blog/20191029220402.png" alt></p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://zwer.xyz/2019/10/26/20191026 elasticSearch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zwer">
      <meta itemprop="description" content="记录学习的日常">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zwer 的博客空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/10/26/20191026 elasticSearch/" class="post-title-link" itemprop="url">20191026 elasticSearch</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-10-26 00:00:00" itemprop="dateCreated datePublished" datetime="2019-10-26T00:00:00+08:00">2019-10-26</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-11-04 22:11:56" itemprop="dateModified" datetime="2019-11-04T22:11:56+08:00">2019-11-04</time>
              </span>
            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h2 id="Lucene"><a href="#Lucene" class="headerlink" title="Lucene"></a>Lucene</h2><h3 id="数据分类"><a href="#数据分类" class="headerlink" title="数据分类"></a>数据分类</h3><ul>
<li><p>结构化（关系型数据库），全文检索<br>表：字段数量，字段类型</p>
</li>
<li><p>非结构化：</p>
<p>文本文档，图片，视频，音乐…</p>
</li>
<li><p>半结构化：</p>
<p>json，html，xml</p>
</li>
</ul>
<h3 id="Lucene-简介"><a href="#Lucene-简介" class="headerlink" title="Lucene 简介"></a>Lucene 简介</h3><p>Lucene 是 Apache 软件基金会的一个项目，是一个开发源码的全文检索引擎工具包，是一个全文检索引擎的一个架构。提供了完成的查询引擎和检索引擎，部分文本分析引擎。</p>
<h3 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h3><p>通俗解释，我们通常都是通过查找文件位置及文件名，再查找文件的内容。倒排索引可以理解为通过文件内容来查找文件位置及文件名的。</p>
<p>倒排索引是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。它是文档检索系统中最常用的数据结构。通过倒排索引，可以根据单词快速获取包含这个单词的文档列表。</p>
<p>倒排索引也是 lucence 的索引核心。</p>
<p>举例：有两个文档 doc，id 分别为 1,2 。doc-id-1中的 content 是“我是中国人”，doc-id-2 中的 content 是 “中国是全球人口最多的国家，中国人也最多”。紧接着为这两个文档建立倒排索引。先读取 doc 文档，使用分词器对 content 中的内容 content 进行分词，产生的结果放入索引 index 表中。以“中国”这个词为例，中国（1:1）{2}，（2:2）{0,15}。（1:1）{2}表示的意思是中国这个词出现在 id 为 1 的 doc 文档中，且出现的次数为 1，偏移量为 2 。（2:2）{0,15}  表示的意思是中国这个词出现在 id 为 2 的doc 文档猴子那个，且出现的次数为 2，偏移量有0,15 。</p>
<img src="http://img.zwer.xyz/blog/20191027103435.png" style="zoom: 67%;">



<p>每个域可以设置三个类型：是否保存，是否索引，是否分词 </p>
<p><img src="http://img.zwer.xyz/blog/20191027104508.png" alt></p>
<p>从 Hbase 中按行取出数据，建立 doc 文档，经过分析（分词，过滤）后，建立倒排索引。</p>
<p>参考： <a href="https://www.cnblogs.com/one--way/p/5708456.html" target="_blank" rel="noopener">https://www.cnblogs.com/one--way/p/5708456.html</a></p>
<h3 id="Lucene-架构"><a href="#Lucene-架构" class="headerlink" title="Lucene 架构"></a>Lucene 架构</h3><ul>
<li><p>横向扩展： 加机器</p>
<p>​    Lucene 集群之间的单机的计算速度，彼此应该相差不大 。</p>
</li>
<li><p>纵向扩展：主从模式</p>
<p>​    主节点-负责计算</p>
<p>​    从节点-1. 备机  2. 分担主节点读请求的压力</p>
</li>
</ul>
<p>下面采用 3 个机器，作为  Lucene 的计算集群。</p>
<p>​        根据 doc 的 id 做 hash 取模，分配到 Lucene 计算集群中，doc  处理完毕后，会在本地生成 index 索引文件，各个机器上 index 索引文件最终汇聚到 master 节点。</p>
<p><img src="http://img.zwer.xyz/blog/20191027104742.png" alt></p>
<h2 id="ElasticSearch-分布式安装"><a href="#ElasticSearch-分布式安装" class="headerlink" title="ElasticSearch 分布式安装"></a>ElasticSearch 分布式安装</h2><blockquote>
<p>零配置，开箱即用<br>没有繁琐的安装配置<br>Java 版本要求：最低 1.7<br>下载地址：<a href="https://www.elastic.co/downloads/" target="_blank" rel="noopener">https://www.elastic.co/downloads/</a></p>
</blockquote>
<p>启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/elasticsearch-2.2.0</span><br><span class="line">./bin/elasticsearch</span><br><span class="line">bin/elasticsearch -d(后台运行)</span><br></pre></td></tr></table></figure>

<h3 id="基础环境"><a href="#基础环境" class="headerlink" title="基础环境"></a>基础环境</h3><p>安装 JDK ，并配置环境变量</p>
<h3 id="安装工作"><a href="#安装工作" class="headerlink" title="安装工作"></a>安装工作</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">共享模式下：</span><br><span class="line">useradd sxt</span><br><span class="line">echo sxt | passwd --stdin sxt</span><br><span class="line"></span><br><span class="line">su sxt</span><br><span class="line">root 用户创建 /opt/sxt/es(普通用户无法创建)</span><br><span class="line">mkdir -p /opt/sxt/es (注意：此时的目录权限属于root)</span><br><span class="line">在父级目录 sxt 下执行： chown sxt:sxt es</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">单节点模式下root用户：</span><br><span class="line">安装解压程序</span><br><span class="line">ftp拷贝至根目录下，或者software目录下（备用，可选）</span><br><span class="line"></span><br><span class="line">切换回sxt用户（共享模式，可以看到software内容）</span><br><span class="line"></span><br><span class="line">单节点模式：</span><br><span class="line"></span><br><span class="line">使用sxt用户解压es2.2.1zip包至es目录，保证es文件属于用户sxt：</span><br><span class="line"></span><br><span class="line">unzip elasticsearch-2.2.1.zip -d /opt/sxt/es</span><br><span class="line"></span><br><span class="line">进入es/conf, 修改elastic配置文件：</span><br><span class="line">修改：</span><br><span class="line">---------------cluster-------------------------</span><br><span class="line"></span><br><span class="line">cluster.name: bjsxt-es</span><br><span class="line">----------------node-------------------------------</span><br><span class="line">node.name: node06 (分发后各节点修改)</span><br><span class="line"></span><br><span class="line">----------------network--------------------------------</span><br><span class="line">network.host: 192.168.133.6 (分发后修改)</span><br><span class="line"></span><br><span class="line">http.port:9200 (放开)</span><br><span class="line"></span><br><span class="line">末尾增加防脑裂：</span><br><span class="line">discovery.zen.ping.multicast.enabled: false </span><br><span class="line">discovery.zen.ping.unicast.hosts: ["192.168.133.6","192.168.133.7", "192.168.133.8"]</span><br><span class="line">discovery.zen.ping_timeout: 120s</span><br><span class="line">client.transport.ping_timeout: 60s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">增加图形可视化插件：</span><br><span class="line"></span><br><span class="line">[root@node06 software]# cp -abr plugins/ /opt/sxt/es/elasticsearch-2.2.1/</span><br><span class="line"></span><br><span class="line">分发其他节点：</span><br><span class="line">scp -r ./elasticsearch-2.2.1/ sxt@node07:`pwd`</span><br><span class="line">scp -r ./elasticsearch-2.2.1/ sxt@node08:`pwd`</span><br><span class="line"></span><br><span class="line">修改配置文件</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">进入bin目录，启动脚本：</span><br><span class="line">[root@node06 bin]# ./elasticsearch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">--- 访问</span><br><span class="line">http://node04:9200/_plugin/head/</span><br></pre></td></tr></table></figure>

<p><img src="http://img.zwer.xyz/blog/20191027123338.png" alt></p>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>ElasticSearch 是不可以以 root 身份启动的，若以 root 身份启动后，启动会报错。然后删除 elasticSearch 安装目录下的 logs 文件夹及其子文件，切换到 elasticSearch 用户，重新启动。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@node04 bin]# ./elasticsearch</span><br><span class="line">Exception in thread <span class="string">"main"</span> java.lang.RuntimeException: don<span class="string">'t run elasticsearch as root.</span></span><br><span class="line"><span class="string">	at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:93)</span></span><br><span class="line"><span class="string">	at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:144)</span></span><br><span class="line"><span class="string">	at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:285)</span></span><br><span class="line"><span class="string">	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)</span></span><br><span class="line"><span class="string">Refer to the log for complete error details.</span></span><br></pre></td></tr></table></figure>

<h3 id="中文分词器"><a href="#中文分词器" class="headerlink" title="中文分词器"></a>中文分词器</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 下载 elasticsearch 对应版本的中文分词器</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 上传到 Linux 服务器上，并修改  plugin-descriptor.properties  文件</span><br><span class="line"><span class="meta">#</span> 将 es 的版本修改为当前安装 es  版本</span><br><span class="line">elasticsearch.version=2.2.1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 重新启动 es</span><br></pre></td></tr></table></figure>

<h2 id="REST"><a href="#REST" class="headerlink" title="REST"></a>REST</h2><blockquote>
<p>REST 英文解释为: Representational State Transfer,  中文解释为： 表面层状态转移<br>一种软件架构风格，而不是标准，只是提供了一组设计原则和约束条件。</p>
</blockquote>
<ul>
<li><p>它主要用于客户端和服务器交互类的软件。</p>
</li>
<li><p>基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。</p>
</li>
</ul>
<h3 id="REST-简介"><a href="#REST-简介" class="headerlink" title="REST 简介"></a>REST 简介</h3><p><img src="http://img.zwer.xyz/blog/20191027201056.png" alt></p>
<h3 id="REST-操作"><a href="#REST-操作" class="headerlink" title="REST 操作"></a>REST 操作</h3><p>REST的操作分为以下几种:</p>
<ul>
<li>GET：获取对象的当前状态；</li>
<li>PUT：改变对象的状态；</li>
<li>POST：创建对象；</li>
<li>DELETE：删除对象；</li>
<li>HEAD：获取头信息。</li>
</ul>
<h3 id="ES-内置的-REST-接口"><a href="#ES-内置的-REST-接口" class="headerlink" title="ES 内置的 REST 接口"></a>ES 内置的 REST 接口</h3><p><img src="http://img.zwer.xyz/blog/20191027201401.png" alt></p>
<h2 id="curl-命令"><a href="#curl-命令" class="headerlink" title="curl 命令"></a>curl 命令</h2><p>简单认为是可以在命令行下访问url的一个工具<br>curl是利用URL语法在命令行方式下工作的开源文件传输工具，使用curl可以简单实现常见的get/post请求。</p>
<h3 id="curl-使用"><a href="#curl-使用" class="headerlink" title="curl 使用"></a>curl 使用</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl  </span><br><span class="line">-X  指定http请求的方法   HEAD  GET POST  PUT DELETE</span><br><span class="line">-d   指定要传输的数据</span><br></pre></td></tr></table></figure>

<h3 id="ES-操作"><a href="#ES-操作" class="headerlink" title="ES 操作"></a>ES 操作</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">file</span><br><span class="line">segment（段，多个document组成）</span><br><span class="line">document（一条记录，一个对象实例）</span><br><span class="line">field（对象的属性）</span><br><span class="line">term（项，分词之后的词条）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> yes</span><br><span class="line">curl -XPUT http://192.168.133.6:9200/bjsxt/</span><br><span class="line"><span class="meta">#</span> yes </span><br><span class="line">curl -XDELETE http://192.168.133.6:9200/test2/</span><br><span class="line">curl -XDELETE http://192.168.133.6:9200/test3/</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>document：yes </span><br><span class="line">curl -XPOST http://192.168.133.6:9200/bjsxt/employee -d '</span><br><span class="line">&#123;</span><br><span class="line"> "first_name" : "bin",</span><br><span class="line"> "age" : 33,</span><br><span class="line"> "about" : "I love to go rock climbing",</span><br><span class="line"> "interests": [ "sports", "music" ]</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line">curl -XPOST http://node02:9200/szxy/employee -d '</span><br><span class="line">&#123;</span><br><span class="line"> "first_name" : "bin",</span><br><span class="line"> "age" : 33,</span><br><span class="line"> "about" : "I love to go rock climbing",</span><br><span class="line"> "interests": [ "sports", "music" ]</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line">curl -XPOST http://node02:9200/szxy/employee -d '</span><br><span class="line">&#123;</span><br><span class="line"> "first_name" : "gob bin",</span><br><span class="line"> "age" : 43,</span><br><span class="line"> "about" : "I love to go rock climbing",</span><br><span class="line"> "interests": [ "sports", "music" ]</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line">curl -XPOST http://192.168.133.6:9200/bjsxt/employee/2 -d '</span><br><span class="line">&#123;</span><br><span class="line"> "first_name" : "bin",</span><br><span class="line"> "age" : 45,</span><br><span class="line"> "about" : "I love to go rock climbing",</span><br><span class="line"> "interests": [ "sports", "music" ]</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>add field yes</span><br><span class="line"></span><br><span class="line">curl -XPOST http://192.168.133.6:9200/bjsxt/employee -d '</span><br><span class="line">&#123;</span><br><span class="line"> "first_name" : "pablo2",</span><br><span class="line"> "age" : 33,</span><br><span class="line"> "about" : "I love to go rock climbing",</span><br><span class="line"> "interests": [ "sports", "music" ],</span><br><span class="line"> "sex": "man"</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">curl -XPOST http://node02:9200/szxy/employee/1 -d '</span><br><span class="line">&#123;</span><br><span class="line"> "first_name" : "pablo2",</span><br><span class="line"> "age" : 35,</span><br><span class="line"> "about" : "I love to go rock climbing",</span><br><span class="line"> "interests": [ "sports", "music" ],</span><br><span class="line"> "sex": "man"</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">----------------------------------------</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>put：yes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">curl -XPUT http://node02:9200/szxy/employee/1 -d '</span><br><span class="line">&#123;</span><br><span class="line"> "first_name" : "pablo2",</span><br><span class="line"> "last_name" : "pang",</span><br><span class="line"> "age" : 42,</span><br><span class="line"> "about" : "I love to go rock climbing",</span><br><span class="line"> "interests": [ "sports", "music" ]</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line">curl -XPUT http://node02:9200/szxy/employee -d '</span><br><span class="line">&#123;</span><br><span class="line"> "first_name" : "god bin",</span><br><span class="line"> "last_name" : "bin",</span><br><span class="line"> "age" : 45,</span><br><span class="line"> "about" : "I love to go rock climbing",</span><br><span class="line"> "interests": [ "sports", "music" ]</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">curl -XPUT http://node02:9200/szxy/employee/2 -d '</span><br><span class="line">&#123;</span><br><span class="line"> "first_name" : "god bin",</span><br><span class="line"> "last_name" : "bin",</span><br><span class="line"> "age" : 45,</span><br><span class="line"> "about" : "I love to go rock climbing",</span><br><span class="line"> "interests": [ "sports", "music" ]</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line">curl -XPUT http://192.168.133.6:9200/bjsxt/employee/1 -d '</span><br><span class="line">&#123;</span><br><span class="line"> "first_name" : "god bin",</span><br><span class="line"> "last_name" : "pang",</span><br><span class="line"> "age" : 40,</span><br><span class="line"> "about" : "I love to go rock climbing",</span><br><span class="line"> "interests": [ "sports", "music" ]</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>根据document的id来获取数据：(without pretty)</span><br><span class="line">curl -XGET http://node02:9200/bjsxt/employee/1?pretty</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>根据field来查询数据：</span><br><span class="line">curl -XGET http://node02:9200/szxy/employee/_search?q=first_name="bin"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>根据field来查询数据：match</span><br><span class="line">curl -XGET http://node02:9200/szxy/employee/_search?pretty -d '</span><br><span class="line">&#123;</span><br><span class="line"> "query":</span><br><span class="line">  &#123;"match":</span><br><span class="line">   &#123;"first_name":"bin"&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>对多个field发起查询：multi_match</span><br><span class="line">curl -XGET http://node02:9200/szxy/employee/_search?pretty -d '</span><br><span class="line">&#123;</span><br><span class="line"> "query":</span><br><span class="line">  &#123;"multi_match":</span><br><span class="line">   &#123;</span><br><span class="line">    "query":"bin",</span><br><span class="line">    "fields":["last_name","first_name"],</span><br><span class="line">    "operator":"and"</span><br><span class="line">   &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>多个term对多个field发起查询:bool（boolean） </span><br><span class="line"><span class="meta">#</span> 组合查询，must，must_not,should </span><br><span class="line"><span class="meta">#</span>  must + must : 交集</span><br><span class="line"><span class="meta">#</span>  must +must_not ：差集</span><br><span class="line"><span class="meta">#</span>  should+should  : 并集</span><br><span class="line"></span><br><span class="line">curl -XGET http://node02:9200/szxy/employee/_search?pretty -d '</span><br><span class="line">&#123;</span><br><span class="line"> "query":</span><br><span class="line">  &#123;"bool" :</span><br><span class="line">   &#123;</span><br><span class="line">    "must" : </span><br><span class="line">     &#123;"match":</span><br><span class="line">      &#123;"first_name":"bin"&#125;</span><br><span class="line">     &#125;,</span><br><span class="line">    "must" : </span><br><span class="line">     &#123;"match":</span><br><span class="line">      &#123;"age":33&#125;</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line">curl -XGET http://192.168.133.6:9200/bjsxt/employee/_search?pretty -d '</span><br><span class="line">&#123;</span><br><span class="line"> "query":</span><br><span class="line">  &#123;"bool" :</span><br><span class="line">   &#123;</span><br><span class="line">    "must" : </span><br><span class="line">     &#123;"match":</span><br><span class="line">      &#123;"first_name":"bin"&#125;</span><br><span class="line">     &#125;,</span><br><span class="line">    "must_not" : </span><br><span class="line">     &#123;"match":</span><br><span class="line">      &#123;"age":33&#125;</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">curl -XGET http://192.168.133.6:9200/bjsxt/employee/_search?pretty -d '</span><br><span class="line">&#123;</span><br><span class="line"> "query":</span><br><span class="line">  &#123;"bool" :</span><br><span class="line">   &#123;</span><br><span class="line">    "must_not" : </span><br><span class="line">     &#123;"match":</span><br><span class="line">      &#123;"first_name":"bin"&#125;</span><br><span class="line">     &#125;,</span><br><span class="line">    "must_not" : </span><br><span class="line">     &#123;"match":</span><br><span class="line">      &#123;"age":33&#125;</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>#查询first_name=bin的，或者年龄在20岁到33岁之间的</span><br><span class="line"></span><br><span class="line">curl -XGET http://192.168.133.6:9200/bjsxt/employee/_search -d '</span><br><span class="line">&#123;</span><br><span class="line"> "query":</span><br><span class="line">  &#123;"bool" :</span><br><span class="line">   &#123;</span><br><span class="line">   "must" :</span><br><span class="line">    &#123;"term" : </span><br><span class="line">     &#123; "first_name" : "bin" &#125;</span><br><span class="line">    &#125;</span><br><span class="line">   ,</span><br><span class="line">   "must_not" : </span><br><span class="line">    &#123;"range":</span><br><span class="line">     &#123;"age" : &#123; "from" : 20, "to" : 33 &#125;</span><br><span class="line">    &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>修改配置</span><br><span class="line">curl -XPUT 'http://192.168.133.6:9200/test2/' -d'&#123;"settings":&#123;"number_of_replicas":2&#125;&#125;'</span><br><span class="line"></span><br><span class="line">curl -XPUT 'http://192.168.133.6:9200/test3/' -d'&#123;"settings":&#123;"number_of_shards":3,"number_of_replicas":3&#125;&#125;'</span><br><span class="line"></span><br><span class="line">curl -XPUT 'http://192.168.133.6:9200/test4/' -d'&#123;"settings":&#123;"number_of_shards":6,"number_of_replicas":4&#125;&#125;'</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">curl -XPOST http://192.168.9.11:9200/bjsxt/person/_mapping -d'</span><br><span class="line">&#123;</span><br><span class="line">    "person": &#123;</span><br><span class="line">        "properties": &#123;</span><br><span class="line">            "content": &#123;</span><br><span class="line">                "type": "string",</span><br><span class="line">                "store": "no",</span><br><span class="line">                "term_vector": "with_positions_offsets",</span><br><span class="line">                "analyzer": "ik_max_word",</span><br><span class="line">                "search_analyzer": "ik_max_word",</span><br><span class="line">                "include_in_all": "true",</span><br><span class="line">                "boost": 8</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;'</span><br></pre></td></tr></table></figure>

<h2 id="ES-API操作"><a href="#ES-API操作" class="headerlink" title="ES API操作"></a>ES API操作</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestES</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line">	Client client;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Before</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">conn</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line"></span><br><span class="line">		Settings settings = Settings.settingsBuilder()</span><br><span class="line">		        .put(<span class="string">"cluster.name"</span>, <span class="string">"es-cluster"</span>).build();</span><br><span class="line">		client = TransportClient.builder().settings(settings).build()</span><br><span class="line">		        .addTransportAddress(<span class="keyword">new</span> InetSocketTransportAddress(InetAddress.getByName(<span class="string">"node02"</span>), <span class="number">9300</span>))</span><br><span class="line">		        .addTransportAddress(<span class="keyword">new</span> InetSocketTransportAddress(InetAddress.getByName(<span class="string">"node03"</span>), <span class="number">9300</span>))</span><br><span class="line">		        .addTransportAddress(<span class="keyword">new</span> InetSocketTransportAddress(InetAddress.getByName(<span class="string">"node04"</span>), <span class="number">9300</span>));</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@After</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span>&#123;</span><br><span class="line">		client.close();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test01</span><span class="params">()</span></span>&#123;</span><br><span class="line">		</span><br><span class="line">		IndicesExistsResponse resp = client.admin().indices().prepareExists(<span class="string">"javatest"</span>).execute().actionGet();</span><br><span class="line">		<span class="keyword">if</span>(resp.isExists())&#123;</span><br><span class="line">			System.err.println(<span class="string">"index is exist..."</span>);</span><br><span class="line">			client.admin().indices().prepareDelete(<span class="string">"javatest"</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		Map&lt;String, Object&gt; sets = <span class="keyword">new</span> HashMap&lt;String,Object&gt;();</span><br><span class="line">		sets.put(<span class="string">"number_of_replicas"</span>, <span class="number">2</span>);</span><br><span class="line">		client.admin().indices().prepareCreate(<span class="string">"javatest"</span>).setSettings(sets).execute().actionGet();</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test02</span><span class="params">()</span></span>&#123;</span><br><span class="line">		</span><br><span class="line">		Map&lt;String, Object&gt; data = <span class="keyword">new</span> HashMap&lt;String,Object&gt;();</span><br><span class="line">		data.put(<span class="string">"name"</span>, <span class="string">"bjsxt"</span>);</span><br><span class="line">		data.put(<span class="string">"content"</span>, <span class="string">"hadoop"</span>);</span><br><span class="line">		data.put(<span class="string">"size"</span>, <span class="number">10086</span>);</span><br><span class="line">		</span><br><span class="line">		IndexResponse resp = client.prepareIndex(<span class="string">"javatest"</span>,<span class="string">"testfiled"</span>).setSource(data).execute().actionGet();</span><br><span class="line">		System.out.println(resp.getId());</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test03</span><span class="params">()</span></span>&#123;</span><br><span class="line">		</span><br><span class="line">		QueryBuilder q =  <span class="keyword">new</span> MatchQueryBuilder(<span class="string">"content"</span>, <span class="string">"hadoop"</span>);</span><br><span class="line">		SearchResponse resp = client.prepareSearch(<span class="string">"javatest"</span>)</span><br><span class="line">									.setTypes(<span class="string">"testfiled"</span>)</span><br><span class="line">									.addHighlightedField(<span class="string">"content"</span>)</span><br><span class="line">									.setHighlighterPreTags(<span class="string">"&lt;font color=red&gt;"</span>)</span><br><span class="line">									.setHighlighterPostTags(<span class="string">"&lt;/font&gt;"</span>)</span><br><span class="line">									.setQuery(q)</span><br><span class="line">									.setFrom(<span class="number">1</span>)</span><br><span class="line">									.setSize(<span class="number">2</span>)</span><br><span class="line">									.execute()</span><br><span class="line">									.actionGet();</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		SearchHits hits = resp.getHits();</span><br><span class="line">		System.out.println(hits.getTotalHits());</span><br><span class="line">		<span class="keyword">for</span> (SearchHit hit : hits) &#123;</span><br><span class="line">			System.out.println(hit.getSourceAsString());</span><br><span class="line">			System.out.println(hit.getSource().get(<span class="string">"name"</span>));</span><br><span class="line">			System.out.println(hit.getHighlightFields().get(<span class="string">"content"</span>).getFragments()[<span class="number">0</span>]);</span><br><span class="line">			</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://zwer.xyz/2019/10/25/20191025 Zookeeper/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zwer">
      <meta itemprop="description" content="记录学习的日常">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zwer 的博客空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/10/25/20191025 Zookeeper/" class="post-title-link" itemprop="url">Zookeeper</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-10-25 00:00:00" itemprop="dateCreated datePublished" datetime="2019-10-25T00:00:00+08:00">2019-10-25</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-27 09:46:08" itemprop="dateModified" datetime="2019-10-27T09:46:08+08:00">2019-10-27</time>
              </span>
            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h2 id="paxos-小岛的故事"><a href="#paxos-小岛的故事" class="headerlink" title="paxos 小岛的故事"></a>paxos 小岛的故事</h2><p><strong>组成：</strong></p>
<ul>
<li>议员： 管理小岛</li>
<li>议员记事本： 记录处理的草案的编号，初始当前编号为 0。</li>
<li>草案 (提议)： 由单个议员发起草案，草案的编号必须大于议员记事本上记录的编号，否则不予处理</li>
<li>法令： 由单个议员发起，需要有半数以上议员们同意，才可生效</li>
</ul>
<p><strong>过程：</strong></p>
<p>​    比方说，该小岛有三个议员，开始的时候，三个议员a、b、c手中记事本记录草案的编号都是 0 。议员 a 提出草案工业用电 2 元/度 ，提出的草案编号为 1，议员 a 自己的记事本的当前编号设置为 1 ，将该草案告诉其他议员 b、c。议员 b、c 接收到该提议后，首先查看自己记事本的当前编号为 0 ，可以处理该草案，处理（赞成或反对）结束后将自己记事本的当前编号设置为 1 ，最后若赞成草案的票数大于半数，则该草案通过，否则不通过。</p>
<p><strong>对应关系：</strong></p>
<ul>
<li>小岛(Island)——ZK Server Cluster </li>
<li>议员(Senator)——ZK Serverabout:reader?url=<a href="https://www.douban.com/note/208430424/" target="_blank" rel="noopener">https://www.douban.com/note/208430424/</a> </li>
<li>提议(Proposal)——ZNode Change(Create/Delete/SetData…) </li>
<li>提议编号(PID)——Zxid(ZooKeeper Transaction Id) </li>
<li>正式法令——所有ZNode及其数据</li>
</ul>
<h2 id="Zookeeper-简介"><a href="#Zookeeper-简介" class="headerlink" title="Zookeeper 简介"></a>Zookeeper 简介</h2><blockquote>
<p>Zookeeper 是Google的Chubby一个开源的实现，是Hadoop的分布式协调服务包含一个简单的原语集，分布式应用程序可以基于它实现</p>
</blockquote>
<p>特点：</p>
<p><img src="http://img.zwer.xyz/blog/20191025215429.png" alt></p>
<h3 id="Zookeeper-集群"><a href="#Zookeeper-集群" class="headerlink" title="Zookeeper 集群"></a>Zookeeper 集群</h3><blockquote>
<p>zookeeper 集群的数量是单数的</p>
</blockquote>
<p><img src="http://img.zwer.xyz/blog/20191025212148.png" alt></p>
<p><img src="http://img.zwer.xyz/blog/20191025215327.png" alt></p>
<h3 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">目录结构</span><br><span class="line">    层次的，目录型结构，便于管理逻辑关系</span><br><span class="line">    节点znode而非文件file</span><br><span class="line">znode信息</span><br><span class="line">    包含最大1MB的数据信息</span><br><span class="line">    记录了zxid等元数据信息</span><br><span class="line">节点类型</span><br><span class="line">    znode有两种类型，瞬时的（ephemeral）和持久的（persistent）</span><br><span class="line">    znode支持序列SEQUENTIAL：leader</span><br><span class="line">    短暂znode的客户端会话结束时，zookeeper会将该短暂znode删除，短暂znode不可以有子节点</span><br><span class="line">    持久znode不依赖于客户端会话，只有当客户端明确要删除该持久znode时才会被删除</span><br><span class="line">    znode的类型在创建时确定并且之后不能再修改</span><br><span class="line">    有序znode节点被分配唯一单调递增的整数。</span><br><span class="line">            比如：客户端创建有序znode，路径为/task/task-，则zookeeper为其分配序号1，并追加到znode节点：</span><br><span class="line">    /task/task-1。有序znode节点唯一，同时也可根据该序号查看znode创建顺序。</span><br><span class="line">    znode有四种形式的目录节点</span><br><span class="line">    PERSISTENT</span><br><span class="line">    EPHEMERAL</span><br><span class="line">    PERSISTENT_SEQUENTIAL</span><br><span class="line">    EPHEMERAL_SEQUENTIAL</span><br></pre></td></tr></table></figure>

<p><img src="http://img.zwer.xyz/blog/20191025215641.png" alt></p>
<h3 id="事件监听"><a href="#事件监听" class="headerlink" title="事件监听"></a>事件监听</h3><ul>
<li><p><strong>基于客户端轮询机制</strong></p>
<p>缺陷：客户端轮询指定节点下的数据，通过网络轮询，代价很大</p>
<p><img src="http://img.zwer.xyz/blog/20191025220242.png" alt></p>
</li>
<li><p><strong>基于事件监听机制</strong></p>
<p>客户端向 ZooKeeper 注册需要接收通知的 znode，通过对 znode 设置监视点（watch）来接收通知。</p>
<p>监视点是一个<strong>单次触发</strong>的操作，意即监视点会触发一个通知。</p>
<p>为了接收多个通知，客户端必须在每次通知后设置一个新的监视点。</p>
</li>
</ul>
<p><img src="http://img.zwer.xyz/blog/20191025220536.png" alt></p>
<ul>
<li><strong>事件监听 Watcher</strong><br>  Watcher 在 ZooKeeper 是一个核心功能，Watcher 可以监控目录节点的数据变化以及子目录的变化，一旦这些状态发生变化，服务器就会通知所有设置在这个目录节点上的Watcher，从而每个客户端都很快知道它所关注的目录节点的状态发生变化，而做出相应的反应</li>
</ul>
<p>可以设置观察的操作：<code>exists</code>,<code>getChildren</code>,<code>getData</code><br>    可以触发观察的操作：<code>create</code>,<code>delete</code>,<code>setData</code></p>
<pre><code>回调client方法业务核心代码在哪里？ `client`</code></pre><h3 id="节点模式-原子广播"><a href="#节点模式-原子广播" class="headerlink" title="节点模式-原子广播"></a>节点模式-原子广播</h3><p>Zookeeper的核心是<strong>原子广播</strong>，这个机制保证了各个server之间的同步。实现这个机制的协议叫做Zab协议。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Zab协议有两种模式：</span><br><span class="line">恢复模式</span><br><span class="line">广播模式</span><br><span class="line">当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，</span><br><span class="line">当领导者被选举出来，且大多数server的完成了和leader的状态同步以后，恢复模式就结束了。</span><br><span class="line">状态同步保证了leader和server具有相同的系统状态</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>恢复模式</th>
<th>广播模式</th>
</tr>
</thead>
<tbody><tr>
<td>无主，无服务</td>
<td>主从模式</td>
</tr>
<tr>
<td>选举leader</td>
<td>leader维护事物的唯一和有序性</td>
</tr>
<tr>
<td></td>
<td>队列机制</td>
</tr>
</tbody></table>
<p>下面详细介绍广播模式和恢复模式</p>
<ul>
<li><p><strong>广播模式</strong></p>
<p>广播模式需要保证 proposal 被按顺序处理，因此zk采用了递增的事务id号(zxid)来保证。</p>
<p>所有的提议 (proposal) 都在被提出的时候加上了 zxid。</p>
<p>实现中 zxid 是一个 64 为的数字，它高32位是 epoch 用来标识 leader 关系是否改变，每次一个leader被选出来，它都会有一个新的epoch，低32位是个递增计数。</p>
<p>两阶段提交：</p>
<p><img src="http://img.zwer.xyz/blog/20191025221442.png" alt></p>
</li>
<li><p><strong>恢复模式-选举</strong></p>
<p>1，判定（zxid，myid）；2，投票传递</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">zxid   &lt;从paxos 到 zookeeper&gt;</span><br><span class="line">myid</span><br><span class="line"></span><br><span class="line">首先选举zxid最大的，如果zxid相同，则选举myid最大的</span><br></pre></td></tr></table></figure>


</li>
</ul>
<p>  <strong>Leader 选举</strong></p>
<p>  选举过程耗时在 200ms 之内，一般情况下zookeeper恢复服务时间间隔不超过 200ms</p>
<p>  server Si (myid,zxid)</p>
<p>  <img src="http://img.zwer.xyz/blog/20191025222248.png" alt></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>  <img src="http://img.zwer.xyz/blog/20191025222727.png" alt></p>
<h2 id="Zookeeper-安装与配置"><a href="#Zookeeper-安装与配置" class="headerlink" title="Zookeeper 安装与配置"></a>Zookeeper 安装与配置</h2><ul>
<li><p>安装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">1.3节点 java 安装 </span><br><span class="line"></span><br><span class="line">2.所有集群节点创建目录: mkdir opt/sxt  </span><br><span class="line"></span><br><span class="line">3.zk压缩包解压在其他路径下:：</span><br><span class="line">	#	tar xf zookeeper-3.4.6.tar.gz -C /opt/sxt/</span><br><span class="line">	</span><br><span class="line">4.进入conf目录，拷贝zoo_sample.cfg zoo.cfg 并配置</span><br><span class="line">   dataDir，集群节点。</span><br><span class="line">5.单节点配置环境变量、并分发 ZOOKEEPER_PREFIX，共享模式读取profile </span><br><span class="line">6. 共享创建 /var/sxt/zk目录，进入各自目录 分别输出1,2，3 至文件 myid</span><br><span class="line">	echo 1 &gt; /var/sxt/zk/myid</span><br><span class="line">	...</span><br><span class="line">7. 共享启动zkServer.sh start 集群</span><br><span class="line">8.启动客户端 help命令查看</span><br></pre></td></tr></table></figure>



</li>
</ul>
<ul>
<li><p>配置</p>
<p>  在conf目录下创建一个配置文件 zoo.cfg，</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tickTime=2000  </span><br><span class="line">dataDir=/Users/zdandljb/zookeeper/data</span><br><span class="line">dataLogDir=/Users/zdandljb/zookeeper/dataLog</span><br><span class="line">clientPort=2181</span><br><span class="line">initLimit=5</span><br><span class="line">syncLimit=2</span><br><span class="line">server.1=server1:2888:3888</span><br><span class="line">server.2=server2:2888:3888</span><br><span class="line">server.3=server3:2888:3888  observer（表示对应节点不参与投票）</span><br></pre></td></tr></table></figure>

<p>  创建myid文件</p>
<p>  tickTime：发送心跳的间隔时间，单位：毫秒<br>  dataDir：zookeeper保存数据的目录。<br>  clientPort：客户端连接 Zookeeper 服务器的端口，Zookeeper  会监听这个端口，接受客户端的访问请求。<br>  initLimit： 这个配置项是用来配置 Zookeeper 接受客户端（这里所说的客户端不是用户连接Zookeeper服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader的Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5 个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 5<em>2000=10秒<br>  syncLimit：这个配置项标识  Leader 与 Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个tickTime 的时间长度，总的时间长度就是 2</em>2000=4 秒<br>  server.A=B：C：D：其 中 A 是一个数字，表示这个是第几号服务器；B 是这个服务器的ip地址；C 表示的是这个服务器与集群中的Leader服务器交换信息的端口；D表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于B都是一样，所以不同的Zookeeper实例通信端口号不能一样，所以要给它们分配不同的端口号。</p>
</li>
</ul>
<h2 id="Zookeeper-操作"><a href="#Zookeeper-操作" class="headerlink" title="Zookeeper 操作"></a>Zookeeper 操作</h2><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><ul>
<li><p><code>ls</code> 命令</p>
<table>
<thead>
<tr>
<th>功能</th>
<th>ls 命令获取路径下的节点信息(所有子节点),注意路径为绝对路径</th>
</tr>
</thead>
<tbody><tr>
<td>作用</td>
<td><code>ls  /zookeeper</code></td>
</tr>
</tbody></table>
</li>
<li><p><code>create</code> 命令</p>
<table>
<thead>
<tr>
<th>功能</th>
<th>创建 zookeeper 下的节点</th>
</tr>
</thead>
<tbody><tr>
<td><code>create /path null</code></td>
<td>创建 zookeeper 下的空节点</td>
</tr>
<tr>
<td><code>create -s /path data</code></td>
<td>创建 zookeeper 下的持续节点</td>
</tr>
<tr>
<td><code>craete -e  /path data</code></td>
<td>创建 zookeeper 下的瞬时节点后<br>即与 zookeeper 断开连接后，创建的瞬时节点会自动移除。</td>
</tr>
</tbody></table>
</li>
<li><p><code>get</code> 命令</p>
<table>
<thead>
<tr>
<th>功能</th>
<th>获取 zookeeper 下节点中的信息</th>
</tr>
</thead>
<tbody><tr>
<td><code>get  /path</code></td>
<td>获取指定的节点信息</td>
</tr>
</tbody></table>
</li>
<li><p><code>delete 命令</code></p>
<table>
<thead>
<tr>
<th>功能</th>
<th>删除 Zookeeper 中节点</th>
</tr>
</thead>
<tbody><tr>
<td><code>delete /path</code></td>
<td>删除 <code>/path</code> 节点，注意 <code>/path</code> 下面必须没有子节点，不然不能删除</td>
</tr>
</tbody></table>
</li>
</ul>
<h2 id="Zookeeper-API-使用"><a href="#Zookeeper-API-使用" class="headerlink" title="Zookeeper API  使用"></a>Zookeeper API  使用</h2><p>使用  RMI （Remote Method Innvocation），远程调用方法。</p>
<p>使用 zookeeper 作为注册中心</p>
<h3 id="RMI-案例"><a href="#RMI-案例" class="headerlink" title="RMI 案例"></a>RMI 案例</h3><h4 id="服务提供端"><a href="#服务提供端" class="headerlink" title="服务提供端"></a>服务提供端</h4><ul>
<li><p><strong>ServiceProvider.java</strong>：连接 zk，发布服务到 zk 上</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ServiceProvider</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(ServiceProvider.class);</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 用于等待 SyncConnected 事件触发后继续执行当前线程</span></span><br><span class="line">    <span class="keyword">private</span> CountDownLatch latch = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 发布 RMI 服务并注册 RMI 地址到 ZooKeeper 中</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">publish</span><span class="params">(Remote remote, String host, <span class="keyword">int</span> port)</span> </span>&#123;</span><br><span class="line">        String url = publishService(remote, host, port); <span class="comment">// 发布 RMI 服务并返回 RMI 地址</span></span><br><span class="line">        <span class="keyword">if</span> (url != <span class="keyword">null</span>) &#123;</span><br><span class="line">            ZooKeeper zk = connectServer(); <span class="comment">// 连接 ZooKeeper 服务器并获取 ZooKeeper 对象</span></span><br><span class="line">            <span class="keyword">if</span> (zk != <span class="keyword">null</span>) &#123;</span><br><span class="line">                createNode(zk, url); <span class="comment">// 创建 ZNode 并将 RMI 地址放入 ZNode 上</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 发布 RMI 服务</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> String <span class="title">publishService</span><span class="params">(Remote remote, String host, <span class="keyword">int</span> port)</span> </span>&#123;</span><br><span class="line">        String url = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// rmi://localhost:1099/demo.zookeeper.remoting.server.HelloServiceImpl</span></span><br><span class="line">            url = String.format(<span class="string">"rmi://%s:%d/%s"</span>, host, port, remote.getClass().getName());</span><br><span class="line">            LocateRegistry.createRegistry(port);</span><br><span class="line">            Naming.rebind(url, remote);</span><br><span class="line">            LOGGER.debug(<span class="string">"publish rmi service (url: &#123;&#125;)"</span>, url);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (RemoteException | MalformedURLException e) &#123;</span><br><span class="line">            LOGGER.error(<span class="string">""</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> url;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 连接 ZooKeeper 服务器</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> ZooKeeper <span class="title">connectServer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ZooKeeper zk = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            zk = <span class="keyword">new</span> ZooKeeper(Constant.ZK_CONNECTION_STRING, Constant.ZK_SESSION_TIMEOUT, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">if</span> (event.getState() == Event.KeeperState.SyncConnected) &#123;</span><br><span class="line">                        latch.countDown(); <span class="comment">// 唤醒当前正在执行的线程</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            latch.await(); <span class="comment">// 使当前线程处于等待状态</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException | InterruptedException e) &#123;</span><br><span class="line">            LOGGER.error(<span class="string">""</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> zk;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 创建 ZNode</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">createNode</span><span class="params">(ZooKeeper zk, String url)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">byte</span>[] data = url.getBytes();</span><br><span class="line">            <span class="comment">// /registry/provider</span></span><br><span class="line">            <span class="comment">// /registry/provider000000003</span></span><br><span class="line">            String path = zk.create(Constant.ZK_PROVIDER_PATH, data, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL); <span class="comment">// 创建一个临时性且有序的 ZNode</span></span><br><span class="line">            LOGGER.debug(<span class="string">"create zookeeper node (&#123;&#125; =&gt; &#123;&#125;)"</span>, path, url);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException | InterruptedException e) &#123;</span><br><span class="line">            LOGGER.error(<span class="string">""</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>HelloServiceImpl.java</strong>：服务具体实现类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloServiceImpl</span> <span class="keyword">extends</span> <span class="title">UnicastRemoteObject</span> <span class="keyword">implements</span> <span class="title">HelloService</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="title">HelloServiceImpl</span><span class="params">()</span> <span class="keyword">throws</span> RemoteException </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">sayHello</span><span class="params">(String name)</span> <span class="keyword">throws</span> RemoteException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> String.format(<span class="string">"Hello %s"</span>, name);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Server.java</strong> ：服务提供者 </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Server</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String host = <span class="string">"localhost"</span>;</span><br><span class="line">        <span class="keyword">int</span> port = Integer.parseInt(<span class="string">"11117"</span>);</span><br><span class="line">        ServiceProvider provider = <span class="keyword">new</span> ServiceProvider();</span><br><span class="line"> </span><br><span class="line">        HelloService helloService = <span class="keyword">new</span> HelloServiceImpl();</span><br><span class="line">        provider.publish(helloService, host, port);</span><br><span class="line"> </span><br><span class="line">        Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="服务消费端"><a href="#服务消费端" class="headerlink" title="服务消费端"></a>服务消费端</h4><ul>
<li><p><strong>ServiceConsumer.java</strong>:连接 zk ，获取服务列表</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ServiceConsumer</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(ServiceConsumer.class);</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 用于等待 SyncConnected 事件触发后继续执行当前线程</span></span><br><span class="line">    <span class="keyword">private</span> CountDownLatch latch = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 定义一个 volatile 成员变量，用于保存最新的 RMI 地址（考虑到该变量或许会被其它线程所修改，一旦修改后，该变量的值会影响到所有线程）</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> List&lt;String&gt; urlList = <span class="keyword">new</span> ArrayList&lt;&gt;(); </span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 构造器</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ServiceConsumer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ZooKeeper zk = connectServer(); <span class="comment">// 连接 ZooKeeper 服务器并获取 ZooKeeper 对象</span></span><br><span class="line">        <span class="keyword">if</span> (zk != <span class="keyword">null</span>) &#123;</span><br><span class="line">            watchNode(zk); <span class="comment">// 观察 /registry 节点的所有子节点并更新 urlList 成员变量</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 查找 RMI 服务</span></span><br><span class="line">    <span class="keyword">public</span> &lt;T extends Remote&gt; <span class="function">T <span class="title">lookup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        T service = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">int</span> size = urlList.size();</span><br><span class="line">        <span class="keyword">if</span> (size &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            String url;</span><br><span class="line">            <span class="keyword">if</span> (size == <span class="number">1</span>) &#123;</span><br><span class="line">                url = urlList.get(<span class="number">0</span>); <span class="comment">// 若 urlList 中只有一个元素，则直接获取该元素</span></span><br><span class="line">                LOGGER.debug(<span class="string">"using only url: &#123;&#125;"</span>, url);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                url = urlList.get(ThreadLocalRandom.current().nextInt(size)); <span class="comment">// 若 urlList 中存在多个元素，则随机获取一个元素</span></span><br><span class="line">                LOGGER.debug(<span class="string">"using random url: &#123;&#125;"</span>, url);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(url);</span><br><span class="line">            service = lookupService(url); <span class="comment">// 从 JNDI 中查找 RMI 服务</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> service;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 连接 ZooKeeper 服务器</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> ZooKeeper <span class="title">connectServer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ZooKeeper zk = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            zk = <span class="keyword">new</span> ZooKeeper(Constant.ZK_CONNECTION_STRING, Constant.ZK_SESSION_TIMEOUT, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">if</span> (event.getState() == Event.KeeperState.SyncConnected) &#123;</span><br><span class="line">                        latch.countDown(); <span class="comment">// 唤醒当前正在执行的线程</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            latch.await(); <span class="comment">// 使当前线程处于等待状态</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException | InterruptedException e) &#123;</span><br><span class="line">            LOGGER.error(<span class="string">""</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> zk;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 观察 /registry 节点下所有子节点是否有变化</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">watchNode</span><span class="params">(<span class="keyword">final</span> ZooKeeper zk)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            List&lt;String&gt; nodeList = zk.getChildren(Constant.ZK_REGISTRY_PATH, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">if</span> (event.getType() == Event.EventType.NodeChildrenChanged) &#123;</span><br><span class="line">                        watchNode(zk); <span class="comment">// 若子节点有变化，则重新调用该方法（为了获取最新子节点中的数据）</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            List&lt;String&gt; dataList = <span class="keyword">new</span> ArrayList&lt;&gt;(); <span class="comment">// 用于存放 /registry 所有子节点中的数据</span></span><br><span class="line">            <span class="keyword">for</span> (String node : nodeList) &#123;     <span class="comment">//   /registry/provider00000000003</span></span><br><span class="line">                <span class="keyword">byte</span>[] data = zk.getData(Constant.ZK_REGISTRY_PATH + <span class="string">"/"</span> + node, <span class="keyword">false</span>, <span class="keyword">null</span>); <span class="comment">// 获取 /registry 的子节点中的数据</span></span><br><span class="line">                dataList.add(<span class="keyword">new</span> String(data));</span><br><span class="line">            &#125;</span><br><span class="line">            LOGGER.debug(<span class="string">"node data: &#123;&#125;"</span>, dataList);</span><br><span class="line">            urlList = dataList; <span class="comment">// 更新最新的 RMI 地址</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (KeeperException | InterruptedException e) &#123;</span><br><span class="line">            LOGGER.error(<span class="string">""</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 在 JNDI 中查找 RMI 远程服务对象</span></span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">    <span class="keyword">private</span> &lt;T&gt; <span class="function">T <span class="title">lookupService</span><span class="params">(String url)</span> </span>&#123;</span><br><span class="line">        T remote = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            remote = (T) Naming.lookup(url);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NotBoundException | MalformedURLException | RemoteException e) &#123;</span><br><span class="line">            <span class="keyword">if</span> (e <span class="keyword">instanceof</span> ConnectException) &#123;</span><br><span class="line">                <span class="comment">// 若连接中断，则使用 urlList 中第一个 RMI 地址来查找（这是一种简单的重试方式，确保不会抛出异常）</span></span><br><span class="line">                LOGGER.error(<span class="string">"ConnectException -&gt; url: &#123;&#125;"</span>, url);</span><br><span class="line">                <span class="keyword">if</span> (urlList.size() != <span class="number">0</span>) &#123;</span><br><span class="line">                    url = urlList.get(<span class="number">0</span>);</span><br><span class="line">                    <span class="keyword">return</span> lookupService(url);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            LOGGER.error(<span class="string">""</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> remote;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>RmiClient.java</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        ServiceConsumer consumer = <span class="keyword">new</span> ServiceConsumer();</span><br><span class="line">        <span class="comment">// zookeeper测试</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            HelloService helloService = consumer.lookup();</span><br><span class="line">            String result = helloService.sayHello(<span class="string">"Jack"</span>);</span><br><span class="line">            System.out.println(result);</span><br><span class="line">            Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="共有"><a href="#共有" class="headerlink" title="共有"></a>共有</h4><ul>
<li><p><strong>HelloService.java</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">HelloService</span> <span class="keyword">extends</span> <span class="title">Remote</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="function">String <span class="title">sayHello</span><span class="params">(String name)</span> <span class="keyword">throws</span> RemoteException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Constant.java</strong>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Constant</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	String ZK_CONNECTION_STRING = <span class="string">"node02:2181,node03:2181,node04:2181"</span>;</span><br><span class="line">	<span class="keyword">int</span> ZK_SESSION_TIMEOUT = <span class="number">5000</span>;</span><br><span class="line">	String ZK_REGISTRY_PATH = <span class="string">"/registry"</span>;</span><br><span class="line">	String ZK_PROVIDER_PATH = ZK_REGISTRY_PATH + <span class="string">"/provider"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="Socket-案例"><a href="#Socket-案例" class="headerlink" title="Socket 案例"></a>Socket 案例</h3><p>Socket 服务端向 zk 注册服务，Socket 客户端从 zk 获取服务列表，从而连接服务器</p>
<ul>
<li><p>Server.java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Server</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> ZooKeeper zk = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> String zkHost = <span class="string">"node02:2181,node03:2181,node04:2181"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> SESSION_OUT = <span class="number">3000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> CountDownLatch latch = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++)&#123;</span><br><span class="line">            Thread t = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        String host = <span class="string">"localhost"</span>;</span><br><span class="line">                        <span class="comment">/*Random random = new Random();</span></span><br><span class="line"><span class="comment">                        String num = String.format("2%4d",random.nextInt(9999));*/</span></span><br><span class="line">                        <span class="keyword">int</span> port = (<span class="keyword">int</span>)((Math.random()*<span class="number">9</span>+<span class="number">1</span>)*<span class="number">10000</span>);</span><br><span class="line">                        String address = host + <span class="string">":"</span> + String.valueOf(port);</span><br><span class="line">                        <span class="comment">// 创建对象</span></span><br><span class="line">                        Server s = <span class="keyword">new</span> Server();</span><br><span class="line">                        <span class="comment">// 连接 zk 集群</span></span><br><span class="line">                        s.connectZk();</span><br><span class="line">                        <span class="comment">// 开启服务端</span></span><br><span class="line">                        ServerSocket server = <span class="keyword">new</span> ServerSocket(port);</span><br><span class="line">                        <span class="comment">// 注册服务</span></span><br><span class="line">                        s.registryService(address);</span><br><span class="line">                        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                            Socket client = server.accept();</span><br><span class="line">                            handleReq(client);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            t.start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 连接 zk 集群</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">connectZk</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        zk = <span class="keyword">new</span> ZooKeeper(zkHost, SESSION_OUT, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">if</span> (event.getState() == Event.KeeperState.SyncConnected) &#123;</span><br><span class="line">                    latch.countDown();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        latch.await();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 注册服务</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> address</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">registryService</span><span class="params">(String address)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String path = <span class="string">"/myRegistry/service"</span>;</span><br><span class="line">        zk.create(path,address.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 处理客户端请求</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> client</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">handleReq</span><span class="params">(Socket client)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        OutputStream os = client.getOutputStream();</span><br><span class="line">        OutputStreamWriter osw = <span class="keyword">new</span> OutputStreamWriter(os, <span class="string">"utf-8"</span>);</span><br><span class="line">        BufferedWriter writer = <span class="keyword">new</span> BufferedWriter(osw);</span><br><span class="line">        writer.write(<span class="string">"Hello Client"</span>);</span><br><span class="line">        writer.newLine();</span><br><span class="line">        writer.flush();</span><br><span class="line">        client.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Client.java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> ZooKeeper zk = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> String zkHost = <span class="string">"node02:2181,node03:2181,node04:2181"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> SESSION_OUT = <span class="number">3000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> CountDownLatch latch = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> List&lt;String&gt; urlList = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Socket client = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Client c = <span class="keyword">new</span> Client();</span><br><span class="line">        <span class="comment">// 连接 zk 集群</span></span><br><span class="line">        c.connectZk();</span><br><span class="line">        <span class="comment">// 获取注册服务列表</span></span><br><span class="line">        c.getRegistryList();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 连接服务器</span></span><br><span class="line">            c.connectServer();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  连接 zk 集群</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">connectZk</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            zk = <span class="keyword">new</span> ZooKeeper(zkHost, SESSION_OUT, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">if</span> (event.getState() == Event.KeeperState.SyncConnected) &#123;</span><br><span class="line">                        latch.countDown();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            latch.await();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取服务列表</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">getRegistryList</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        List&lt;String&gt; nodeList = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            nodeList = zk.getChildren(<span class="string">"/myRegistry"</span>, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">if</span> (event.getType() == Event.EventType.NodeChildrenChanged) &#123;</span><br><span class="line">                        System.out.println(<span class="string">"节点发生变化。。。"</span>);</span><br><span class="line">                        getRegistryList(); <span class="comment">// 调用自身方法</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            urlList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            <span class="keyword">for</span> (String node : nodeList) &#123;</span><br><span class="line">                <span class="keyword">byte</span>[] data = zk.getData(<span class="string">"/myRegistry/"</span> + node, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">                String url = <span class="keyword">new</span> String(data);</span><br><span class="line">                urlList.add(url);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 连接服务器</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">connectServer</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String url = <span class="keyword">null</span>;</span><br><span class="line">        String host = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.urlList.size() == <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">"没有可用的服务器...."</span>);</span><br><span class="line">            Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="keyword">this</span>.urlList.size() == <span class="number">1</span>) &#123;</span><br><span class="line">            url = <span class="keyword">this</span>.urlList.get(<span class="number">0</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            Random random = <span class="keyword">new</span> Random();</span><br><span class="line">            url = <span class="keyword">this</span>.urlList.get(random.nextInt(urlList.size()));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        host = url.substring(<span class="number">0</span>, url.indexOf(<span class="string">":"</span>));</span><br><span class="line">        <span class="keyword">int</span> port = Integer.valueOf(url.substring(url.indexOf(<span class="string">":"</span>) + <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">        client = <span class="keyword">new</span> Socket(host, port);</span><br><span class="line">        InputStream is = client.getInputStream();</span><br><span class="line">        InputStreamReader isr = <span class="keyword">new</span> InputStreamReader(is, <span class="string">"utf-8"</span>);</span><br><span class="line">        BufferedReader reader = <span class="keyword">new</span> BufferedReader(isr);</span><br><span class="line">        String line = reader.readLine();</span><br><span class="line">        System.out.println(host + <span class="string">":"</span> + port + <span class="string">"  服务器响应消息: "</span> + line);</span><br><span class="line">        Thread.sleep(<span class="number">2000</span>);</span><br><span class="line"></span><br><span class="line">        client.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

















</li>
</ul>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://zwer.xyz/2019/10/16/20191016 HBase/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zwer">
      <meta itemprop="description" content="记录学习的日常">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zwer 的博客空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/10/16/20191016 HBase/" class="post-title-link" itemprop="url">Untitled</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-10-16 00:00:00" itemprop="dateCreated datePublished" datetime="2019-10-16T00:00:00+08:00">2019-10-16</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-11-04 10:45:51" itemprop="dateModified" datetime="2019-11-04T10:45:51+08:00">2019-11-04</time>
              </span>
            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="HBase-简介"><a href="#HBase-简介" class="headerlink" title="HBase 简介"></a>HBase 简介</h2><blockquote>
<p>Hadoop Database，是一个高可靠性、高性能、<strong>面向列</strong>、可伸缩、实时读写的分布式<strong>数据库</strong></p>
</blockquote>
<p><strong>作用：</strong>主要用来存储非结构化和半结构化的松散数据（列存 NoSQL 数据库）</p>
<p>利用 Hadoop HDFS 作为其文件存储系统,</p>
<p>利用 Hadoop MapReduce 来处理 HBase 中的海量数据,</p>
<p>利用 Zookeeper 作为其分布式协同服务</p>
<ul>
<li><p>非关系型数据库知识面扩展</p>
<ul>
<li>Cassandra hbase mongodb </li>
<li>Couchdb，文件存储数据库</li>
<li>Neo4j非关系型图数据库</li>
</ul>
</li>
<li><p>HBase 官网地址：<a href="http://hbase.apache.org/" target="_blank" rel="noopener">http://hbase.apache.org/</a></p>
</li>
</ul>
<h3 id="Hadoop-生态系统"><a href="#Hadoop-生态系统" class="headerlink" title="Hadoop 生态系统"></a>Hadoop 生态系统</h3><p><img src="http://img.zwer.xyz/blog/20191016145209.png" alt></p>
<p><em>MapReduce 计算的数据来源：</em></p>
<ol>
<li>HDFS 或者其他文件系统 2.数据库（既可以是关系型数据也可以非关系型）</li>
</ol>
<p><em>Hive 和 HBase 的区别：</em></p>
<p> Hive 是数据仓库，HBase 是数据库。Hive 是用 SQL 方式处理数据，底层使用 MapReduce 计算框架</p>
<p><em>使用 MapReduce  注意：</em></p>
<ol>
<li>map 生成小文件  2. 数据倾斜</li>
</ol>
<h2 id="HBase-数据模型"><a href="#HBase-数据模型" class="headerlink" title="HBase 数据模型"></a>HBase 数据模型</h2><p><img src="http://img.zwer.xyz/blog/20191016162050.png" alt></p>
<ul>
<li><p><strong>ROW  KEY</strong>（ROW KEY 设计很重要）</p>
<p>决定一行数据，按照<strong>字典顺序</strong>排序的。Row key只能存储 64k 的字节数据</p>
</li>
<li><p><strong>Column Family 列族 &amp; qualifier列</strong></p>
<ol>
<li><p>HBase 表中的每个列都归属于某个列族，列族必须作为表模式(schema)定义的一部分预先给出。</p>
<p>如 create ‘test’, ‘course’；</p>
</li>
<li><p>列名以列族作为前缀，每个“列族”都可以有多个列成员(column)；</p>
<p>如course:math, course:english, 新的列族成员（列）可以随后按需、动态加入；</p>
</li>
<li><p>权限控制、存储以及调优都是在列族层面进行的；</p>
</li>
<li><p>HBase 把同一列族里面的数据存储在同一目录下，由几个文件保存。</p>
</li>
</ol>
</li>
<li><p><strong>Cell 单元格</strong></p>
<p>由行和列的坐标交叉决定；</p>
<p>单元格是有版本的；</p>
<p>单元格的内容是未解析的<em>字节数组</em>；</p>
<p>由<code>{row key， column( =&lt;family&gt; +&lt;qualifier&gt;)， version}</code> 唯一确定的单元。</p>
<p>cell中的数据是没有类型的，全部是<em>字节码形式存贮</em>。</p>
</li>
<li><p><strong>Timestamp 时间戳</strong></p>
<p>在 HBase 每个 cell 存储单元对同一份数据有多个版本，根据唯一的时间戳来区分每个版本之间的差异，不同版本的数据按照时间倒序排序，最新的数据版本排在最前面。</p>
<p>时间戳的类型是 64位整型。</p>
<p>时间戳可以由 HBase (在数据写入时自动)赋值，此时时间戳是精确到毫秒的当前系统时间。</p>
<p>时间戳也可以由客户显式赋值，如果应用程序要避免数据版本冲突，就必须自己生成具有唯一性的时间戳。</p>
</li>
<li><p><strong>HLog(WAL log)</strong></p>
<p>HLog 文件就是一个普通的 Hadoop Sequence File，Sequence File 的 Key 是 HLogKey 对象，HLogKey 中记录了写入数据的归属信息，除了 table 和 region 名字外，同时还包括 sequence number 和 timestamp，timestamp 是” 写入时间”，sequence number 的起始值为0，或者是最近一次存入文件系统中 sequence number。<br>HLog SequeceFile 的 Value 是 HBase 的 KeyValue 对象，即对应 HFile 中的 KeyValue。</p>
</li>
</ul>
<p>注：region：范围、地区</p>
<h2 id="HBase-架构"><a href="#HBase-架构" class="headerlink" title="HBase 架构"></a>HBase 架构</h2><h3 id="HBase-架构图"><a href="#HBase-架构图" class="headerlink" title="HBase 架构图"></a>HBase 架构图</h3><p><img src="http://img.zwer.xyz/blog/20191016162618.png" alt></p>
<h3 id="HBase-架构中各角色作用"><a href="#HBase-架构中各角色作用" class="headerlink" title="HBase 架构中各角色作用"></a>HBase 架构中各角色作用</h3><ul>
<li><p><strong>Client</strong><br>包含访问 HBase 的接口并维护 cache 来加快对 HBase 的访问</p>
</li>
<li><p><strong>Zookeeper</strong>（不仅可以做集群的高可用）<br>保证任何时候，集群中只有一个 master<br>存贮所有 Region 的寻址入口。<br>实时监控 Region server 的上线和下线信息。并实时通知 Master<br>存储 HBase 的 schema 和 table 元数据</p>
</li>
<li><p><strong>Master</strong><br>为 Region server 分配 region<br>负责 Region server 的负载均衡<br>发现失效的 Region server 并重新分配其上的 region<br>管理用户对 table 的增删改操作</p>
</li>
<li><p><strong>RegionServer</strong><br>Region server 维护 region，处理对这些 region 的 IO 请求<br>Region server 负责切分在运行过程中变得过大的 region</p>
</li>
<li><p><strong>Region</strong><br>HBase 自动把表水平划分成多个区域(region)，每个 region 会保存一个表里面某段<em>连续的数据</em>（按字典序）</p>
<p>每个表一开始只有一个 region，随着数据不断插入表，region 不断增大，当增大到一个阀值的时候，region就会等分会两个新的 region（裂变）</p>
<p>当 table 中的行不断增多，就会有越来越多的 region。这样一张完整的表被保存在多个 Regionserver 上。</p>
</li>
<li><p><strong>Memstore &amp; storefile</strong><br>一个 region 由多个 store 组成，一个 store 对应一个CF（列族）</p>
<p>store 包括位于内存中的 memstore 和位于磁盘的 storefile 。</p>
<p>写操作先写入memstore，当 memstore 中的数据达到某个阈值，hregionserver 会启动 flashcache 进程写</p>
<p>入 storefile，每次写入形成单独的一个 storefile。</p>
<p>当 storefile 文件的数量增长到一定阈值后，<strong>系统会进行合并（minor、major compaction）</strong>，在合并过程</p>
<p>中会进行版本合并和删除工作（majar），形成更大的 storefile。</p>
<p>当一个 region 所有 storefile的大小和数量超过一定阈值后，会把当前的 region 分割为两个，并由 hmaster</p>
<p>分配到相应的 regionserver 服务器，实现负载均衡。</p>
<p>客户端检索数据，先在 memstore 找，找不到再找 storefile（先找 cache 后找磁盘）</p>
</li>
<li><p><strong>Region补充：</strong></p>
<p>HRegion 是 HBase 中分布式存储和负载均衡的最小单元。</p>
<p>最小单元就表示不同的 HRegion 可以分布在不同的 HRegion server上。</p>
<p>HRegion 由一个或者多个 Store 组成，每个 store 保存一个 columns family。</p>
<p>每个 Strore 又由一个 memStore 和 0 至多个 StoreFile 组成。</p>
<p>如图：StoreFile 以 HFile 格式保存在 HDFS上。</p>
<img src="http://img.zwer.xyz/blog/20191016164827.png" style="zoom: 50%;">

<img src="http://img.zwer.xyz/blog/20191016165005.png" style="zoom:50%;">

</li>
</ul>
<h2 id="HBase-环境搭建"><a href="#HBase-环境搭建" class="headerlink" title="HBase 环境搭建"></a>HBase 环境搭建</h2><p>HBase 官方文档地址：<a href="http://hbase.apache.org/book.html#quickstart" target="_blank" rel="noopener">http://hbase.apache.org/book.html#quickstart</a></p>
<h3 id="HBase-伪分布式搭建"><a href="#HBase-伪分布式搭建" class="headerlink" title="HBase 伪分布式搭建"></a>HBase 伪分布式搭建</h3><ul>
<li><p><strong>系统环境</strong></p>
<p>JDK  1.7，并配置 JAVA_HOME 环境变量</p>
</li>
<li><p><strong>HBase 安装步骤</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 上传 HBase 压缩包文件，并解压到指定目录， 通过 tar 命令中 -C 指定解压到的目录</span><br><span class="line">tar xf hbase-0.98.12.1-hadoop2-bin.tar.gz  -C  /opt/sxt</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 配置 HBase 环境变量</span><br><span class="line">vi /etc/profile</span><br><span class="line"><span class="meta">#</span> 增加的配置内容</span><br><span class="line">export HBASE_HOME=/opt/sxt/hbase-0.98.12.1-hadoop2</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin:$HBASE_HOME/bin</span><br><span class="line"><span class="meta">#</span> 环境变量生效</span><br><span class="line">. /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 进入 $HBSE_HOME/conf 下</span><br><span class="line"><span class="meta">#</span> 修改 hbase-env.sh</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.7.0_67</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 修改 hbase-site.xml </span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;file:///home/testuser/hbase&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/home/testuser/zookeeper&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;</span><br><span class="line">&lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 启动</span><br><span class="line">start-hbase.sh</span><br><span class="line"><span class="meta">#</span> 访问 HBase ，端口号为 60010</span><br><span class="line">http://192.168.170.105:60010</span><br><span class="line"><span class="meta">#</span> </span><br><span class="line">hbase shell</span><br><span class="line"><span class="meta">#</span>help 查看 hbase 使用</span><br><span class="line"><span class="meta">#</span>list  列出所欲当前数据表</span><br><span class="line"><span class="meta">#</span>scan  列出当前数据表中记录数</span><br><span class="line"><span class="meta">#</span>create 创建表</span><br><span class="line"><span class="meta">#</span>put    增加记录</span><br><span class="line"><span class="meta">#</span>delete  删除记录</span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li><strong>HBase 操作</strong></li>
</ul>
<p><img src="http://img.zwer.xyz/blog/20191016204121.png" alt></p>
<p>补充：  list  显示当前 HBase 中所有表  </p>
<p>​              flush 将 inmemstore 中数据写入 storefile </p>
<h3 id="HBase-完全分布式搭建"><a href="#HBase-完全分布式搭建" class="headerlink" title="HBase 完全分布式搭建"></a>HBase 完全分布式搭建</h3><ul>
<li><p><strong>节点分布</strong></p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">NN</th>
<th align="center">DN</th>
<th align="center">ZK</th>
<th align="center">HMaster</th>
<th align="center">Backup-HMaster</th>
<th align="center">RegionServer</th>
</tr>
</thead>
<tbody><tr>
<td align="center">node01</td>
<td align="center">*</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">*</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">node02</td>
<td align="center"></td>
<td align="center">*</td>
<td align="center">*</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">*</td>
</tr>
<tr>
<td align="center">node03</td>
<td align="center"></td>
<td align="center">*</td>
<td align="center">*</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">*</td>
</tr>
<tr>
<td align="center">node04</td>
<td align="center"></td>
<td align="center">*</td>
<td align="center">*</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">*</td>
</tr>
<tr>
<td align="center">node05</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center">*</td>
<td align="center"></td>
</tr>
</tbody></table>
</li>
<li><p><strong>系统设置</strong></p>
<ol>
<li><p>集群间网络通信</p>
</li>
<li><p>时间同步</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 安装 ntp 服务</span><br><span class="line">yum install -y ntp</span><br><span class="line"><span class="meta">#</span> 时间服务器</span><br><span class="line">ntpdate ntp1.aliyun.com</span><br></pre></td></tr></table></figure>
</li>
<li><p>JDK 环境</p>
</li>
<li><p>免秘钥登录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen</span><br><span class="line">ssh-copy-id -i /root/.ssh/id_rsa.pub host(需要免密钥登录的服务器地址)</span><br><span class="line">eg: ssh-copy-id -i .ssh/id_rsa.pub  node02</span><br></pre></td></tr></table></figure>
</li>
<li><p>hadoop 集群启动</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li><p><strong>HBase 搭建</strong></p>
<ol>
<li><p>上传解压</p>
</li>
<li><p>修改配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> node 节点上------------------------------</span><br><span class="line"><span class="meta">#</span> 进入 $HBASE_HOME/conf 目录下</span><br><span class="line"><span class="meta">#</span> 编辑 vi  hbase-env.sh ,配置JDk 、关闭 zk </span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.7.0_67</span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 编辑 vi hbase-site.xml ，增加内容为 </span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hdfs://mycluster:8020/hbase&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;node02,node03,node04&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 编辑 vi regionservers,增加内容为 </span><br><span class="line">node02</span><br><span class="line">node03</span><br><span class="line">node04</span><br><span class="line"><span class="meta">#</span> 编辑 vi backup-masters，增加内容为 </span><br><span class="line">node05</span><br><span class="line"><span class="meta">#</span> 拷贝 $HADOOP_HOME/etc/hadoop/hdfs-size.xml 到 $HBASE_HOME/conf 目录下(重要)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 分发到 node02、node03、node04、node05</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 配置 node02、node03、node04、node05 的 hbase 环境变量</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>启动</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-hbase.sh</span><br></pre></td></tr></table></figure>

<p><img src="http://img.zwer.xyz/blog/20191016213051.png" alt></p>
</li>
</ol>
</li>
</ul>
<h2 id="HBase-API"><a href="#HBase-API" class="headerlink" title="HBase-API"></a>HBase-API</h2><blockquote>
<p>重点 ： rowkey 设计</p>
</blockquote>
<h3 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h3><ol>
<li><p>创建 hbase-demo 普通 java 项目，并导入 hadoop 和 hbase 相关依赖 jar 包，并发布到类路径上</p>
</li>
<li><p>创建 HBaseDemo</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HbaseDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	HBaseAdmin admin;</span><br><span class="line">	HTable htable;</span><br><span class="line">	Configuration conf;</span><br><span class="line">	String TN = <span class="string">"test"</span>;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Before</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">		conf.set(<span class="string">"hbase.zookeeper.quorum"</span>, <span class="string">"node02,node03,node04"</span>);</span><br><span class="line">		admin = <span class="keyword">new</span> HBaseAdmin(conf);</span><br><span class="line">		htable = <span class="keyword">new</span> HTable(conf, TN.getBytes());</span><br><span class="line">	&#125;</span><br><span class="line">    </span><br><span class="line">    	<span class="meta">@After</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (admin != <span class="keyword">null</span>) &#123;</span><br><span class="line">			admin.close();</span><br><span class="line">		&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>创建表</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createTable</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    HTableDescriptor table = <span class="keyword">new</span> HTableDescriptor(TableName.valueOf(TN.getBytes()));</span><br><span class="line">    HColumnDescriptor column = <span class="keyword">new</span> HColumnDescriptor(<span class="string">"cf"</span>);</span><br><span class="line">    table.addFamily(column);</span><br><span class="line">    <span class="keyword">if</span> (admin.tableExists(TN.getBytes())) &#123;</span><br><span class="line">        admin.disableTable(TN.getBytes());</span><br><span class="line">        admin.deleteTable(TN.getBytes());</span><br><span class="line">    &#125;</span><br><span class="line">    admin.createTable(table);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>存放数据</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		String rowkey = <span class="string">"r124"</span>;</span><br><span class="line">		Put put = <span class="keyword">new</span> Put(rowkey.getBytes());</span><br><span class="line">		put.add(<span class="string">"cf"</span>.getBytes(), <span class="string">"name"</span>.getBytes(), <span class="string">"xiaoli"</span>.getBytes());</span><br><span class="line">		put.add(<span class="string">"cf"</span>.getBytes(), <span class="string">"age"</span>.getBytes(), <span class="string">"32"</span>.getBytes());</span><br><span class="line">		put.add(<span class="string">"cf"</span>.getBytes(), <span class="string">"sex"</span>.getBytes(), <span class="string">"female"</span>.getBytes());</span><br><span class="line">		htable.put(put);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>获取数据</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">showTable</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    Get get = <span class="keyword">new</span> Get(<span class="string">"r123"</span>.getBytes());</span><br><span class="line">    <span class="comment">// 必须加</span></span><br><span class="line">    get.addColumn(<span class="string">"cf"</span>.getBytes(), <span class="string">"name"</span>.getBytes());</span><br><span class="line">    get.addColumn(<span class="string">"cf"</span>.getBytes(), <span class="string">"age"</span>.getBytes());</span><br><span class="line">    Result result = htable.get(get);</span><br><span class="line">    Cell name = result.getColumnLatestCell(<span class="string">"cf"</span>.getBytes(), <span class="string">"name"</span>.getBytes());</span><br><span class="line">    Cell age = result.getColumnLatestCell(<span class="string">"cf"</span>.getBytes(), <span class="string">"age"</span>.getBytes());</span><br><span class="line">    <span class="comment">// System.out.println(new String(name.getValue()));</span></span><br><span class="line">    <span class="comment">// System.out.println(new String(age.getValue()));</span></span><br><span class="line">    System.out.print(<span class="keyword">new</span> String(CellUtil.cloneValue(name)));</span><br><span class="line">    System.out.print(<span class="keyword">new</span> String(CellUtil.cloneValue(age)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>条件查询</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">	</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 生成电话号码</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> prefix</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	Random r = <span class="keyword">new</span> Random();</span><br><span class="line">	<span class="function"><span class="keyword">private</span> String <span class="title">generatePhoneNumber</span><span class="params">(String prefix)</span> </span>&#123;</span><br><span class="line">		String pNum = prefix + String.format(<span class="string">"%08d"</span>, r.nextInt(<span class="number">99999999</span>));</span><br><span class="line">		<span class="keyword">return</span> pNum;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 *  获取随机时间</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	DateFormat sdf = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyyMMddHHmmss"</span>);</span><br><span class="line">	<span class="function"><span class="keyword">public</span> String <span class="title">getDate</span><span class="params">(String year)</span> </span>&#123;</span><br><span class="line">		<span class="comment">// 月 天 小时 分钟 秒</span></span><br><span class="line">		Object[] args = &#123; r.nextInt(<span class="number">12</span>)+<span class="number">1</span>, r.nextInt(<span class="number">31</span>)+<span class="number">1</span>, r.nextInt(<span class="number">24</span>), r.nextInt(<span class="number">60</span>), r.nextInt(<span class="number">60</span>) &#125;;</span><br><span class="line">		String dateStr = year + String.format(<span class="string">"%02d%02d%02d%02d%02d"</span>, args);</span><br><span class="line">		<span class="keyword">return</span> dateStr;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 *  生成 10个人通话记录</span></span><br><span class="line"><span class="comment">	 *  // phoneNum_(max-timestamp)  </span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addPhoneRecord</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		List&lt;Put&gt; puts = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; <span class="number">10</span>;i++)&#123;</span><br><span class="line">			String phoneNum = generatePhoneNumber(<span class="string">"189"</span>);</span><br><span class="line">			<span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt; <span class="number">100</span>;j++)&#123;</span><br><span class="line">				String dnum = generatePhoneNumber(<span class="string">"138"</span>);</span><br><span class="line">				String length = r.nextInt(<span class="number">99</span>)+<span class="string">""</span>; <span class="comment">// 通话时长</span></span><br><span class="line">				String type = r.nextInt(<span class="number">2</span>)+<span class="string">""</span>; <span class="comment">// 1 是主叫，2 是被叫</span></span><br><span class="line">				String dataStr  = getDate(<span class="string">"2019"</span>);  <span class="comment">// 通话开始时间</span></span><br><span class="line">				String rowkey = phoneNum+<span class="string">"_"</span>+(Long.MAX_VALUE-sdf.parse(dataStr).getTime());</span><br><span class="line">				Put put = <span class="keyword">new</span> Put(rowkey.getBytes());</span><br><span class="line">				put.add(<span class="string">"cf"</span>.getBytes(),<span class="string">"dnum"</span>.getBytes(),dnum.getBytes());</span><br><span class="line">				put.add(<span class="string">"cf"</span>.getBytes(),<span class="string">"length"</span>.getBytes(),length.getBytes());</span><br><span class="line">				put.add(<span class="string">"cf"</span>.getBytes(),<span class="string">"type"</span>.getBytes(),type.getBytes());</span><br><span class="line">				put.add(<span class="string">"cf"</span>.getBytes(),<span class="string">"dataStr"</span>.getBytes(),dataStr.getBytes());</span><br><span class="line">				puts.add(put);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		htable.put(puts);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 查找通话记录 ，指定电话的在 1月份 4 月份之间的通话记录</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">scan</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		String phoneNum = <span class="string">"18985484208"</span>;                            <span class="comment">//20190022203207</span></span><br><span class="line">		String startRow = phoneNum+<span class="string">"_"</span>+(Long.MAX_VALUE-sdf.parse(<span class="string">"20190401000000"</span>).getTime());</span><br><span class="line">		String stopRow =  phoneNum+<span class="string">"_"</span>+(Long.MAX_VALUE-sdf.parse(<span class="string">"20190101000000"</span>).getTime());</span><br><span class="line">		Scan scan = <span class="keyword">new</span> Scan();</span><br><span class="line">		scan.setStartRow(startRow.getBytes());</span><br><span class="line">		scan.setStopRow(stopRow.getBytes());</span><br><span class="line">		ResultScanner scanner = htable.getScanner(scan);</span><br><span class="line">		<span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">for</span> (Result rs : scanner) &#123;</span><br><span class="line">			System.out.print(<span class="keyword">new</span> String(CellUtil.cloneValue(rs.getColumnLatestCell(<span class="string">"cf"</span>.getBytes(), <span class="string">"dnum"</span>.getBytes()))));</span><br><span class="line">			System.out.print(<span class="string">"\t"</span>+<span class="keyword">new</span> String(CellUtil.cloneValue(rs.getColumnLatestCell(<span class="string">"cf"</span>.getBytes(), <span class="string">"length"</span>.getBytes()))));</span><br><span class="line">			System.out.print(<span class="string">"\t"</span>+<span class="keyword">new</span> String(CellUtil.cloneValue(rs.getColumnLatestCell(<span class="string">"cf"</span>.getBytes(), <span class="string">"type"</span>.getBytes()))));</span><br><span class="line">			System.out.println(<span class="string">"\t"</span>+<span class="keyword">new</span> String(CellUtil.cloneValue(rs.getColumnLatestCell(<span class="string">"cf"</span>.getBytes(), <span class="string">"dataStr"</span>.getBytes()))));</span><br><span class="line">			count ++;</span><br><span class="line">		&#125;</span><br><span class="line">		System.out.println(<span class="string">"count:"</span>+count);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * 查找指定电话主叫的通话记录</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@throws</span> Exception</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">scan2</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		FilterList list = <span class="keyword">new</span> FilterList(FilterList.Operator.MUST_PASS_ALL);</span><br><span class="line">		PrefixFilter filter1 = <span class="keyword">new</span> PrefixFilter(<span class="string">"18985484208"</span>.getBytes());</span><br><span class="line">		SingleColumnValueFilter filter2 = <span class="keyword">new</span> SingleColumnValueFilter(<span class="string">"cf"</span>.getBytes(), <span class="string">"type"</span>.getBytes(),</span><br><span class="line">				CompareOp.EQUAL, <span class="string">"1"</span>.getBytes());</span><br><span class="line">		list.addFilter(filter1);</span><br><span class="line">		list.addFilter(filter2);</span><br><span class="line">		Scan scan = <span class="keyword">new</span> Scan();</span><br><span class="line">		scan.setFilter(list);</span><br><span class="line">		ResultScanner scanner = htable.getScanner(scan);</span><br><span class="line">		<span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">for</span> (Result rs : scanner) &#123;</span><br><span class="line">			System.out.print(<span class="keyword">new</span> String(rs.getRow()));</span><br><span class="line">			System.out.print(<span class="string">"\t"</span>+<span class="keyword">new</span> String(CellUtil.cloneValue(rs.getColumnLatestCell(<span class="string">"cf"</span>.getBytes(), <span class="string">"dnum"</span>.getBytes()))));</span><br><span class="line">			System.out.print(<span class="string">"\t"</span>+<span class="keyword">new</span> String(CellUtil.cloneValue(rs.getColumnLatestCell(<span class="string">"cf"</span>.getBytes(), <span class="string">"length"</span>.getBytes()))));</span><br><span class="line">			System.out.print(<span class="string">"\t"</span>+<span class="keyword">new</span> String(CellUtil.cloneValue(rs.getColumnLatestCell(<span class="string">"cf"</span>.getBytes(), <span class="string">"type"</span>.getBytes()))));</span><br><span class="line">			System.out.println(<span class="string">"\t"</span>+<span class="keyword">new</span> String(CellUtil.cloneValue(rs.getColumnLatestCell(<span class="string">"cf"</span>.getBytes(), <span class="string">"dataStr"</span>.getBytes()))));</span><br><span class="line">			count ++;</span><br><span class="line">		&#125;</span><br><span class="line">		System.out.println(<span class="string">"count:"</span>+count);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="工具类"><a href="#工具类" class="headerlink" title="工具类"></a>工具类</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br></pre></td><td class="code"><pre><span class="line">public class HBaseDAOImp &#123;</span><br><span class="line"></span><br><span class="line">	HConnection hTablePool = null;</span><br><span class="line">	static Configuration conf = null;</span><br><span class="line"></span><br><span class="line">	public HBaseDAOImp() &#123;</span><br><span class="line">		conf = new Configuration();</span><br><span class="line">		String zk_list = &quot;node01,node02,node03&quot;;</span><br><span class="line">		conf.set(&quot;hbase.zookeeper.quorum&quot;, zk_list);</span><br><span class="line">		try &#123;</span><br><span class="line">			hTablePool = HConnectionManager.createConnection(conf);</span><br><span class="line">		&#125; catch (IOException e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public void save(Put put, String tableName) &#123;</span><br><span class="line">		HTableInterface table = null;</span><br><span class="line">		try &#123;</span><br><span class="line">			table = hTablePool.getTable(tableName);</span><br><span class="line">			table.put(put);</span><br><span class="line"></span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				table.close();</span><br><span class="line">			&#125; catch (IOException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/**</span><br><span class="line">	 * 插入一个cell</span><br><span class="line">	 * </span><br><span class="line">	 * @param tableName</span><br><span class="line">	 * @param rowKey</span><br><span class="line">	 * @param family</span><br><span class="line">	 * @param quailifer</span><br><span class="line">	 * @param value</span><br><span class="line">	 */</span><br><span class="line">	public void insert(String tableName, String rowKey, String family, String quailifer, String value) &#123;</span><br><span class="line">		// TODO Auto-generated method stub</span><br><span class="line">		HTableInterface table = null;</span><br><span class="line">		try &#123;</span><br><span class="line">			table = hTablePool.getTable(tableName);</span><br><span class="line">			Put put = new Put(rowKey.getBytes());</span><br><span class="line">			put.add(family.getBytes(), quailifer.getBytes(), value.getBytes());</span><br><span class="line">			table.put(put);</span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				table.close();</span><br><span class="line">			&#125; catch (IOException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/**</span><br><span class="line">	 * 在一个列族下插入多个单元格</span><br><span class="line">	 * </span><br><span class="line">	 * @param tableName</span><br><span class="line">	 * @param rowKey</span><br><span class="line">	 * @param family</span><br><span class="line">	 * @param quailifer</span><br><span class="line">	 * @param value</span><br><span class="line">	 */</span><br><span class="line">	public void insert(String tableName, String rowKey, String family, String quailifer[], String value[]) &#123;</span><br><span class="line">		HTableInterface table = null;</span><br><span class="line">		try &#123;</span><br><span class="line">			table = hTablePool.getTable(tableName);</span><br><span class="line">			Put put = new Put(rowKey.getBytes());</span><br><span class="line">			// 批量添加</span><br><span class="line">			for (int i = 0; i &lt; quailifer.length; i++) &#123;</span><br><span class="line">				String col = quailifer[i];</span><br><span class="line">				String val = value[i];</span><br><span class="line">				put.add(family.getBytes(), col.getBytes(), val.getBytes());</span><br><span class="line">			&#125;</span><br><span class="line">			table.put(put);</span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				table.close();</span><br><span class="line">			&#125; catch (IOException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public void save(List&lt;Put&gt; Put, String tableName) &#123;</span><br><span class="line">		HTableInterface table = null;</span><br><span class="line">		try &#123;</span><br><span class="line">			table = hTablePool.getTable(tableName);</span><br><span class="line">			table.put(Put);</span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				table.close();</span><br><span class="line">			&#125; catch (IOException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public Result getOneRow(String tableName, String rowKey) &#123;</span><br><span class="line">		HTableInterface table = null;</span><br><span class="line">		Result rsResult = null;</span><br><span class="line">		try &#123;</span><br><span class="line">			table = hTablePool.getTable(tableName);</span><br><span class="line">			Get get = new Get(rowKey.getBytes());</span><br><span class="line">			rsResult = table.get(get);</span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				table.close();</span><br><span class="line">			&#125; catch (IOException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		return rsResult;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/**</span><br><span class="line">	 * 最常用的方法，优化查询 查询一行数据，</span><br><span class="line">	 * </span><br><span class="line">	 * @param tableName</span><br><span class="line">	 * @param rowKey</span><br><span class="line">	 * @param cols</span><br><span class="line">	 * @return</span><br><span class="line">	 */</span><br><span class="line">	public Result getOneRowAndMultiColumn(String tableName, String rowKey, String[] cols) &#123;</span><br><span class="line">		HTableInterface table = null;</span><br><span class="line">		Result rsResult = null;</span><br><span class="line">		try &#123;</span><br><span class="line">			table = hTablePool.getTable(tableName);</span><br><span class="line">			Get get = new Get(rowKey.getBytes());</span><br><span class="line">			for (int i = 0; i &lt; cols.length; i++) &#123;</span><br><span class="line">				get.addColumn(&quot;cf&quot;.getBytes(), cols[i].getBytes());</span><br><span class="line">			&#125;</span><br><span class="line">			rsResult = table.get(get);</span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				table.close();</span><br><span class="line">			&#125; catch (IOException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		return rsResult;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public List&lt;Result&gt; getRows(String tableName, String rowKeyLike) &#123;</span><br><span class="line">		HTableInterface table = null;</span><br><span class="line">		List&lt;Result&gt; list = null;</span><br><span class="line">		try &#123;</span><br><span class="line">			FilterList fl = new FilterList(FilterList.Operator.MUST_PASS_ALL);</span><br><span class="line">			table = hTablePool.getTable(tableName);</span><br><span class="line">			PrefixFilter filter = new PrefixFilter(rowKeyLike.getBytes());</span><br><span class="line">			SingleColumnValueFilter filter1 = new SingleColumnValueFilter(&quot;order&quot;.getBytes(), &quot;order_type&quot;.getBytes(),</span><br><span class="line">					CompareOp.EQUAL, Bytes.toBytes(&quot;1&quot;));</span><br><span class="line">			fl.addFilter(filter);</span><br><span class="line">			fl.addFilter(filter1);</span><br><span class="line">			Scan scan = new Scan();</span><br><span class="line">			scan.setFilter(fl);</span><br><span class="line">			ResultScanner scanner = table.getScanner(scan);</span><br><span class="line">			list = new ArrayList&lt;Result&gt;();</span><br><span class="line">			for (Result rs : scanner) &#123;</span><br><span class="line">				list.add(rs);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				table.close();</span><br><span class="line">			&#125; catch (IOException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		return list;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public List&lt;Result&gt; getRows(String tableName, String rowKeyLike, String cols[]) &#123;</span><br><span class="line">		// TODO Auto-generated method stub</span><br><span class="line">		HTableInterface table = null;</span><br><span class="line">		List&lt;Result&gt; list = null;</span><br><span class="line">		try &#123;</span><br><span class="line">			table = hTablePool.getTable(tableName);</span><br><span class="line">			PrefixFilter filter = new PrefixFilter(rowKeyLike.getBytes());</span><br><span class="line"></span><br><span class="line">			Scan scan = new Scan();</span><br><span class="line">			for (int i = 0; i &lt; cols.length; i++) &#123;</span><br><span class="line">				scan.addColumn(&quot;cf&quot;.getBytes(), cols[i].getBytes());</span><br><span class="line">			&#125;</span><br><span class="line">			scan.setFilter(filter);</span><br><span class="line">			ResultScanner scanner = table.getScanner(scan);</span><br><span class="line">			list = new ArrayList&lt;Result&gt;();</span><br><span class="line">			for (Result rs : scanner) &#123;</span><br><span class="line">				list.add(rs);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				table.close();</span><br><span class="line">			&#125; catch (IOException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		return list;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public List&lt;Result&gt; getRowsByOneKey(String tableName, String rowKeyLike, String cols[]) &#123;</span><br><span class="line">		// TODO Auto-generated method stub</span><br><span class="line">		HTableInterface table = null;</span><br><span class="line">		List&lt;Result&gt; list = null;</span><br><span class="line">		try &#123;</span><br><span class="line">			table = hTablePool.getTable(tableName);</span><br><span class="line">			PrefixFilter filter = new PrefixFilter(rowKeyLike.getBytes());</span><br><span class="line"></span><br><span class="line">			Scan scan = new Scan();</span><br><span class="line">			for (int i = 0; i &lt; cols.length; i++) &#123;</span><br><span class="line">				scan.addColumn(&quot;cf&quot;.getBytes(), cols[i].getBytes());</span><br><span class="line">			&#125;</span><br><span class="line">			scan.setFilter(filter);</span><br><span class="line">			ResultScanner scanner = table.getScanner(scan);</span><br><span class="line">			list = new ArrayList&lt;Result&gt;();</span><br><span class="line">			for (Result rs : scanner) &#123;</span><br><span class="line">				list.add(rs);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				table.close();</span><br><span class="line">			&#125; catch (IOException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		return list;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/**</span><br><span class="line">	 * 范围查询</span><br><span class="line">	 * </span><br><span class="line">	 * @param tableName</span><br><span class="line">	 * @param startRow</span><br><span class="line">	 * @param stopRow</span><br><span class="line">	 * @return</span><br><span class="line">	 */</span><br><span class="line">	public List&lt;Result&gt; getRows(String tableName, String startRow, String stopRow) &#123;</span><br><span class="line">		HTableInterface table = null;</span><br><span class="line">		List&lt;Result&gt; list = null;</span><br><span class="line">		try &#123;</span><br><span class="line">			table = hTablePool.getTable(tableName);</span><br><span class="line">			Scan scan = new Scan();</span><br><span class="line">			scan.setStartRow(startRow.getBytes());</span><br><span class="line">			scan.setStopRow(stopRow.getBytes());</span><br><span class="line">			ResultScanner scanner = table.getScanner(scan);</span><br><span class="line">			list = new ArrayList&lt;Result&gt;();</span><br><span class="line">			for (Result rsResult : scanner) &#123;</span><br><span class="line">				list.add(rsResult);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				table.close();</span><br><span class="line">			&#125; catch (IOException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		return list;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public void deleteRecords(String tableName, String rowKeyLike) &#123;</span><br><span class="line">		HTableInterface table = null;</span><br><span class="line">		try &#123;</span><br><span class="line">			table = hTablePool.getTable(tableName);</span><br><span class="line">			PrefixFilter filter = new PrefixFilter(rowKeyLike.getBytes());</span><br><span class="line">			Scan scan = new Scan();</span><br><span class="line">			scan.setFilter(filter);</span><br><span class="line">			ResultScanner scanner = table.getScanner(scan);</span><br><span class="line">			List&lt;Delete&gt; list = new ArrayList&lt;Delete&gt;();</span><br><span class="line">			for (Result rs : scanner) &#123;</span><br><span class="line">				Delete del = new Delete(rs.getRow());</span><br><span class="line">				list.add(del);</span><br><span class="line">			&#125;</span><br><span class="line">			table.delete(list);</span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				table.close();</span><br><span class="line">			&#125; catch (IOException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public void deleteCell(String tableName, String rowkey, String cf, String column) &#123;</span><br><span class="line">		HTableInterface table = null;</span><br><span class="line">		try &#123;</span><br><span class="line">			table = hTablePool.getTable(tableName);</span><br><span class="line">			Delete del = new Delete(rowkey.getBytes());</span><br><span class="line">			del.deleteColumn(cf.getBytes(), column.getBytes());</span><br><span class="line">			table.delete(del);</span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				table.close();</span><br><span class="line">			&#125; catch (IOException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public void createTable(String tableName, String[] columnFamilys) &#123;</span><br><span class="line">		try &#123;</span><br><span class="line">			// admin 对象</span><br><span class="line">			HBaseAdmin admin = new HBaseAdmin(conf);</span><br><span class="line">			if (admin.tableExists(tableName)) &#123;</span><br><span class="line">				System.err.println(&quot;此表，已存在！&quot;);</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				HTableDescriptor tableDesc = new HTableDescriptor(TableName.valueOf(tableName));</span><br><span class="line"></span><br><span class="line">				for (String columnFamily : columnFamilys) &#123;</span><br><span class="line">					tableDesc.addFamily(new HColumnDescriptor(columnFamily));</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				admin.createTable(tableDesc);</span><br><span class="line">				System.err.println(&quot;建表成功!&quot;);</span><br><span class="line"></span><br><span class="line">			&#125;</span><br><span class="line">			admin.close();// 关闭释放资源</span><br><span class="line">		&#125; catch (MasterNotRunningException e) &#123;</span><br><span class="line">			// TODO Auto-generated catch block</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; catch (ZooKeeperConnectionException e) &#123;</span><br><span class="line">			// TODO Auto-generated catch block</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; catch (IOException e) &#123;</span><br><span class="line">			// TODO Auto-generated catch block</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/**</span><br><span class="line">	 * 删除一个表</span><br><span class="line">	 * </span><br><span class="line">	 * @param tableName</span><br><span class="line">	 *            删除的表名</span><br><span class="line">	 */</span><br><span class="line">	public void deleteTable(String tableName) &#123;</span><br><span class="line">		try &#123;</span><br><span class="line">			HBaseAdmin admin = new HBaseAdmin(conf);</span><br><span class="line">			if (admin.tableExists(tableName)) &#123;</span><br><span class="line">				admin.disableTable(tableName);// 禁用表</span><br><span class="line">				admin.deleteTable(tableName);// 删除表</span><br><span class="line">				System.err.println(&quot;删除表成功!&quot;);</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				System.err.println(&quot;删除的表不存在！&quot;);</span><br><span class="line">			&#125;</span><br><span class="line">			admin.close();</span><br><span class="line">		&#125; catch (MasterNotRunningException e) &#123;</span><br><span class="line">			// TODO Auto-generated catch block</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; catch (ZooKeeperConnectionException e) &#123;</span><br><span class="line">			// TODO Auto-generated catch block</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125; catch (IOException e) &#123;</span><br><span class="line">			// TODO Auto-generated catch block</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	/**</span><br><span class="line">	 * 查询表中所有行</span><br><span class="line">	 * </span><br><span class="line">	 * @param tablename</span><br><span class="line">	 */</span><br><span class="line">	public void scaner(String tablename) &#123;</span><br><span class="line">		try &#123;</span><br><span class="line">			HTable table = new HTable(conf, tablename);</span><br><span class="line">			Scan s = new Scan();</span><br><span class="line">			// s.addColumn(family, qualifier)</span><br><span class="line">			// s.addColumn(family, qualifier)</span><br><span class="line">			ResultScanner rs = table.getScanner(s);</span><br><span class="line">			for (Result r : rs) &#123;</span><br><span class="line"></span><br><span class="line">				for (Cell cell : r.rawCells()) &#123;</span><br><span class="line">					System.out.println(&quot;RowName:&quot; + new String(CellUtil.cloneRow(cell)) + &quot; &quot;);</span><br><span class="line">					System.out.println(&quot;Timetamp:&quot; + cell.getTimestamp() + &quot; &quot;);</span><br><span class="line">					System.out.println(&quot;column Family:&quot; + new String(CellUtil.cloneFamily(cell)) + &quot; &quot;);</span><br><span class="line">					System.out.println(&quot;row Name:&quot; + new String(CellUtil.cloneQualifier(cell)) + &quot; &quot;);</span><br><span class="line">					System.out.println(&quot;value:&quot; + new String(CellUtil.cloneValue(cell)) + &quot; &quot;);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; catch (IOException e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public void scanerByColumn(String tablename) &#123;</span><br><span class="line"></span><br><span class="line">		try &#123;</span><br><span class="line">			HTable table = new HTable(conf, tablename);</span><br><span class="line">			Scan s = new Scan();</span><br><span class="line">			s.addColumn(&quot;cf&quot;.getBytes(), &quot;201504052237&quot;.getBytes());</span><br><span class="line">			s.addColumn(&quot;cf&quot;.getBytes(), &quot;201504052237&quot;.getBytes());</span><br><span class="line">			ResultScanner rs = table.getScanner(s);</span><br><span class="line">			for (Result r : rs) &#123;</span><br><span class="line"></span><br><span class="line">				for (Cell cell : r.rawCells()) &#123;</span><br><span class="line">					System.out.println(&quot;RowName:&quot; + new String(CellUtil.cloneRow(cell)) + &quot; &quot;);</span><br><span class="line">					System.out.println(&quot;Timetamp:&quot; + cell.getTimestamp() + &quot; &quot;);</span><br><span class="line">					System.out.println(&quot;column Family:&quot; + new String(CellUtil.cloneFamily(cell)) + &quot; &quot;);</span><br><span class="line">					System.out.println(&quot;row Name:&quot; + new String(CellUtil.cloneQualifier(cell)) + &quot; &quot;);</span><br><span class="line">					System.out.println(&quot;value:&quot; + new String(CellUtil.cloneValue(cell)) + &quot; &quot;);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; catch (IOException e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">		// 创建表</span><br><span class="line">		// String tableName=&quot;test&quot;;</span><br><span class="line">		// String cfs[] = &#123;&quot;cf&quot;&#125;;</span><br><span class="line">		// dao.createTable(tableName,cfs);</span><br><span class="line"></span><br><span class="line">		// 存入一条数据</span><br><span class="line">		// Put put = new Put(&quot;bjsxt&quot;.getBytes());</span><br><span class="line">		// put.add(&quot;cf&quot;.getBytes(), &quot;name&quot;.getBytes(), &quot;cai10&quot;.getBytes()) ;</span><br><span class="line">		// dao.save(put, &quot;test&quot;) ;</span><br><span class="line"></span><br><span class="line">		// 插入多列数据</span><br><span class="line">		// Put put = new Put(&quot;bjsxt&quot;.getBytes());</span><br><span class="line">		// List&lt;Put&gt; list = new ArrayList&lt;Put&gt;();</span><br><span class="line">		// put.add(&quot;cf&quot;.getBytes(), &quot;addr&quot;.getBytes(), &quot;shanghai1&quot;.getBytes()) ;</span><br><span class="line">		// put.add(&quot;cf&quot;.getBytes(), &quot;age&quot;.getBytes(), &quot;30&quot;.getBytes()) ;</span><br><span class="line">		// put.add(&quot;cf&quot;.getBytes(), &quot;tel&quot;.getBytes(), &quot;13889891818&quot;.getBytes())</span><br><span class="line">		// ;</span><br><span class="line">		// list.add(put) ;</span><br><span class="line">		// dao.save(list, &quot;test&quot;);</span><br><span class="line"></span><br><span class="line">		// 插入单行数据</span><br><span class="line">		// dao.insert(&quot;test&quot;, &quot;testrow&quot;, &quot;cf&quot;, &quot;age&quot;, &quot;35&quot;) ;</span><br><span class="line">		// dao.insert(&quot;test&quot;, &quot;testrow&quot;, &quot;cf&quot;, &quot;cardid&quot;, &quot;12312312335&quot;) ;</span><br><span class="line">		// dao.insert(&quot;test&quot;, &quot;testrow&quot;, &quot;cf&quot;, &quot;tel&quot;, &quot;13512312345&quot;) ;</span><br><span class="line"></span><br><span class="line">		// List&lt;Result&gt; list = dao.getRows(&quot;test&quot;, &quot;testrow&quot;,new</span><br><span class="line">		// String[]&#123;&quot;age&quot;&#125;) ;</span><br><span class="line">		// for(Result rs : list)</span><br><span class="line">		// &#123;</span><br><span class="line">		// for(Cell cell:rs.rawCells())&#123;</span><br><span class="line">		// System.out.println(&quot;RowName:&quot;+new String(CellUtil.cloneRow(cell))+&quot;</span><br><span class="line">		// &quot;);</span><br><span class="line">		// System.out.println(&quot;Timetamp:&quot;+cell.getTimestamp()+&quot; &quot;);</span><br><span class="line">		// System.out.println(&quot;column Family:&quot;+new</span><br><span class="line">		// String(CellUtil.cloneFamily(cell))+&quot; &quot;);</span><br><span class="line">		// System.out.println(&quot;row Name:&quot;+new</span><br><span class="line">		// String(CellUtil.cloneQualifier(cell))+&quot; &quot;);</span><br><span class="line">		// System.out.println(&quot;value:&quot;+new String(CellUtil.cloneValue(cell))+&quot;</span><br><span class="line">		// &quot;);</span><br><span class="line">		// &#125;</span><br><span class="line">		// &#125;</span><br><span class="line"></span><br><span class="line">		// Result rs = dao.getOneRow(&quot;test&quot;, &quot;testrow&quot;);</span><br><span class="line">		// System.out.println(new String(rs.getValue(&quot;cf&quot;.getBytes(),</span><br><span class="line">		// &quot;age&quot;.getBytes())));</span><br><span class="line"></span><br><span class="line">		// Result rs = dao.getOneRowAndMultiColumn(&quot;cell_monitor_table&quot;,</span><br><span class="line">		// &quot;29448-513332015-04-05&quot;, new</span><br><span class="line">		// String[]&#123;&quot;201504052236&quot;,&quot;201504052237&quot;&#125;);</span><br><span class="line">		// for(Cell cell:rs.rawCells())&#123;</span><br><span class="line">		// System.out.println(&quot;RowName:&quot;+new String(CellUtil.cloneRow(cell))+&quot;</span><br><span class="line">		// &quot;);</span><br><span class="line">		// System.out.println(&quot;Timetamp:&quot;+cell.getTimestamp()+&quot; &quot;);</span><br><span class="line">		// System.out.println(&quot;column Family:&quot;+new</span><br><span class="line">		// String(CellUtil.cloneFamily(cell))+&quot; &quot;);</span><br><span class="line">		// System.out.println(&quot;row Name:&quot;+new</span><br><span class="line">		// String(CellUtil.cloneQualifier(cell))+&quot; &quot;);</span><br><span class="line">		// System.out.println(&quot;value:&quot;+new String(CellUtil.cloneValue(cell))+&quot;</span><br><span class="line">		// &quot;);</span><br><span class="line">		// &#125;</span><br><span class="line"></span><br><span class="line">		// dao.deleteTable(&quot;cell_monitor_table&quot;);</span><br><span class="line">		// 创建表</span><br><span class="line">		String tableName = &quot;cell_monitor_table&quot;;</span><br><span class="line">		String cfs[] = &#123; &quot;cf&quot; &#125;;</span><br><span class="line">		// dao.createTable(tableName,cfs);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public static void testRowFilter(String tableName) &#123;</span><br><span class="line">		try &#123;</span><br><span class="line">			HTable table = new HTable(conf, tableName);</span><br><span class="line">			Scan scan = new Scan();</span><br><span class="line">			scan.addColumn(Bytes.toBytes(&quot;column1&quot;), Bytes.toBytes(&quot;qqqq&quot;));</span><br><span class="line">			Filter filter1 = new RowFilter(CompareOp.LESS_OR_EQUAL, new BinaryComparator(Bytes.toBytes(&quot;laoxia157&quot;)));</span><br><span class="line">			scan.setFilter(filter1);</span><br><span class="line">			ResultScanner scanner1 = table.getScanner(scan);</span><br><span class="line">			for (Result res : scanner1) &#123;</span><br><span class="line">				System.out.println(res);</span><br><span class="line">			&#125;</span><br><span class="line">			scanner1.close();</span><br><span class="line"></span><br><span class="line">			//</span><br><span class="line">			// Filter filter2 = new RowFilter(CompareFilter.CompareOp.EQUAL,new</span><br><span class="line">			// RegexStringComparator(&quot;laoxia4\\d&#123;2&#125;&quot;));</span><br><span class="line">			// scan.setFilter(filter2);</span><br><span class="line">			// ResultScanner scanner2 = table.getScanner(scan);</span><br><span class="line">			// for (Result res : scanner2) &#123;</span><br><span class="line">			// System.out.println(res);</span><br><span class="line">			// &#125;</span><br><span class="line">			// scanner2.close();</span><br><span class="line"></span><br><span class="line">			Filter filter3 = new RowFilter(CompareOp.EQUAL, new SubstringComparator(&quot;laoxia407&quot;));</span><br><span class="line">			scan.setFilter(filter3);</span><br><span class="line">			ResultScanner scanner3 = table.getScanner(scan);</span><br><span class="line">			for (Result res : scanner3) &#123;</span><br><span class="line">				System.out.println(res);</span><br><span class="line">			&#125;</span><br><span class="line">			scanner3.close();</span><br><span class="line">		&#125; catch (IOException e) &#123;</span><br><span class="line">			// TODO Auto-generated catch block</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Test</span><br><span class="line">	public void testTrasaction() &#123;</span><br><span class="line">		try &#123;</span><br><span class="line">			HTableInterface table = null;</span><br><span class="line">			table = hTablePool.getTable(&quot;t_test&quot;.getBytes());</span><br><span class="line">			// Put put1 =new Put(&quot;002&quot;.getBytes());</span><br><span class="line">			// put1.add(&quot;cf1&quot;.getBytes(), &quot;name&quot;.getBytes(), &quot;王五&quot;.getBytes());</span><br><span class="line">			// table.put(put1);</span><br><span class="line">			Put newput = new Put(&quot;001&quot;.getBytes());</span><br><span class="line">			newput.add(&quot;cf1&quot;.getBytes(), &quot;like&quot;.getBytes(), &quot;看书&quot;.getBytes());</span><br><span class="line"></span><br><span class="line">			boolean f = table.checkAndPut(&quot;001&quot;.getBytes(), &quot;cf1&quot;.getBytes(), &quot;age&quot;.getBytes(), &quot;24&quot;.getBytes(),</span><br><span class="line">					newput);</span><br><span class="line">			System.out.println(f);</span><br><span class="line"></span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="HBase-微博案例"><a href="#HBase-微博案例" class="headerlink" title="HBase 微博案例"></a>HBase 微博案例</h2><blockquote>
<p>目的：怎么设计 HBase 表以及内部 RowKey 的设计</p>
</blockquote>
<h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">1. 添加、查看关注</span><br><span class="line">2. 粉丝列表</span><br><span class="line">3. 写微博</span><br><span class="line">4. 查看首页， 所有关注过的好友发布的最新微博</span><br><span class="line">5. 查看某个用户发布的所有微博</span><br><span class="line"></span><br><span class="line">eg:               关注列表 					粉丝列表</span><br><span class="line">张三001             李四				       王五</span><br><span class="line">李四002                                      张三，王五</span><br><span class="line">王五003  	           张三					  张三</span><br><span class="line"></span><br><span class="line">follow_fan</span><br><span class="line">rowkey  		 cf1(关注列表)                cf2(粉丝列表)</span><br><span class="line">001				 002=李四;					   003=王五;</span><br><span class="line">002              	                            001=张三;003=王五                      </span><br><span class="line">003              001=张三;					   001=张三</span><br><span class="line"></span><br><span class="line">tb_write_blog</span><br><span class="line">rowkey      					cf1</span><br><span class="line">uid_(Max-timestamp)             cf1:title;cf1:content;</span><br><span class="line"></span><br><span class="line">writed_blog_history_version</span><br></pre></td></tr></table></figure>

<h2 id="Protobuf"><a href="#Protobuf" class="headerlink" title="Protobuf"></a>Protobuf</h2><blockquote>
<p>Protocol Buffers 是<strong>一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化</strong>。</p>
</blockquote>
<h3 id="Protobuf-简介"><a href="#Protobuf-简介" class="headerlink" title="Protobuf 简介"></a>Protobuf 简介</h3><p>Google Protocol Buffer( 简称 Protobuf) 是 Google 公司内部的混合语言数据标准。</p>
<p>目前已经正在使用的有超过 48,162 种报文格式定义和超过 12,183 个 .proto 文件。</p>
<p>他们用于 RPC 系统和持续数据存储系统。</p>
<p>Protocol Buffers 是<strong>一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化</strong>。</p>
<p>它很适合做数据存储或 RPC 数据交换格式。</p>
<p>可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。</p>
<p>目前提供了 C++、Java、Python 三种语言的 API。</p>
<h3 id="安装-Google-Protocol-Buffer"><a href="#安装-Google-Protocol-Buffer" class="headerlink" title="安装 Google  Protocol Buffer"></a>安装 Google  Protocol Buffer</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">yum groupinstall Development tools -y</span><br><span class="line"></span><br><span class="line">tar -xzf protobuf-2.1.0.tar.gz </span><br><span class="line"><span class="meta">#</span> 配置</span><br><span class="line">.cofigure --prefix=/usr/local/protobuf</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>编译并安装</span><br><span class="line">make &amp;&amp; make install </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>配置环境变量</span><br><span class="line">export PROTOBUF=/usr/local/protobuf</span><br></pre></td></tr></table></figure>

<h3 id="protobuf-的使用"><a href="#protobuf-的使用" class="headerlink" title="protobuf 的使用"></a>protobuf 的使用</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 编辑 vi  Phone.proto 文件</span><br><span class="line">package com.szxy.hbase;</span><br><span class="line">message PhoneDetail&#123;</span><br><span class="line">	required string dnum=1;   // 被叫电话</span><br><span class="line">	required string type=2;  // 通话类型</span><br><span class="line">	required string length=3;  // 通话时长</span><br><span class="line">	required string datastr=4; // 通话时间</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 执行 </span><br><span class="line">protoc ./Phone --java_out=./</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 将生成的 java 文件拷贝到本地 Eclipse 上</span><br><span class="line"></span><br><span class="line">@Test</span><br><span class="line">	public void addPhoneRecord2() throws Exception&#123;</span><br><span class="line">		List&lt;Put&gt; puts = new ArrayList&lt;&gt;();</span><br><span class="line">		for(int i = 0;i &lt; 10;i++)&#123;</span><br><span class="line">			String phoneNum = generatePhoneNumber("189");</span><br><span class="line">			for(int j = 0;j &lt; 100;j++)&#123;</span><br><span class="line">				String dnum = generatePhoneNumber("138");</span><br><span class="line">				String length = r.nextInt(99)+""; // 通话时长</span><br><span class="line">				String type = r.nextInt(2)+""; // 1 是主叫，2 是被叫</span><br><span class="line">				String dataStr  = getDate("2019");  // 通话开始时间</span><br><span class="line">				String rowkey =</span><br><span class="line">                phoneNum+"_"+(Long.MAX_VALUE-sdf.parse(dataStr).getTime());</span><br><span class="line">				Builder builder</span><br><span class="line">                = Phone.PhoneDetail.getDefaultInstance().newBuilderForType();</span><br><span class="line">				builder.setDnum(dnum);</span><br><span class="line">				builder.setLength(length);</span><br><span class="line">				builder.setType(type);</span><br><span class="line">				builder.setDatastr(dataStr);</span><br><span class="line">				Put put </span><br><span class="line">				= new Put(rowkey.getBytes());</span><br><span class="line">			put.add("cf".getBytes(),"phoneDetail".getBytes(),builder.build().toByteArray());</span><br><span class="line">				puts.add(put);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		htable.put(puts);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line"><span class="meta">#</span> 编辑 vi  phoneDetail.proto 文件</span><br><span class="line">package com.szxy.hbase;</span><br><span class="line"></span><br><span class="line">message PhoneDetail</span><br><span class="line">&#123;</span><br><span class="line">    required string dnum=1;  </span><br><span class="line">    required string type=2; </span><br><span class="line">    required string length=3; </span><br><span class="line">    required string datastr=4;</span><br><span class="line">&#125; </span><br><span class="line">message dayPhoneDetail</span><br><span class="line">&#123;</span><br><span class="line">	repeated PhoneDetail  phoneDetail = 1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line">	 * 生成 10 个人一天的通话记录</span><br><span class="line">	 * 每行中 列中存储 100 条通话记录</span><br><span class="line">	 *</span><br><span class="line">	 */</span><br><span class="line">	@Test</span><br><span class="line">	public void addPhoneRecord3() throws Exception&#123;</span><br><span class="line">		List&lt;Put&gt; puts = new ArrayList&lt;&gt;();</span><br><span class="line">		for(int i = 0;i &lt; 10;i++)&#123;</span><br><span class="line">			String phoneNum = generatePhoneNumber("189");</span><br><span class="line">			String rowkey = phoneNum+"_"+(Long.MAX_VALUE-sdf.parse(getDate2("20190801")).getTime());</span><br><span class="line">			Phone.dayPhoneDetail.Builder dayPhoneDetail = Phone.dayPhoneDetail.newBuilder();</span><br><span class="line">			for(int j = 0;j &lt; 100;j++)&#123;</span><br><span class="line">				String dnum = generatePhoneNumber("138");</span><br><span class="line">				String length = r.nextInt(99)+""; // 通话时长</span><br><span class="line">				String type = r.nextInt(2)+""; // 1 是主叫，2 是被叫</span><br><span class="line">				String dataStr  = getDate("2019");  // 通话开始时间</span><br><span class="line">				PhoneDetail.Builder phoneDetail = Phone.PhoneDetail.newBuilder();</span><br><span class="line">				phoneDetail.setDnum(dnum);</span><br><span class="line">				phoneDetail.setLength(length);</span><br><span class="line">				phoneDetail.setType(type);</span><br><span class="line">				phoneDetail.setDatastr(dataStr);</span><br><span class="line">				dayPhoneDetail.addPhoneDetail(phoneDetail);</span><br><span class="line">			&#125;</span><br><span class="line">			Put put = new Put(rowkey.getBytes());</span><br><span class="line">			put.add("cf".getBytes(),"day".getBytes(),dayPhoneDetail.build().toByteArray());</span><br><span class="line">			puts.add(put);</span><br><span class="line">		&#125;</span><br><span class="line">		htable.put(puts);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	/**</span><br><span class="line">	 * 查看数据</span><br><span class="line">	 * @throws IOException</span><br><span class="line">	 */</span><br><span class="line">	@Test</span><br><span class="line">	public void getData() throws IOException&#123;</span><br><span class="line">		Get get = new Get("18962786962_9223370472247815807".getBytes());</span><br><span class="line">		Result result = htable.get(get);</span><br><span class="line">		Cell cell = result.getColumnLatestCell("cf".getBytes(), "day".getBytes());</span><br><span class="line">		dayPhoneDetail dayPhoneDetail = Phone.dayPhoneDetail.parseFrom(CellUtil.cloneValue(cell));</span><br><span class="line">		List&lt;PhoneDetail&gt; phoneDetailList = dayPhoneDetail.getPhoneDetailList();</span><br><span class="line">		int count = 0;</span><br><span class="line">		for (PhoneDetail pd : phoneDetailList) &#123;</span><br><span class="line">			System.out.println(pd.getDnum()+"\t"+pd.getType()+"\t"+pd.getLength()+"\t"+pd.getDatastr());</span><br><span class="line">			count ++;</span><br><span class="line">		&#125;</span><br><span class="line">		System.out.println("count:"+count);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<h2 id="HBase-优化"><a href="#HBase-优化" class="headerlink" title="HBase 优化"></a>HBase 优化</h2><h3 id="表设计"><a href="#表设计" class="headerlink" title="表设计"></a>表设计</h3><ul>
<li><p><strong>Region 切分</strong></p>
<p>在表设计时，预先估计表中的数据，并切分多个 region，防止数据过多，导致单个服务器过载。</p>
<p>Region 是按照 Rowkey 来切分的</p>
</li>
<li><p><strong>Rowkey 设计</strong></p>
<p>Rowkey 按照字典序排列（即 ASCII ）。Rowkey 的长度不要太长，符合业务需求即可。</p>
</li>
<li><p><strong>ColumnFamily 设计</strong></p>
<p>列族控制在 1~2 之间，不要超过 3 个列族</p>
</li>
<li><p><strong>InMemory</strong></p>
<p>HBase  中缓存分为写缓存和读缓存。通过 <code>HColumnDescriptor.setInMemory(true)</code> 将表放到RegionServer的缓存中，保证在读取的时候被cache命中。</p>
</li>
<li><p><strong><font color="red" size="3px">compact  &amp; split</font></strong></p>
<p>在 HBase 中，数据在更新时首先写入 WAL 日志(HLog)和内存(MemStore)中，MemStore 中的数据是排序的，当 MemStore 累计到一定阈值时，就会创建一个新的 MemStore，并且将老的 MemStore 添加到 flush队列，由单独的线程 flush 到磁盘上，成为一个 StoreFile 。于此同时， 系统会在 zookeeper 中记录一个 redo point，表示这个时刻之前的变更已经持久化了(minor compact)。<br><strong>StoreFile 是只读的</strong>，一旦创建后就不可以再修改。因此 Hbase 的更新其实是不断追加的操作。当一个 Store中的 StoreFile 达到一定的阈值后，就会进行一次合并(major compact)，将对同一个 key 的修改合并到一起，形成一个大的 StoreFile，当 StoreFile 的大小达到一定阈值后，又会对 StoreFile进行分割(split)，等分为两个StoreFile。<br>由于对表的更新是不断追加的，处理读请求时，需要访问Store中全部的StoreFile和MemStore，将它们按照row key进行合并，由于StoreFile和MemStore都是经过排序的，并且StoreFile带有内存中索引，通常合并过程还是比较快的。<br>实际应用中，可以考虑必要时手动进行major compact，将同一个row key的修改进行合并形成一个大的StoreFile。同时，可以将StoreFile设置大些，减少split的发生。</p>
<p>hbase为了防止小文件（被刷到磁盘的menstore）过多，以保证保证查询效率，hbase需要在必要的时候将这些小的store file合并成相对较大的store file，这个过程就称之为compaction。在hbase中，主要存在两种类型的compaction：minor  compaction和major compaction。<br>minor compaction:的是较小、很少文件的合并。<br>major compaction 的功能是将所有的store file合并成一个，触发major compaction的可能条件有：major_compact 命令、majorCompact() API、region server自动运行（相关参数：hbase.hregion.majoucompaction 默认为24 小时、hbase.hregion.majorcompaction.jetter 默认值为0.2 防止region server 在同一时间进行major compaction）。<br>hbase.hregion.majorcompaction.jetter参数的作用是：对参数hbase.hregion.majoucompaction 规定的值起到浮动的作用，假如两个参数都为默认值24和0,2，那么major compact最终使用的数值为：19.2~28.8 这个范围。</p>
<p>1、关闭自动major compaction<br>2、手动编程major compaction<br>Timer类，contab<br>minor compaction的运行机制要复杂一些，它由一下几个参数共同决定：<br>hbase.hstore.compaction.min :默认值为 3，表示至少需要三个满足条件的store file时，minor compaction才会启动<br>hbase.hstore.compaction.max 默认值为10，表示一次minor compaction中最多选取10个store file<br>hbase.hstore.compaction.min.size 表示文件大小小于该值的store file 一定会加入到minor compaction的store file中<br>hbase.hstore.compaction.max.size 表示文件大小大于该值的store file 一定会被minor compaction排除<br>hbase.hstore.compaction.ratio 将store file 按照文件年龄排序（older to younger），minor compaction总是从older store file开始选择</p>
</li>
</ul>
<h3 id="写表操作"><a href="#写表操作" class="headerlink" title="写表操作"></a>写表操作</h3><ol>
<li><p><strong>多 Table 并发写</strong></p>
<p>创建多个HTable客户端用于写操作，提高写数据的吞吐量，一个例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> Configuration conf = HBaseConfiguration.create();</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> String table_log_name = “user_log”;</span><br><span class="line">wTableLog = <span class="keyword">new</span> HTable[tableN];</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; tableN; i++) &#123;</span><br><span class="line">    wTableLog[i] = <span class="keyword">new</span> HTable(conf, table_log_name);</span><br><span class="line">    wTableLog[i].setWriteBufferSize(<span class="number">5</span> * <span class="number">1024</span> * <span class="number">1024</span>); <span class="comment">//5MB</span></span><br><span class="line">    wTableLog[i].setAutoFlush(<span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>HTable 参数设置：</strong></p>
<ul>
<li><p>Auto Flush </p>
<p>通过调用HTable.setAutoFlush(false)方法可以将HTable写客户端的自动flush关闭，这样可以批量写入数据到HBase，而不是有一条put就执行一次更新，只有当put填满客户端写缓存时，才实际向HBase服务端发起写请求。默认情况下auto flush是开启的。</p>
</li>
<li><p>Write Buffer</p>
<p>通过调用HTable.setWriteBufferSize(writeBufferSize)方法可以设置HTable客户端的写buffer大小，如果新设置的buffer小于当前写buffer中的数据时，buffer将会被flush到服务端。其中，writeBufferSize的单位是byte字节数，可以根据实际写入数据量的多少来设置该值。</p>
</li>
<li><p>WAL  Flag</p>
<p>在HBae中，客户端向集群中的RegionServer提交数据时（Put/Delete操作），首先会先写WAL（Write Ahead Log）日志（即HLog，一个RegionServer上的所有Region共享一个HLog），只有当WAL日志写成功后，再接着写MemStore，然后客户端被通知提交数据成功；如果写WAL日志失败，客户端则被通知提交失败。这样做的好处是可以做到RegionServer宕机后的数据恢复。</p>
<p>因此，对于相对不太重要的数据，可以在Put/Delete操作时，通过调用Put.setWriteToWAL(false)或Delete.setWriteToWAL(false)函数，放弃写WAL日志，从而提高数据写入的性能。</p>
<p><strong>值得注意的是：谨慎选择关闭WAL日志，因为这样的话，一旦RegionServer宕机，Put/Delete的数据将会无法根据WAL日志进行恢复。</strong></p>
</li>
</ul>
</li>
<li><p><strong>批量写</strong></p>
<p>通过调用HTable.put(Put)方法可以将一个指定的row key记录写入HBase，同样HBase提供了另一个方法：通过调用HTable.put(List<put>)方法可以将指定的row key列表，批量写入多行记录，这样做的好处是批量执行，只需要一次网络I/O开销，这对于对数据实时性要求高，网络传输RTT高的情景下可能带来明显的性能提升。</put></p>
</li>
<li><p>多线程并发写</p>
<p> 在客户端开启多个HTable写线程，每个写线程负责一个HTable对象的flush操作，这样结合定时flush和写buffer（writeBufferSize），可以既保证在数据量小的时候，数据可以在较短时间内被flush（如1秒内），同时又保证在数据量大的时候，写buffer一满就及时进行flush。下面给个具体的例子：</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; threadN; i++) &#123;</span><br><span class="line">    Thread th = <span class="keyword">new</span> Thread() &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    sleep(<span class="number">1000</span>); <span class="comment">//1 second</span></span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line"><span class="keyword">synchronized</span> (wTableLog[i]) &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        wTableLog[i].flushCommits();</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">&#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    th.setDaemon(<span class="keyword">true</span>);</span><br><span class="line">    th.start();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



</li>
</ol>
<h3 id="读表操作"><a href="#读表操作" class="headerlink" title="读表操作"></a>读表操作</h3><ol>
<li><p>多 HTable 并发读</p>
<p>创建多个HTable客户端用于读操作，提高读数据的吞吐量，一个例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">static final Configuration conf = HBaseConfiguration.create();</span><br><span class="line">static final String table_log_name = “user_log”;</span><br><span class="line">rTableLog = new HTable[tableN];</span><br><span class="line">for (int i = 0; i &lt; tableN; i++) &#123;</span><br><span class="line">    rTableLog[i] = new HTable(conf, table_log_name);</span><br><span class="line">    rTableLog[i].setScannerCaching(50);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>HTable 参数设置</p>
<ul>
<li>Scanner Caching<br>hbase.client.scanner.caching配置项可以设置HBase scanner一次从服务端抓取的数据条数，默认情况下一次一条。通过将其设置成一个合理的值，可以减少scan过程中next()的时间开销，代价是scanner需要通过客户端的内存来维持这些被cache的行记录。<br>有三个地方可以进行配置：1）在HBase的conf配置文件中进行配置；2）通过调用HTable.setScannerCaching(int scannerCaching)进行配置；3）通过调用Scan.setCaching(int caching)进行配置。三者的优先级越来越高。</li>
<li>Scan Attribute Selection<br>scan时指定需要的Column Family，可以减少网络传输数据量，否则默认scan操作会返回整行所有Column Family的数据。</li>
<li>Close ResultScanner<br>通过scan取完数据后，记得要关闭ResultScanner，否则RegionServer可能会出现问题（对应的Server资源无法释放）。</li>
</ul>
</li>
<li><p>批量读</p>
<p>通过调用HTable.get(Get)方法可以根据一个指定的row key获取一行记录，同样HBase提供了另一个方法：通过调用HTable.get(List<get>)方法可以根据一个指定的row key列表，批量获取多行记录，这样做的好处是批量执行，只需要一次网络I/O开销，这对于对数据实时性要求高而且网络传输RTT高的情景下可能带来明显的性能提升。</get></p>
</li>
<li><p>多线程并发读</p>
<p>在客户端开启多个HTable读线程，每个读线程负责通过HTable对象进行get操作。下面是一个多线程并发读取HBase，获取店铺一天内各分钟PV值的例子：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataReaderServer</span> </span>&#123;</span><br><span class="line">     <span class="comment">//获取店铺一天内各分钟PV值的入口函数</span></span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ConcurrentHashMap&lt;String, String&gt; <span class="title">getUnitMinutePV</span><span class="params">(<span class="keyword">long</span> uid, <span class="keyword">long</span> startStamp, <span class="keyword">long</span> endStamp)</span></span>&#123;</span><br><span class="line">         <span class="keyword">long</span> min = startStamp;</span><br><span class="line">         <span class="keyword">int</span> count = (<span class="keyword">int</span>)((endStamp - startStamp) / (<span class="number">60</span>*<span class="number">1000</span>));</span><br><span class="line">         List&lt;String&gt; lst = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">         <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt;= count; i++) &#123;</span><br><span class="line">            min = startStamp + i * <span class="number">60</span> * <span class="number">1000</span>;</span><br><span class="line">            lst.add(uid + <span class="string">"_"</span> + min);</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">return</span> parallelBatchMinutePV(lst);</span><br><span class="line">     &#125;</span><br><span class="line">      <span class="comment">//多线程并发查询，获取分钟PV值</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> ConcurrentHashMap&lt;String, String&gt; <span class="title">parallelBatchMinutePV</span><span class="params">(List&lt;String&gt; lstKeys)</span></span>&#123;</span><br><span class="line">        ConcurrentHashMap&lt;String, String&gt; hashRet = <span class="keyword">new</span> ConcurrentHashMap&lt;String, String&gt;();</span><br><span class="line">        <span class="keyword">int</span> parallel = <span class="number">3</span>;</span><br><span class="line">        List&lt;List&lt;String&gt;&gt; lstBatchKeys  = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (lstKeys.size() &lt; parallel )&#123;</span><br><span class="line">            lstBatchKeys  = <span class="keyword">new</span> ArrayList&lt;List&lt;String&gt;&gt;(<span class="number">1</span>);</span><br><span class="line">            lstBatchKeys.add(lstKeys);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            lstBatchKeys  = <span class="keyword">new</span> ArrayList&lt;List&lt;String&gt;&gt;(parallel);</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; parallel; i++  )&#123;</span><br><span class="line">                List&lt;String&gt; lst = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">                lstBatchKeys.add(lst);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; lstKeys.size() ; i ++ )&#123;</span><br><span class="line">                lstBatchKeys.get(i%parallel).add(lstKeys.get(i));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        List&lt;Future&lt; ConcurrentHashMap&lt;String, String&gt; &gt;&gt; futures = <span class="keyword">new</span> ArrayList&lt;Future&lt; ConcurrentHashMap&lt;String, String&gt; &gt;&gt;(<span class="number">5</span>);</span><br><span class="line">        </span><br><span class="line">        ThreadFactoryBuilder builder = <span class="keyword">new</span> ThreadFactoryBuilder();</span><br><span class="line">        builder.setNameFormat(<span class="string">"ParallelBatchQuery"</span>);</span><br><span class="line">        ThreadFactory factory = builder.build();</span><br><span class="line">        ThreadPoolExecutor executor = (ThreadPoolExecutor) Executors.newFixedThreadPool(lstBatchKeys.size(), factory);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(List&lt;String&gt; keys : lstBatchKeys)&#123;</span><br><span class="line">            Callable&lt; ConcurrentHashMap&lt;String, String&gt; &gt; callable = <span class="keyword">new</span> BatchMinutePVCallable(keys);</span><br><span class="line">            FutureTask&lt; ConcurrentHashMap&lt;String, String&gt; &gt; future = (FutureTask&lt; ConcurrentHashMap&lt;String, String&gt; &gt;) executor.submit(callable);</span><br><span class="line">            futures.add(future);</span><br><span class="line">        &#125;</span><br><span class="line">        executor.shutdown();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Wait for all the tasks to finish</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="keyword">boolean</span> stillRunning = !executor.awaitTermination(</span><br><span class="line">              <span class="number">5000000</span>, TimeUnit.MILLISECONDS);</span><br><span class="line">          <span class="keyword">if</span> (stillRunning) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                executor.shutdownNow();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                <span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">              Thread.currentThread().interrupt();</span><br><span class="line">          &#125; <span class="keyword">catch</span> (Exception e1) &#123;</span><br><span class="line">            <span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">            e1.printStackTrace();</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Look for any exception</span></span><br><span class="line">        <span class="keyword">for</span> (Future f : futures) &#123;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">              <span class="keyword">if</span>(f.get() != <span class="keyword">null</span>)</span><br><span class="line">              &#123;</span><br><span class="line">                  hashRet.putAll((ConcurrentHashMap&lt;String, String&gt;)f.get());</span><br><span class="line">              &#125;</span><br><span class="line">          &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                 Thread.currentThread().interrupt();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e1) &#123;</span><br><span class="line">                <span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">                e1.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">          &#125; <span class="keyword">catch</span> (ExecutionException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> hashRet;</span><br><span class="line">    &#125;</span><br><span class="line">     <span class="comment">//一个线程批量查询，获取分钟PV值</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">static</span> ConcurrentHashMap&lt;String, String&gt; <span class="title">getBatchMinutePV</span><span class="params">(List&lt;String&gt; lstKeys)</span></span>&#123;</span><br><span class="line">        ConcurrentHashMap&lt;String, String&gt; hashRet = <span class="keyword">null</span>;</span><br><span class="line">        List&lt;Get&gt; lstGet = <span class="keyword">new</span> ArrayList&lt;Get&gt;();</span><br><span class="line">        String[] splitValue = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">for</span> (String s : lstKeys) &#123;</span><br><span class="line">            splitValue = s.split(<span class="string">"_"</span>);</span><br><span class="line">            <span class="keyword">long</span> uid = Long.parseLong(splitValue[<span class="number">0</span>]);</span><br><span class="line">            <span class="keyword">long</span> min = Long.parseLong(splitValue[<span class="number">1</span>]);</span><br><span class="line">            <span class="keyword">byte</span>[] key = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">16</span>];</span><br><span class="line">            Bytes.putLong(key, <span class="number">0</span>, uid);</span><br><span class="line">            Bytes.putLong(key, <span class="number">8</span>, min);</span><br><span class="line">            Get g = <span class="keyword">new</span> Get(key);</span><br><span class="line">            g.addFamily(fp);</span><br><span class="line">            lstGet.add(g);</span><br><span class="line">        &#125;</span><br><span class="line">        Result[] res = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            res = tableMinutePV[rand.nextInt(tableN)].get(lstGet);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e1) &#123;</span><br><span class="line">            logger.error(<span class="string">"tableMinutePV exception, e="</span> + e1.getStackTrace());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (res != <span class="keyword">null</span> &amp;&amp; res.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            hashRet = <span class="keyword">new</span> ConcurrentHashMap&lt;String, String&gt;(res.length);</span><br><span class="line">            <span class="keyword">for</span> (Result re : res) &#123;</span><br><span class="line">                <span class="keyword">if</span> (re != <span class="keyword">null</span> &amp;&amp; !re.isEmpty()) &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        <span class="keyword">byte</span>[] key = re.getRow();</span><br><span class="line">                        <span class="keyword">byte</span>[] value = re.getValue(fp, cp);</span><br><span class="line">                        <span class="keyword">if</span> (key != <span class="keyword">null</span> &amp;&amp; value != <span class="keyword">null</span>) &#123;</span><br><span class="line">                            hashRet.put(String.valueOf(Bytes.toLong(key,</span><br><span class="line">                                    Bytes.SIZEOF_LONG)), String.valueOf(Bytes</span><br><span class="line">                                    .toLong(value)));</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (Exception e2) &#123;</span><br><span class="line">                        logger.error(e2.getStackTrace());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> hashRet;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//调用接口类，实现Callable接口</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BatchMinutePVCallable</span> <span class="keyword">implements</span> <span class="title">Callable</span>&lt;<span class="title">ConcurrentHashMap</span>&lt;<span class="title">String</span>, <span class="title">String</span>&gt;&gt;</span>&#123;</span><br><span class="line">     <span class="keyword">private</span> List&lt;String&gt; keys;</span><br><span class="line"></span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="title">BatchMinutePVCallable</span><span class="params">(List&lt;String&gt; lstKeys )</span> </span>&#123;</span><br><span class="line">         <span class="keyword">this</span>.keys = lstKeys;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     <span class="function"><span class="keyword">public</span> ConcurrentHashMap&lt;String, String&gt; <span class="title">call</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">         <span class="keyword">return</span> DataReadServer.getBatchMinutePV(keys);</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>缓存查询</p>
<p>对于频繁查询HBase的应用场景，可以考虑在应用程序中做缓存，当有新的查询请求时，首先在缓存中查找，如果存在则直接返回，不再查询HBase；否则对HBase发起读请求查询，然后在应用程序中将查询结果缓存起来。至于缓存的替换策略，可以考虑LRU等常用的策略。</p>
</li>
<li><p><font color="red">BlockCache</font></p>
<p>HBase上Regionserver 的内存分为两个部分，一部分作为 Memstore，主要用来写；另外一部分作为BlockCache，主要用于读。</p>
<p>写请求会先写入Memstore，Regionserver会给每个region提供一个Memstore，当Memstore满64MB以后，会启动 flush刷新到磁盘。当Memstore的总大小超过限制时（heapsize * hbase.regionserver.global.memstore.upperLimit * 0.9），会强行启动flush进程，从最大的Memstore开始flush直到低于限制。</p>
<p>读请求先到Memstore中查数据，查不到就到BlockCache中查，再查不到就会到磁盘上读，并把读的结果放入BlockCache。由于BlockCache采用的是LRU策略，因此BlockCache达到上限(heapsize * hfile.block.cache.size * 0.85)后，会启动淘汰机制，淘汰掉最老的一批数据。</p>
<p>一个Regionserver上有一个BlockCache和N个Memstore，它们的大小之和不能大于等于heapsize * 0.8，否则HBase不能启动。默认BlockCache为0.2，而Memstore为0.4。<strong>对于注重读响应时间的系统，可以将</strong> <strong>BlockCache设大些，比如设置BlockCache=0.4，Memstore=0.39，以加大缓存的命中率。</strong></p>
</li>
</ol>
<h3 id="HTable-和-HTablePool使用注意事项"><a href="#HTable-和-HTablePool使用注意事项" class="headerlink" title="HTable 和 HTablePool使用注意事项"></a>HTable 和 HTablePool使用注意事项</h3><p>HTable和HTablePool都是HBase客户端API的一部分，可以使用它们对HBase表进行CRUD操作。下面结合在项目中的应用情况，对二者使用过程中的注意事项做一下概括总结。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Configuration conf = HBaseConfiguration.create();</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> (Connection connection = ConnectionFactory.createConnection(conf)) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> (Table table = connection.getTable(TableName.valueOf(tablename)) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// use table as needed, the table returned is lightweight</span></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="HTable"><a href="#HTable" class="headerlink" title="HTable"></a>HTable</h3><p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html" target="_blank" rel="noopener">HTable</a>是HBase客户端与HBase服务端通讯的Java API对象，客户端可以通过HTable对象与服务端进行CRUD操作（增删改查）。它的创建很简单：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Configuration conf = HBaseConfiguration.create();</span><br><span class="line"></span><br><span class="line">HTable table = <span class="keyword">new</span> HTable(conf, <span class="string">"tablename"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//TODO CRUD Operation……</span></span><br></pre></td></tr></table></figure>

<p>HTable使用时的一些注意事项：</p>
<ol>
<li><p>规避 HTable 对象的创建开销<br>因为客户端创建 HTable 对象后，需要进行一系列的操作：检查.META.表确认指定名称的HBase表是否存在，表是否有效等等，整个时间开销比较重，可能会耗时几秒钟之长，因此最好在程序启动时一次性创建完成需要的HTable对象，如果使用 Java API，一般来说是在构造函数中进行创建，程序启动后直接重用。</p>
</li>
<li><p>HTable 对象不是线程安全的<br>HTable 对象对于客户端读写数据来说不是线程安全的，因此多线程时，要为每个线程单独创建复用一个HTable 对象，不同对象间不要共享HTable对象使用，特别是在客户端auto flash被置为false时，由于存在本地write buffer，可能导致数据不一致。</p>
</li>
<li><p>HTable对象之间共享Configuration<br>HTable对象共享Configuration对象，这样的好处在于：</p>
</li>
</ol>
<ul>
<li>共享ZooKeeper的连接：每个客户端需要与ZooKeeper建立连接，查询用户的table regions位置，这些信息可以在连接建立后缓存起来共享使用；</li>
<li>共享公共的资源：客户端需要通过ZooKeeper查找-ROOT-和.META.表，这个需要网络传输开销，客户端缓存这些公共资源后能够减少后续的网络传输开销，加快查找过程速度。</li>
</ul>
<p>因此，与以下这种方式相比：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HTable table1 = <span class="keyword">new</span> HTable(<span class="string">"table1"</span>);</span><br><span class="line"></span><br><span class="line">HTable table2 = <span class="keyword">new</span> HTable(<span class="string">"table2"</span>);</span><br></pre></td></tr></table></figure>

<p>下面的方式更有效些：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Configuration conf = HBaseConfiguration.create();</span><br><span class="line"></span><br><span class="line">HTable table1 = <span class="keyword">new</span> HTable(conf, <span class="string">"table1"</span>);</span><br><span class="line"></span><br><span class="line">HTable table2 = <span class="keyword">new</span> HTable(conf, <span class="string">"table2"</span>);</span><br></pre></td></tr></table></figure>

<p>备注：即使是高负载的多线程程序，也并没有发现因为共享Configuration而导致的性能问题；如果你的实际情况中不是如此，那么可以尝试不共享Configuration。</p>
<h3 id="HTablePool"><a href="#HTablePool" class="headerlink" title="HTablePool"></a>HTablePool</h3><p><a href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTablePool.html" target="_blank" rel="noopener">HTablePool</a>可以解决HTable存在的线程不安全问题，同时通过维护固定数量的HTable对象，能够在程序运行期间复用这些HTable资源对象。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Configuration conf = HBaseConfiguration.create();</span><br><span class="line"></span><br><span class="line">HTablePool pool = <span class="keyword">new</span> HTablePool(conf, <span class="number">10</span>);</span><br></pre></td></tr></table></figure>

<ol>
<li><p>HTablePool可以自动创建HTable对象，而且对客户端来说使用上是完全透明的，可以避免多线程间数据并发修改问题。</p>
</li>
<li><p>HTablePool中的HTable对象之间是公用Configuration连接的，能够可以减少网络开销。</p>
</li>
</ol>
<p>HTablePool的使用很简单：每次进行操作前，通过HTablePool的getTable方法取得一个HTable对象，然后进行put/get/scan/delete等操作，最后通过 HTablePool 的 putTable 方法将HTable对象放回到HTablePool中。</p>
<p>下面是个使用HTablePool的简单例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">public void createUser(String username, String firstName, String lastName, String email, String password, String roles) throws IOException &#123;</span><br><span class="line"></span><br><span class="line">　　HTable table = rm.getTable(UserTable.NAME);</span><br><span class="line"></span><br><span class="line">　　Put put = new Put(Bytes.toBytes(username));</span><br><span class="line"></span><br><span class="line">　　put.add(UserTable.DATA_FAMILY, UserTable.FIRSTNAME,</span><br><span class="line"></span><br><span class="line">　　Bytes.toBytes(firstName));</span><br><span class="line"></span><br><span class="line">　　put.add(UserTable.DATA_FAMILY, UserTable.LASTNAME,</span><br><span class="line"></span><br><span class="line">　　　　Bytes.toBytes(lastName));</span><br><span class="line"></span><br><span class="line">　　put.add(UserTable.DATA_FAMILY, UserTable.EMAIL, Bytes.toBytes(email));</span><br><span class="line"></span><br><span class="line">　　put.add(UserTable.DATA_FAMILY, UserTable.CREDENTIALS,</span><br><span class="line"></span><br><span class="line">　　　　Bytes.toBytes(password));</span><br><span class="line"></span><br><span class="line">　　put.add(UserTable.DATA_FAMILY, UserTable.ROLES, Bytes.toBytes(roles));</span><br><span class="line"></span><br><span class="line">　　table.put(put);</span><br><span class="line"></span><br><span class="line">　　table.flushCommits();</span><br><span class="line"></span><br><span class="line">　　rm.putTable(table);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>Hbase和DBMS比较：</p>
<p>查询数据不灵活：</p>
<ol>
<li><p>不能使用column之间过滤查询</p>
</li>
<li><p>不支持全文索引。使用solr和hbase整合完成全文搜索。</p>
<p>a) 使用MR批量读取hbase中的数据，在solr里面建立索引（no  store）之保存rowkey的值。</p>
<p>b) 根据关键词从索引中搜索到rowkey（分页）</p>
<p>c) 根据rowkey从hbase查询所有数据</p>
</li>
</ol>
<h2 id="HBase-MapReduce-整合"><a href="#HBase-MapReduce-整合" class="headerlink" title="HBase-MapReduce 整合"></a>HBase-MapReduce 整合</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://zwer.xyz/2019/10/12/20191012 Hive/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zwer">
      <meta itemprop="description" content="记录学习的日常">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zwer 的博客空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/10/12/20191012 Hive/" class="post-title-link" itemprop="url">20191012 Hive</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-10-12 00:00:00" itemprop="dateCreated datePublished" datetime="2019-10-12T00:00:00+08:00">2019-10-12</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-11-04 10:30:12" itemprop="dateModified" datetime="2019-11-04T10:30:12+08:00">2019-11-04</time>
              </span>
            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h2 id="Hive-简介"><a href="#Hive-简介" class="headerlink" title="Hive 简介"></a>Hive 简介</h2><ul>
<li>Hive 数据仓库</li>
<li>Hive 解释器，编译器，优化器</li>
<li>Hive 运行时，元数据存储在关系型数据库里面</li>
</ul>
<h2 id="Hive-架构"><a href="#Hive-架构" class="headerlink" title="Hive 架构"></a>Hive 架构</h2><p>CLI： command line  interface  命令行接口</p>
<p>JDBC/ODBC:    Java 连接数据库（MySQL、Oracle）</p>
<p>Web GUI：  Hive web 用户界面</p>
<p>metastore：表、字段的约束</p>
<p>Driver： Driver 服务，负责 Hadoop 和 Hive 之间的联系（）</p>
<img src="http://img.zwer.xyz/blog/20191012192509.png" style="zoom:50%;">


<p>（1）用户接口主要有三个：CLI，Client 和 WUI。其中最常用的是CLI，Cli启动的时候，会同时启动一个Hive副本。Client是Hive的客户端，用户连接至Hive Server。在启动 Client模式的时候，需要指出Hive Server所在节点，并且在该节点启动Hive Server。 WUI是通过浏览器访问Hive。<br>（2）Hive将元数据存储在数据库中，如mysql、derby。Hive中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。<br>（3）解释器、编译器、优化器完成HQL查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在HDFS中，并在随后有MapReduce调用执行。<br>（4）Hive的数据存储在HDFS中，大部分的查询、计算由MapReduce完成（包含*的查询，比如select * from tbl不会生成MapRedcue任务）。</p>
<img src="http://img.zwer.xyz/blog/20191012192548.png" style="zoom:50%;">



<h3 id="Hive-的架构"><a href="#Hive-的架构" class="headerlink" title="Hive 的架构"></a>Hive 的架构</h3><p>编译器将一个Hive SQL转换操作符<br>操作符是Hive的最小的处理单元<br>每个操作符代表HDFS的一个操作或者一道MapReduce作业</p>
<h3 id="Operator"><a href="#Operator" class="headerlink" title="Operator"></a>Operator</h3><p>Operator都是hive定义的一个处理过程<br>Operator都定义有:<br>protected List &lt;Operator&lt;?  extends Serializable &gt;&gt; childOperators;<br>protected List &lt;Operator&lt;?  extends Serializable &gt;&gt; parentOperators;<br>protected boolean done; // 初始化值为false</p>
<p><img src="http://img.zwer.xyz/blog/20191012192638.png" alt></p>
<ul>
<li>ANTER 词法语法分析工具解析 SQL</li>
</ul>
<img src="http://img.zwer.xyz/blog/20191012192647.png" style="zoom: 67%;">

<h2 id="Hive-搭建模式"><a href="#Hive-搭建模式" class="headerlink" title="Hive 搭建模式"></a>Hive 搭建模式</h2><h3 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h3><blockquote>
<p>通过网络连接到一个数据库中</p>
</blockquote>
<p><img src="http://img.zwer.xyz/blog/20191012203656.png" alt></p>
<p>节点部署：</p>
<table>
<thead>
<tr>
<th>HOST/Soft</th>
<th>MySQL</th>
<th>Hive</th>
</tr>
</thead>
<tbody><tr>
<td>node01/192.168.170.101</td>
<td>*</td>
<td></td>
</tr>
<tr>
<td>hode02/192.168.170.102</td>
<td></td>
<td>*</td>
</tr>
</tbody></table>
<p>搭建过程步骤：</p>
<ul>
<li><p><strong>安装 MySQL</strong></p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 安装 mysql 服务</span><br><span class="line">yum install mysql-server -y </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 输入 msyql  会出现这样的错误信息， 原因是 mysqld 服务未启动</span><br><span class="line"><span class="meta">#</span> ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 启动 mysqld 服务</span><br><span class="line">service mysqld start</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 配置 mysql 远程连接以及用户名和密码</span><br><span class="line">grant all privileges on *.* to root@'%' identified by '123' with grant option;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 刷新权限</span><br><span class="line">flush privileges;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 删除 mysql.user 表中的除了远程连接用户外其他用户的记录</span><br><span class="line">delete from user where mysql.host != '%'</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>  查看 mysql 用户表</span><br><span class="line">select host,user,password from mysql.user</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>安装 Hive</strong> </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">  #</span> 安装 hive</span><br><span class="line"><span class="meta">  #</span> 上传 hive 压缩包并解压</span><br><span class="line">tar -zxvf hive.x.y.z.tar.gz</span><br><span class="line"><span class="meta">  #</span> 移动到 /opt/sxt 目录下</span><br><span class="line">  mv  hive.x.y.z  /opt/sxt</span><br><span class="line"><span class="meta">  #</span> 配置 hive 环境变量,编辑 vi /etc/profile 文件</span><br><span class="line">  export HIVE_HOME=/opt/sxt/hive.x.y.z</span><br><span class="line">  export PATH=$PATH:$HIVE_HOME/bin</span><br><span class="line"><span class="meta">  #</span> 使  /etc/profile 生效</span><br><span class="line">  . /etc/profile</span><br><span class="line"><span class="meta">  #</span> 输入 hive 命令，查看 hive 是否安装成功</span><br><span class="line">  </span><br><span class="line"><span class="meta">  #</span> 修改配置文件</span><br><span class="line">  cp hive-.xml  hive-site.xml  </span><br><span class="line">  vi hive-site.xml</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;/user/hive_remote/warehouse&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;jdbc:mysql://node01/hive_remote?createDatabaseIfNotExist=true&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;123&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line"><span class="meta">  #</span> 更新 jar  资源</span><br><span class="line"><span class="meta">  #</span> 将 jline.jar 调整为高版本，同时将 hadoop 的低版本删除</span><br><span class="line">  cd $HODOOP_HOME/share/hadoop/yarn/lib/ </span><br><span class="line">  rm -fr jline-0.9.94.jar </span><br><span class="line">  cp $HIVE_HOME/lib/jline-2.12.jar ./ </span><br><span class="line">  </span><br><span class="line"><span class="meta">  #</span> 启动</span><br><span class="line">  hive</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h3 id="分布式模式"><a href="#分布式模式" class="headerlink" title="分布式模式"></a>分布式模式</h3><blockquote>
<p>用于非Java客户端访问元数据库，在服务器端启动 MetaStoreServer，客户端利用 Thrift 协议通过MetaStoreServer访问元数据库</p>
</blockquote>
<p><img src="http://img.zwer.xyz/blog/20191012220336.png" alt></p>
<p><strong>搭建环境准备：</strong></p>
<table>
<thead>
<tr>
<th></th>
<th>mysql</th>
<th>hive-server</th>
<th>hive-client</th>
</tr>
</thead>
<tbody><tr>
<td>node01</td>
<td>*</td>
<td></td>
<td></td>
</tr>
<tr>
<td>node03</td>
<td></td>
<td>*</td>
<td></td>
</tr>
<tr>
<td>node04</td>
<td></td>
<td></td>
<td>*</td>
</tr>
</tbody></table>
<p><strong>搭建步骤：</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 搭建分布式 Hive 是建立在单机模式之上</span><br><span class="line"><span class="meta">#</span> 从之前的 node02 节点上拷贝 $HIVE_HOME 目录 到 node03、node04 上</span><br><span class="line"><span class="meta">#</span> 其中 node03 作为 Hive 服务端， node04 作为 Hive 客户端</span><br><span class="line">scp -r apache-hive-1.2.1-bin/ root@node03:`pwd`/ </span><br><span class="line">scp -r apache-hive-1.2.1-bin/ root@node04:`pwd`/ </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 配置 node03 node04 的 HIVE 环境变量</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 更新 jar 资源</span><br><span class="line"><span class="meta">#</span> 将 jline.jar 调整为高版本，同时将 hadoop 的低版本删除</span><br><span class="line">cd $HODOOP_HOME/share/hadoop/yarn/lib/ </span><br><span class="line">rm -fr jline-0.9.94.jar </span><br><span class="line">cp $HIVE_HOME/lib/jline-2.12.jar ./ </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 在 node03 上 启动 hive metastore 服务</span><br><span class="line">hive --service metastore</span><br><span class="line"><span class="meta">#</span> 在 node04 上启用 hive 客户端</span><br><span class="line">hive</span><br></pre></td></tr></table></figure>

<p><strong>配置环境变量的目的：</strong></p>
<ol>
<li>找可执行性文件</li>
<li>方便其他框架或者服务使用。 eg: HIVE 通过 HADOOP 的环境变量连接到 Hadoop 上</li>
</ol>
<h2 id="Hive-之-DDL"><a href="#Hive-之-DDL" class="headerlink" title="Hive 之 DDL"></a>Hive 之 DDL</h2><p>官方文档地址：</p>
<p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-Overview" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-Overview</a></p>
<h3 id="DDL-语法"><a href="#DDL-语法" class="headerlink" title="DDL 语法"></a>DDL 语法</h3><ul>
<li><strong>创建表</strong></li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">TEMPORARY</span>] [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [<span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]table_name    <span class="comment">-- (<span class="doctag">Note:</span> TEMPORARY available in Hive 0.14.0 and later)</span></span><br><span class="line">  [(col_name data_type [column_constraint_specification] [<span class="keyword">COMMENT</span> col_comment], ... [constraint_specification])]</span><br><span class="line">  [<span class="keyword">COMMENT</span> table_comment]</span><br><span class="line">  [PARTITIONED <span class="keyword">BY</span> (col_name data_type [<span class="keyword">COMMENT</span> col_comment], ...)]</span><br><span class="line">  [CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...) [SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span>|<span class="keyword">DESC</span>], ...)] <span class="keyword">INTO</span> num_buckets BUCKETS]</span><br><span class="line">  [SKEWED <span class="keyword">BY</span> (col_name, col_name, ...)                  <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.10.0 and later)]</span></span><br><span class="line">     <span class="keyword">ON</span> ((col_value, col_value, ...), (col_value, col_value, ...), ...)</span><br><span class="line">     [<span class="keyword">STORED</span> <span class="keyword">AS</span> DIRECTORIES]</span><br><span class="line">  [</span><br><span class="line">   [<span class="keyword">ROW</span> <span class="keyword">FORMAT</span> row_format] </span><br><span class="line">   [<span class="keyword">STORED</span> <span class="keyword">AS</span> file_format]</span><br><span class="line">     | <span class="keyword">STORED</span> <span class="keyword">BY</span> <span class="string">'storage.handler.class.name'</span> [<span class="keyword">WITH</span> SERDEPROPERTIES (...)]  <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.6.0 and later)</span></span><br><span class="line">  ]</span><br><span class="line">  [LOCATION hdfs_path]</span><br><span class="line">  [TBLPROPERTIES (property_name=property_value, ...)]   <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.6.0 and later)</span></span><br><span class="line">  [<span class="keyword">AS</span> select_statement];   <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.5.0 and later; not supported for external tables)</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">TEMPORARY</span>] [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [<span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]table_name</span><br><span class="line">  <span class="keyword">LIKE</span> existing_table_or_view_name</span><br><span class="line">  [LOCATION hdfs_path];</span><br><span class="line"> </span><br><span class="line">data_type</span><br><span class="line">  : primitive_type</span><br><span class="line">  | array_type</span><br><span class="line">  | map_type</span><br><span class="line">  | struct_type</span><br><span class="line">  | union_type  <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.7.0 and later)</span></span><br><span class="line"> </span><br><span class="line">primitive_type</span><br><span class="line">  : TINYINT</span><br><span class="line">  | SMALLINT</span><br><span class="line">  | INT</span><br><span class="line">  | BIGINT</span><br><span class="line">  | BOOLEAN</span><br><span class="line">  | FLOAT</span><br><span class="line">  | DOUBLE</span><br><span class="line">  | DOUBLE PRECISION <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 2.2.0 and later)</span></span><br><span class="line">  | STRING</span><br><span class="line">  | BINARY      <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.8.0 and later)</span></span><br><span class="line">  | TIMESTAMP   <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.8.0 and later)</span></span><br><span class="line">  | DECIMAL     <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.11.0 and later)</span></span><br><span class="line">  | DECIMAL(precision, scale)  <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.13.0 and later)</span></span><br><span class="line">  | DATE        <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.12.0 and later)</span></span><br><span class="line">  | VARCHAR     <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.12.0 and later)</span></span><br><span class="line">  | CHAR        <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.13.0 and later)</span></span><br><span class="line"> </span><br><span class="line">array_type</span><br><span class="line">  : ARRAY &lt; data_type &gt;</span><br><span class="line"> </span><br><span class="line">map_type</span><br><span class="line">  : MAP &lt; primitive_type, data_type &gt;</span><br><span class="line"> </span><br><span class="line">struct_type</span><br><span class="line">  : STRUCT &lt; col_name : data_type [COMMENT col_comment], ...&gt;</span><br><span class="line"> </span><br><span class="line">union_type</span><br><span class="line">   : UNIONTYPE &lt; data_type, data_type, ... &gt;  -- (Note: Available in Hive 0.7.0 and later)</span><br><span class="line"> </span><br><span class="line">row_format</span><br><span class="line">  : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS TERMINATED BY char]</span><br><span class="line">        [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]</span><br><span class="line">        [NULL DEFINED AS char]   <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.13 and later)</span></span><br><span class="line">  | SERDE serde_name [<span class="keyword">WITH</span> SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]</span><br><span class="line"> </span><br><span class="line">file_format:</span><br><span class="line">  : SEQUENCEFILE</span><br><span class="line">  | TEXTFILE    <span class="comment">-- (Default, depending on hive.default.fileformat configuration)</span></span><br><span class="line">  | RCFILE      <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.6.0 and later)</span></span><br><span class="line">  | ORC         <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.11.0 and later)</span></span><br><span class="line">  | PARQUET     <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.13.0 and later)</span></span><br><span class="line">  | AVRO        <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 0.14.0 and later)</span></span><br><span class="line">  | JSONFILE    <span class="comment">-- (<span class="doctag">Note:</span> Available in Hive 4.0.0 and later)</span></span><br><span class="line">  | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname</span><br><span class="line"> </span><br><span class="line">column_constraint_specification:</span><br><span class="line">  : [ PRIMARY <span class="keyword">KEY</span>|<span class="keyword">UNIQUE</span>|<span class="keyword">NOT</span> <span class="literal">NULL</span>|<span class="keyword">DEFAULT</span> [default_value]|<span class="keyword">CHECK</span>  [check_expression] <span class="keyword">ENABLE</span>|<span class="keyword">DISABLE</span> <span class="keyword">NOVALIDATE</span> <span class="keyword">RELY</span>/<span class="keyword">NORELY</span> ]</span><br><span class="line"> </span><br><span class="line">default_value:</span><br><span class="line">  : [ LITERAL|<span class="keyword">CURRENT_USER</span>()|<span class="keyword">CURRENT_DATE</span>()|<span class="keyword">CURRENT_TIMESTAMP</span>()|<span class="literal">NULL</span> ] </span><br><span class="line"> </span><br><span class="line">constraint_specification:</span><br><span class="line">  : [, PRIMARY <span class="keyword">KEY</span> (col_name, ...) <span class="keyword">DISABLE</span> <span class="keyword">NOVALIDATE</span> <span class="keyword">RELY</span>/<span class="keyword">NORELY</span> ]</span><br><span class="line">    [, PRIMARY <span class="keyword">KEY</span> (col_name, ...) <span class="keyword">DISABLE</span> <span class="keyword">NOVALIDATE</span> <span class="keyword">RELY</span>/<span class="keyword">NORELY</span> ]</span><br><span class="line">    [, <span class="keyword">CONSTRAINT</span> constraint_name <span class="keyword">FOREIGN</span> <span class="keyword">KEY</span> (col_name, ...) <span class="keyword">REFERENCES</span> table_name(col_name, ...) <span class="keyword">DISABLE</span> <span class="keyword">NOVALIDATE</span> </span><br><span class="line">    [, <span class="keyword">CONSTRAINT</span> constraint_name <span class="keyword">UNIQUE</span> (col_name, ...) <span class="keyword">DISABLE</span> <span class="keyword">NOVALIDATE</span> <span class="keyword">RELY</span>/<span class="keyword">NORELY</span> ]</span><br><span class="line">    [, <span class="keyword">CONSTRAINT</span> constraint_name <span class="keyword">CHECK</span> [check_expression] <span class="keyword">ENABLE</span>|<span class="keyword">DISABLE</span> <span class="keyword">NOVALIDATE</span> <span class="keyword">RELY</span>/<span class="keyword">NORELY</span> ]</span><br></pre></td></tr></table></figure>

<p>练习： </p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> psn</span><br><span class="line">(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span>,</span><br><span class="line"><span class="keyword">name</span> <span class="keyword">string</span>,</span><br><span class="line">likes <span class="built_in">array</span>&lt;<span class="keyword">string</span>&gt;,</span><br><span class="line">address <span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="keyword">string</span>&gt;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span></span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span></span><br><span class="line">collection items <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'-'</span></span><br><span class="line"><span class="keyword">map</span> <span class="keyword">keys</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">':'</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/root/data/data'</span> <span class="keyword">into</span> <span class="keyword">table</span> psn;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查看表结构</span></span><br><span class="line">desc formatted 表名</span><br></pre></td></tr></table></figure>

<h2 id="Hive-表"><a href="#Hive-表" class="headerlink" title="Hive 表"></a>Hive 表</h2><h3 id="内部表"><a href="#内部表" class="headerlink" title="内部表"></a>内部表</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> psn3</span><br><span class="line">(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span>,</span><br><span class="line"><span class="keyword">name</span> <span class="keyword">string</span>,</span><br><span class="line">likes <span class="built_in">array</span>&lt;<span class="keyword">string</span>&gt;,</span><br><span class="line">address <span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="keyword">string</span>&gt;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span></span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\001'</span></span><br><span class="line">collection items <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\002'</span></span><br><span class="line"><span class="keyword">map</span> <span class="keyword">keys</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\003'</span>;</span><br></pre></td></tr></table></figure>

<h3 id="外部表"><a href="#外部表" class="headerlink" title="外部表"></a>外部表</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> psn4</span><br><span class="line">(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span>,</span><br><span class="line"><span class="keyword">name</span> <span class="keyword">string</span>,</span><br><span class="line">likes <span class="built_in">array</span>&lt;<span class="keyword">string</span>&gt;,</span><br><span class="line">address <span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="keyword">string</span>&gt;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span></span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span></span><br><span class="line">collection items <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'-'</span></span><br><span class="line"><span class="keyword">map</span> <span class="keyword">keys</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">':'</span></span><br><span class="line">location <span class="string">'/data/hive/input/'</span>;</span><br></pre></td></tr></table></figure>

<h3 id="区别"><a href="#区别" class="headerlink" title="区别*"></a><font color="pinkbrown">区别*</font></h3><table>
<thead>
<tr>
<th></th>
<th>内部表 MANAGED</th>
<th>外部表 EXTERNAL</th>
</tr>
</thead>
<tbody><tr>
<td>创建表时</td>
<td>直接存储在默认的hdfs路径</td>
<td>需要自己指定路径</td>
</tr>
<tr>
<td>删除表时</td>
<td>将数据和元数据全部删除</td>
<td>只删除元数据，数据不删除</td>
</tr>
</tbody></table>
<p><strong>先有表，后有数据，使用内部表。先有数据，后有表，使用外部表。</strong></p>
<p>注意： </p>
<ol>
<li>删除外部表中不会删除 HDFS 中的数据</li>
<li><strong>Hive 读时检查（解耦，便于数据读取）; 关系数据库 写时检查</strong></li>
</ol>
<h2 id="Hive-分区"><a href="#Hive-分区" class="headerlink" title="Hive 分区"></a>Hive 分区</h2><blockquote>
<p><strong>分区表的意义在于优化查询。查询时尽量利用分区字段。如果不使用分区字段，就会全部扫描。</strong></p>
</blockquote>
<p>注意：分区属于元数据，不能通过外部表直接从 HDFS 加载 Hive 中，必须在表定义时指定对应的partition字段</p>
<h3 id="分区建表"><a href="#分区建表" class="headerlink" title="分区建表"></a>分区建表</h3><p>a. 单分区建表语句：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> day_table (<span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">content</span> <span class="keyword">string</span>) partitioned <span class="keyword">by</span> (dt <span class="keyword">string</span>);</span><br></pre></td></tr></table></figure>

<p>单分区表，按天分区，在表结构中存在 id，content，dt 三列。<br>以 dt 为文件夹区分</p>
<p>b. 双分区建表语句：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> day_hour_table (<span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">content</span> <span class="keyword">string</span>) partitioned <span class="keyword">by</span> (dt <span class="keyword">string</span>, <span class="keyword">hour</span> <span class="keyword">string</span>);</span><br></pre></td></tr></table></figure>

<p>双分区表，按天和小时分区，在表结构中新增加了 dt 和 hour 两列。<br>先以 dt 为文件夹，再以 hour 子文件夹区分</p>
<h3 id="添加分区表语法"><a href="#添加分区表语法" class="headerlink" title="添加分区表语法"></a>添加分区表语法</h3><blockquote>
<p>（表已创建，在此基础上添加分区）：<br>ALTER TABLE table_name ADD [IF NOT EXISTS] PARTITION partition_spec  [LOCATION ‘location1’] partition_spec [LOCATION ‘location2’] …;</p>
</blockquote>
<dl><dt>partition_spec:</dt><dd>(partition_column = partition_col_value, partition_column = partition_col_value, …)<br>例：</dd></dl><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> day_table <span class="keyword">ADD</span> <span class="keyword">PARTITION</span> (dt=<span class="string">'2008-08-08'</span>, <span class="keyword">hour</span>=<span class="string">'08'</span>)</span><br></pre></td></tr></table></figure>

<h3 id="删除分区"><a href="#删除分区" class="headerlink" title="删除分区"></a>删除分区</h3><dl><dt>LTER TABLE table_name DROP partition_spec, partition_spec,…<br>partition_spec:</dt><dd>(partition_column = partition_col_value, partition_column = partition_col_value, …)</dd></dl><p>用户可以用 ALTER TABLE DROP PARTITION 来删除分区。<br>内部表中、对应分区的元数据和数据将被一并删除。</p>
<p>例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> day_hour_table <span class="keyword">DROP</span> <span class="keyword">PARTITION</span> (dt=<span class="string">'2008-08-08'</span>, <span class="keyword">hour</span>=<span class="string">'09'</span>);</span><br></pre></td></tr></table></figure>

<h3 id="向指定分区添加数据语法"><a href="#向指定分区添加数据语法" class="headerlink" title="向指定分区添加数据语法"></a>向指定分区添加数据语法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">LOAD</span> <span class="keyword">DATA</span> [<span class="keyword">LOCAL</span>] INPATH <span class="string">'filepath'</span> [OVERWRITE] </span><br><span class="line"><span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1=val1, partcol2=val2 ...)]</span><br></pre></td></tr></table></figure>

<p>例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 从 HDFS 中加载数据</span></span><br><span class="line"><span class="keyword">LOAD</span> <span class="keyword">DATA</span> INPATH <span class="string">'/user/pv.txt'</span> </span><br><span class="line"><span class="keyword">INTO</span> <span class="keyword">TABLE</span> day_hour_table <span class="keyword">PARTITION</span>(dt=<span class="string">'2008-08- 08'</span>, <span class="keyword">hour</span>=<span class="string">'08'</span>); </span><br><span class="line"></span><br><span class="line"><span class="comment">-- 从本地文件系统中加载数据</span></span><br><span class="line"><span class="keyword">LOAD</span> <span class="keyword">DATA</span> <span class="keyword">local</span> INPATH <span class="string">'/user/hua/*'</span> </span><br><span class="line"><span class="keyword">INTO</span> <span class="keyword">TABLE</span> day_hour <span class="keyword">partition</span>(dt=<span class="string">'2010-07- 07'</span>);</span><br></pre></td></tr></table></figure>

<p>当数据被加载至表中时，不会对数据进行任何转换。</p>
<p>Load 操作<strong>只是将数据复制至 Hive 表对应的位置。数据加载时在表下自动创建一个目录</strong>。</p>
<h3 id="查询执行分区语法"><a href="#查询执行分区语法" class="headerlink" title="查询执行分区语法"></a>查询执行分区语法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> day_table.* <span class="keyword">FROM</span> day_table <span class="keyword">WHERE</span> day_table.dt&gt;= <span class="string">'2008-08-08'</span>;</span><br></pre></td></tr></table></figure>

<p><strong>分区表的意义在于优化查询。查询时尽量利用分区字段。如果不使用分区字段，就会全部扫描。</strong></p>
<h3 id="Hive查询表的分区信息语法"><a href="#Hive查询表的分区信息语法" class="headerlink" title="Hive查询表的分区信息语法"></a>Hive查询表的分区信息语法</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> <span class="keyword">PARTITIONS</span> day_hour_table;</span><br></pre></td></tr></table></figure>

<p>预先导入分区数据，但是无法识别怎么办？</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Msck <span class="keyword">repair</span> <span class="keyword">table</span> tablename</span><br></pre></td></tr></table></figure>

<p>直接添加分区</p>
<h3 id="动态分区"><a href="#动态分区" class="headerlink" title="动态分区"></a>动态分区</h3><ul>
<li><p><strong>开启支持动态分区</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition=<span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<p>默认：true</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode=nostrict;</span><br></pre></td></tr></table></figure>

<p>默认：strict（至少有一个分区列是静态分区）<br>相关参数</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.max.dynamic.partitions.pernode;</span><br></pre></td></tr></table></figure>

<p>每一个执行mr节点上，允许创建的动态分区的最大数量(100)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.max.dynamic.partitions;</span><br></pre></td></tr></table></figure>

<p>所有执行mr节点上，允许创建的所有动态分区的最大数量(1000)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.max.created.files;</span><br></pre></td></tr></table></figure>

<p>所有的mr job允许创建的文件的最大数量(100000)</p>
</li>
<li><p><strong>加载数据</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> psn21(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span>,</span><br><span class="line"><span class="keyword">name</span> <span class="keyword">string</span>,</span><br><span class="line">sex <span class="keyword">string</span>,</span><br><span class="line">age <span class="built_in">int</span>,</span><br><span class="line">likes <span class="built_in">array</span>&lt;<span class="keyword">string</span>&gt;,</span><br><span class="line">address <span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="keyword">string</span>&gt;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span></span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span></span><br><span class="line">collection items <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'-'</span></span><br><span class="line"><span class="keyword">map</span> <span class="keyword">keys</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">':'</span></span><br><span class="line">location <span class="string">'/data/bucket/input'</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> psn22(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span>,</span><br><span class="line"><span class="keyword">name</span> <span class="keyword">string</span>,</span><br><span class="line">likes <span class="built_in">array</span>&lt;<span class="keyword">string</span>&gt;,</span><br><span class="line">address <span class="keyword">map</span>&lt;<span class="keyword">string</span>,<span class="keyword">string</span>&gt;</span><br><span class="line">)</span><br><span class="line">partitioned <span class="keyword">by</span> (age <span class="built_in">int</span>,sex <span class="keyword">string</span>) </span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span></span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span></span><br><span class="line">collection items <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'-'</span></span><br><span class="line"><span class="keyword">map</span> <span class="keyword">keys</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">':'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># hive 命令行中设置动态分区为非严格模式</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode=nonstrict</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意： 参数的位置要对应</span></span><br><span class="line"><span class="keyword">from</span> psn21</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> psn22 <span class="keyword">partition</span>(age, sex)  </span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, <span class="keyword">name</span>, likes, address, age,sex <span class="keyword">distribute</span> <span class="keyword">by</span> age, sex;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Hive-之-DML"><a href="#Hive-之-DML" class="headerlink" title="Hive 之 DML*"></a>Hive 之 DML*</h2><p>官方文档地址：</p>
<p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-HiveDataManipulationLanguage" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML#LanguageManualDML-HiveDataManipulationLanguage</a></p>
<h3 id="加载数据的方式"><a href="#加载数据的方式" class="headerlink" title="加载数据的方式"></a>加载数据的方式</h3><ul>
<li><p>Loading files into tables 从文件中加载数据</p>
<p>Hive does not do any transformation while loading data into tables. Load operations are currently pure copy/move operations that move datafiles into locations corresponding to Hive tables.</p>
<p><strong>语法：</strong></p>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">LOAD</span> <span class="keyword">DATA</span> [<span class="keyword">LOCAL</span>] INPATH <span class="string">'filepath'</span> [OVERWRITE] </span><br><span class="line"><span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename </span><br><span class="line">[<span class="keyword">PARTITION</span> (partcol1=val1, partcol2=val2 ...)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">LOAD</span> <span class="keyword">DATA</span> [<span class="keyword">LOCAL</span>] INPATH <span class="string">'filepath'</span> [OVERWRITE] </span><br><span class="line"><span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename </span><br><span class="line">[<span class="keyword">PARTITION</span> (partcol1=val1, partcol2=val2 ...)] </span><br><span class="line">[INPUTFORMAT <span class="string">'inputformat'</span> SERDE <span class="string">'serde'</span>] (<span class="number">3.0</span> <span class="keyword">or</span> later)</span><br></pre></td></tr></table></figure>


</li>
</ul>
<p>  注意： 从 HDFS 中加载数据，数据发生移动，而从本地加载数据，数据发生拷贝。</p>
<ul>
<li><p>Inserting data into Hive Tables from queries 从查询结果集中加载数据</p>
<p>Query Results can be inserted into tables by using the insert clause.</p>
<p><strong>语法：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Standard syntax:</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1=val1, partcol2=val2 ...) [<span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>]] select_statement1 <span class="keyword">FROM</span> from_statement;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1=val1, partcol2=val2 ...)] select_statement1 <span class="keyword">FROM</span> from_statement;</span><br><span class="line"> </span><br><span class="line">Hive extension (multiple inserts):</span><br><span class="line">FROM from_statement</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1=val1, partcol2=val2 ...) [<span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>]] select_statement1</span><br><span class="line">[<span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename2 [<span class="keyword">PARTITION</span> ... [<span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>]] select_statement2]</span><br><span class="line">[<span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename2 [<span class="keyword">PARTITION</span> ...] select_statement2] ...;</span><br><span class="line">FROM from_statement</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1=val1, partcol2=val2 ...)] select_statement1</span><br><span class="line">[<span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename2 [<span class="keyword">PARTITION</span> ...] select_statement2]</span><br><span class="line">[<span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename2 [<span class="keyword">PARTITION</span> ... [<span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>]] select_statement2] ...;</span><br><span class="line"> </span><br><span class="line">Hive extension (dynamic partition inserts):</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename <span class="keyword">PARTITION</span> (partcol1[=val1], partcol2[=val2] ...) select_statement <span class="keyword">FROM</span> from_statement;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename <span class="keyword">PARTITION</span> (partcol1[=val1], partcol2[=val2] ...) select_statement <span class="keyword">FROM</span> from_statement;</span><br></pre></td></tr></table></figure>

<p><strong>例子：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">FROM psn</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> psn10</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">id</span>,<span class="keyword">name</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> psn11</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>,likes </span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> <span class="keyword">directory</span> <span class="string">'/root/result'</span> </span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> psn;</span><br></pre></td></tr></table></figure>




</li>
</ul>
<h3 id="更新操作"><a href="#更新操作" class="headerlink" title="更新操作"></a>更新操作</h3><ul>
<li>ACID 事务的特性</li>
<li>三大范式</li>
</ul>
<h2 id="Hive-SerDe"><a href="#Hive-SerDe" class="headerlink" title="Hive SerDe"></a>Hive SerDe</h2><blockquote>
<p>SerDe 用于做序列化和反序列化。</p>
</blockquote>
<p>构建在数据存储和执行引擎之间，对两者实现解耦。<br>Hive通过 ROW FORMAT DELIMITED 以及 SERDE  进行内容的读写。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">row_format</span><br><span class="line">: DELIMITED </span><br><span class="line">          [FIELDS TERMINATED BY char [ESCAPED BY char]] </span><br><span class="line">          [COLLECTION ITEMS TERMINATED BY char] </span><br><span class="line">          [MAP KEYS TERMINATED BY char] </span><br><span class="line">          [LINES TERMINATED BY char] </span><br><span class="line">: SERDE serde_name [<span class="keyword">WITH</span> SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]</span><br></pre></td></tr></table></figure>

<h3 id="Hive-正则匹配"><a href="#Hive-正则匹配" class="headerlink" title="Hive 正则匹配"></a>Hive 正则匹配</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> logtbl (</span><br><span class="line">    host <span class="keyword">STRING</span>,</span><br><span class="line">    <span class="keyword">identity</span> <span class="keyword">STRING</span>,</span><br><span class="line">    t_user <span class="keyword">STRING</span>,</span><br><span class="line">    <span class="built_in">time</span> <span class="keyword">STRING</span>,</span><br><span class="line">    request <span class="keyword">STRING</span>,</span><br><span class="line">    referer <span class="keyword">STRING</span>,</span><br><span class="line">    <span class="keyword">agent</span> <span class="keyword">STRING</span>)</span><br><span class="line">  <span class="keyword">ROW</span> <span class="keyword">FORMAT</span> SERDE <span class="string">'org.apache.hadoop.hive.serde2.RegexSerDe'</span></span><br><span class="line">  <span class="keyword">WITH</span> SERDEPROPERTIES (</span><br><span class="line">    <span class="string">"input.regex"</span> = <span class="string">"([^ ]*) ([^ ]*) ([^ ]*) \\[(.*)\\] \"(.*)\" (-|[0-9]*) (-|[0-9]*)"</span></span><br><span class="line">  )</span><br><span class="line">  <span class="keyword">STORED</span> <span class="keyword">AS</span> TEXTFILE;</span><br></pre></td></tr></table></figure>

<h2 id="Hive-Beeline"><a href="#Hive-Beeline" class="headerlink" title="Hive Beeline"></a>Hive Beeline</h2><blockquote>
<p>提供了 JDBC 的访问方式</p>
<p>beenline 不能用于 DML 操作，只能执行一些查询操作</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 第一种方式</span></span><br><span class="line">beeline </span><br><span class="line">!connect jdbc:hive2://node04:10000/default root 123</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 第二种方式</span></span><br><span class="line">beeline -u connect jdbc:hive2://node04:10000/default -n root</span><br></pre></td></tr></table></figure>

<h2 id="Hive-JDBC"><a href="#Hive-JDBC" class="headerlink" title="Hive  JDBC"></a>Hive  JDBC</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HiveDemo</span> </span>&#123;</span><br><span class="line">	</span><br><span class="line"><span class="comment">//	private final static String driver = "org.apache.hive.jdbc.HiveDriver";</span></span><br><span class="line"><span class="comment">//	private final static String url = "jdbc:hive2://node04:10000/default";</span></span><br><span class="line"><span class="comment">//	private final static String username = "root";</span></span><br><span class="line"><span class="comment">//	private final static String password = "123";</span></span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			Properties prop = <span class="keyword">new</span> Properties();</span><br><span class="line">			prop.load(<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(<span class="string">"jdbc.properties"</span>)));</span><br><span class="line">			String driver = prop.getProperty(<span class="string">"driver"</span>);</span><br><span class="line">			String url = prop.getProperty(<span class="string">"url"</span>);</span><br><span class="line">			String username = prop.getProperty(<span class="string">"username"</span>);</span><br><span class="line">			String password = prop.getProperty(<span class="string">"password"</span>);</span><br><span class="line">            </span><br><span class="line">			Class.forName(driver);</span><br><span class="line">			Connection conn = DriverManager.getConnection(url,username,password);</span><br><span class="line">			Statement st = conn.createStatement();</span><br><span class="line">			String sql = <span class="string">"select * from psn"</span>;</span><br><span class="line">			ResultSet rs = st.executeQuery(sql);</span><br><span class="line">			<span class="keyword">while</span>(rs.next())&#123;</span><br><span class="line">				<span class="keyword">int</span> id = rs.getInt(<span class="string">"id"</span>);</span><br><span class="line">				String name = rs.getString(<span class="string">"name"</span>);</span><br><span class="line">				System.out.println(id+<span class="string">"\t"</span>+name);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Hive-函数"><a href="#Hive-函数" class="headerlink" title="Hive 函数"></a>Hive 函数</h2><p>官方文档地址：</p>
<p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF</a></p>
<h4 id="自定义-UDF"><a href="#自定义-UDF" class="headerlink" title="自定义 UDF"></a>自定义 UDF</h4><p>官方文档地址：</p>
<p><a href="https://cwiki.apache.org/confluence/display/Hive/HivePlugins" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/HivePlugins</a></p>
<ul>
<li>java 代码</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TuoMing</span> <span class="keyword">extends</span> <span class="title">UDF</span></span>&#123;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> Text <span class="title">evaluate</span><span class="params">(<span class="keyword">final</span> Text s)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (s == <span class="keyword">null</span>) &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		String str = s.toString().substring(<span class="number">0</span>, <span class="number">3</span>) + <span class="string">"***"</span>;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">new</span> Text(str);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>将 java 代码文件打包成 jar ，上传 Linux 上的 HDFS 中</p>
</li>
<li><p>创建临时函数</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 本地文件系统加载</span></span><br><span class="line">add jar /root/tm/tm.jar;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">temporary</span> <span class="keyword">function</span> tm <span class="keyword">as</span> <span class="string">'com.szxy.hive.TuoMing'</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 从 HDFS 中加载</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">temporary</span> <span class="keyword">function</span> tms <span class="keyword">as</span> <span class="string">'com.szxy.hive.TuoMing'</span> </span><br><span class="line"><span class="keyword">using</span> jar <span class="string">'hdfs://node01:8020/data/jar/tm/tm.jar'</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用临时函数</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">select <span class="title">tms</span><span class="params">(name)</span> from psn</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>结果</p>
<p><img src="http://img.zwer.xyz/blog/20191014222337.png" alt></p>
</li>
</ul>
<h2 id="Hive-案例"><a href="#Hive-案例" class="headerlink" title="Hive 案例"></a>Hive 案例</h2><h3 id="struct-结构体"><a href="#struct-结构体" class="headerlink" title="struct 结构体"></a>struct 结构体</h3><ul>
<li><p>测试数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1001,zhangsan:24</span><br><span class="line">1002,lisi:25</span><br><span class="line">1003,wangwu:26</span><br><span class="line">1004,zhaoliu:27</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建表</p>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span>,</span><br><span class="line">info <span class="keyword">struct</span>&lt;<span class="keyword">name</span>:<span class="keyword">string</span>,age:<span class="built_in">int</span>&gt;)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> </span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">","</span> </span><br><span class="line">collection items <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">":"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> inpath <span class="string">'/data/struct/input'</span> <span class="keyword">into</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="WordCount"><a href="#WordCount" class="headerlink" title="WordCount"></a>WordCount</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> hello(</span><br><span class="line">line <span class="keyword">string</span> </span><br><span class="line">)</span><br><span class="line">location <span class="string">'/data/wc/input'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> hello_wc(</span><br><span class="line">word <span class="keyword">string</span> ,</span><br><span class="line"><span class="keyword">num</span> <span class="built_in">int</span> </span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">from (<span class="keyword">select</span> <span class="keyword">explode</span>(<span class="keyword">split</span>(line,<span class="string">' '</span>)) word <span class="keyword">from</span> hello ) t </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> hello_wc </span><br><span class="line"><span class="keyword">select</span> word,<span class="keyword">count</span>(word) <span class="keyword">group</span> <span class="keyword">by</span> word;</span><br></pre></td></tr></table></figure>

<h3 id="基站掉话率统计"><a href="#基站掉话率统计" class="headerlink" title="基站掉话率统计"></a>基站掉话率统计</h3><ul>
<li><p>需求：</p>
<p>找出掉线率最高的前10基站</p>
</li>
<li><p>sql 语句</p>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> tb_cell_result(</span><br><span class="line">imei <span class="keyword">string</span>,</span><br><span class="line">drop_num <span class="built_in">int</span>,</span><br><span class="line"><span class="keyword">duration</span> <span class="built_in">int</span>,</span><br><span class="line">drop_rate <span class="keyword">double</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> tb_cell(</span><br><span class="line">record_time <span class="keyword">string</span>,</span><br><span class="line">imei <span class="keyword">string</span>,</span><br><span class="line">cell <span class="keyword">string</span>,</span><br><span class="line">ph_num <span class="built_in">int</span>,</span><br><span class="line">call_num <span class="keyword">string</span>,</span><br><span class="line">drop_num <span class="built_in">int</span>,</span><br><span class="line"><span class="keyword">duration</span> <span class="built_in">int</span>,</span><br><span class="line">drop_rate <span class="built_in">int</span>,</span><br><span class="line">net_type <span class="keyword">string</span>,</span><br><span class="line">erl <span class="built_in">int</span> </span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span></span><br><span class="line">location <span class="string">'/data/cell/input'</span>;</span><br><span class="line"></span><br><span class="line">from tb_cell </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tb_cell_result</span><br><span class="line"><span class="keyword">select</span> imei,<span class="keyword">sum</span>(drop_num) sdrop,<span class="keyword">sum</span>(<span class="keyword">duration</span>) sdura, <span class="keyword">sum</span>(drop_num)/<span class="keyword">sum</span>(<span class="keyword">duration</span>) srate <span class="keyword">group</span> <span class="keyword">by</span> imei sorted <span class="keyword">by</span> srate <span class="keyword">desc</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> tb_cell_result <span class="keyword">limit</span> <span class="number">10</span>;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Hive-参数"><a href="#Hive-参数" class="headerlink" title="Hive 参数"></a>Hive 参数</h2><ul>
<li><p><strong>hive 参数、变量</strong></p>
<p>hive当中的参数、变量，都是以命名空间开头</p>
<table>
<thead>
<tr>
<th>命名空间</th>
<th>读写权限</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>hiveconf</td>
<td>可读写</td>
<td>hive-site.xml 中配置各种变量<br> 例：<code>hive --hiveconf hive.cli.print.header=true</code></td>
</tr>
<tr>
<td>System</td>
<td>可读写</td>
<td>系统变量，包括 JVM 运行参数等 <br>例：system:user.name=root</td>
</tr>
<tr>
<td>env</td>
<td>只读</td>
<td>环境变量“<br> 例：env:JAVA_HOME</td>
</tr>
<tr>
<td>hivevar</td>
<td>可读写</td>
<td>例：hive -d val=key</td>
</tr>
</tbody></table>
<p>通过 <code>${}</code> 方式进行引用，其中 system、env 下的变量必须以前缀开头</p>
</li>
<li><p><strong>hive 参数设置方式</strong></p>
<ol>
<li><p>修改配置文件 <code>${HIVE_HOME}/conf/hive-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>启动 hive cli 时，通过 <code>--hiveconf key=value</code>的方式进行设置</p>
<p>​    例：<code>hive --hiveconf hive.cli.print.header=true</code></p>
</li>
<li><p>进入<code>cli</code>之后，通过使用set命令设置</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.cli.print.header=<span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

</li>
</ol>
</li>
</ul>
<h2 id="Hive-分桶"><a href="#Hive-分桶" class="headerlink" title="Hive 分桶"></a>Hive 分桶</h2><h3 id="分桶概念"><a href="#分桶概念" class="headerlink" title="分桶概念"></a>分桶概念</h3><ul>
<li><p>分桶表是对列值取哈希值的方式，将不同数据放到不同文件中存储。</p>
</li>
<li><p>对于hive中每一个表、分区都可以进一步进行分桶。</p>
</li>
<li><p>由列的哈希值除以桶的个数来决定每条数据划分在哪个桶中。</p>
</li>
</ul>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>数据抽样（ sampling ）</p>
<h3 id="分桶操作"><a href="#分桶操作" class="headerlink" title="分桶操作"></a>分桶操作</h3><ul>
<li><p><strong>开启支持分桶</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.enforce.bucketing=<span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<p>默认：false；设置为 true之后，mr运行时会根据 bucket 的个数自动分配 reduce task 个数。</p>
<p>（用户也可以通过mapred.reduce.tasks自己设置reduce任务个数，但分桶时不推荐使用）<br>注意：一次作业产生的桶（文件数量）和reduce task个数一致。</p>
</li>
<li><p><strong>往分桶表中加载数据</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> bucket_table <span class="keyword">select</span> <span class="keyword">columns</span> <span class="keyword">from</span> tbl;</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> bucket_table <span class="keyword">select</span> <span class="keyword">columns</span> <span class="keyword">from</span> tbl;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>桶表 抽样查询</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from bucket_table tablesample(bucket 1 out of 4 on columns);</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>TABLESAMPLE 语法</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TABLESAMPLE(BUCKET x OUT OF y)</span><br></pre></td></tr></table></figure>

<p>x：表示从哪个bucket开始抽取数据<br>y：必须为该表总bucket数的倍数或因子</p>
</li>
<li><p><strong>栗子</strong><br>当表总 bucket 数为32时</p>
<p>TABLESAMPLE(BUCKET 3 OUT OF 8)，抽取哪些数据？</p>
<p>答：共抽取2（32/16）个bucket的数据，抽取第2、第18（16+2）个bucket的数据</p>
<p>TABLESAMPLE(BUCKET 3 OUT OF 256)，抽取哪些数据？</p>
</li>
</ul>
<h3 id="分桶案例"><a href="#分桶案例" class="headerlink" title="分桶案例"></a>分桶案例</h3><ul>
<li><p><strong>测试数据</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1,tom,11</span><br><span class="line">2,cat,22</span><br><span class="line">3,dog,33</span><br><span class="line">4,hive,44</span><br><span class="line">5,hbase,55</span><br><span class="line">6,mr,66</span><br><span class="line">7,alice,77</span><br><span class="line">8,scala,88</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>创建 hive 表</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> tb_bucket(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span>,</span><br><span class="line"><span class="keyword">name</span> <span class="keyword">string</span>,</span><br><span class="line">score <span class="built_in">int</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> </span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span></span><br><span class="line">location <span class="string">'/data/bucket/input'</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>创建分桶表</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> psn_bucket(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span>,</span><br><span class="line"><span class="keyword">name</span> <span class="keyword">string</span>,</span><br><span class="line">score <span class="built_in">int</span></span><br><span class="line">)</span><br><span class="line">clustered <span class="keyword">by</span>(score) <span class="keyword">into</span> <span class="number">4</span> buckets</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span></span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>向分桶表中添加数据</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> psn_bucket <span class="keyword">select</span> <span class="keyword">id</span>,<span class="keyword">name</span>,score <span class="keyword">from</span> tb_bucket;</span><br></pre></td></tr></table></figure>

<p><font color="red" size="4px">注意：Hive 分桶默认是关闭的,通过 <code>set hive.enforce.bucketing=true;</code>开启分桶</font></p>
<p><img src="http://img.zwer.xyz/blog/20191015170433.png" alt></p>
</li>
</ul>
<ul>
<li><p><strong>抽样</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>,<span class="keyword">name</span>,score <span class="keyword">from</span> psn_bucket <span class="keyword">tablesample</span>(<span class="keyword">bucket</span> <span class="number">2</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">4</span>);</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Hive-Laternal-View"><a href="#Hive-Laternal-View" class="headerlink" title="Hive Laternal View"></a>Hive Laternal View</h2><blockquote>
<p>在 UDTF 函数中使用</p>
</blockquote>
<p>Lateral View用于和UDTF函数（explode、split）结合来使用。<br>首先通过UDTF函数拆分成多行，再将多行结果组合成一个支持别名的虚拟表。<br>主要解决在select使用UDTF做查询过程中，查询只能包含单个UDTF，不能包含其他字段、以及多个UDTF的问题</p>
<p><strong>语法：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LATERAL VIEW udtf(expression) tableAlias AS columnAlias (',' columnAlias)</span><br></pre></td></tr></table></figure>

<p>注意： 列别名有多个，并且可以重复</p>
<p><strong>栗子</strong></p>
<p>统计人员表中共有多少种爱好、多少个城市?</p>
<p><img src="http://img.zwer.xyz/blog/20191015190839.png" alt></p>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">distinct</span>(myCol1)), <span class="keyword">count</span>(<span class="keyword">distinct</span>(myCol2)) <span class="keyword">from</span> psn</span><br><span class="line"><span class="keyword">LATERAL</span> <span class="keyword">VIEW</span> <span class="keyword">explode</span>(likes) myTable1 <span class="keyword">AS</span> myCol1 </span><br><span class="line"><span class="keyword">LATERAL</span> <span class="keyword">VIEW</span> <span class="keyword">explode</span>(address) myTable2 <span class="keyword">AS</span> myCol2, myCol3;  </span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(<span class="keyword">distinct</span>(mycol)) <span class="keyword">from</span> psn <span class="keyword">lateral</span> <span class="keyword">view</span> <span class="keyword">explode</span>(likes)  myTable <span class="keyword">as</span> mycol;</span><br></pre></td></tr></table></figure>

<h2 id="Hive-视图"><a href="#Hive-视图" class="headerlink" title="Hive 视图"></a>Hive 视图</h2><blockquote>
<p>视图本质上就是一个虚拟表  Virtual Table,和关系型数据库中的普通视图一样，hive也支持视图</p>
</blockquote>
<p><strong>特点：</strong></p>
<ul>
<li><p>不支持物化视图</p>
</li>
<li><p>只能查询，不能做加载数据操作</p>
</li>
<li><p>视图的创建，只是保存一份元数据，查询视图时才执行对应的子查询</p>
</li>
<li><p>view定义中若包含了ORDER BY/LIMIT语句，当查询视图时也进行ORDER BY/LIMIT语句操作，view当中定义的优先级更高</p>
</li>
<li><p>view支持迭代视图</p>
</li>
</ul>
<p><strong>view语法</strong></p>
<ul>
<li><p>创建视图：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> [<span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] [db_name.]view_name </span><br><span class="line">  [(column_name [<span class="keyword">COMMENT</span> column_comment], ...) ]</span><br><span class="line">  [<span class="keyword">COMMENT</span> view_comment]</span><br><span class="line">  [TBLPROPERTIES (property_name = property_value, ...)]</span><br><span class="line">  <span class="keyword">AS</span> <span class="keyword">SELECT</span> ... ;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查询视图：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> colums <span class="keyword">from</span> <span class="keyword">view</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除视图：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">VIEW</span> [<span class="keyword">IF</span> <span class="keyword">EXISTS</span>] [db_name.]view_name</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Hive-索引"><a href="#Hive-索引" class="headerlink" title="Hive 索引"></a>Hive 索引</h2><ul>
<li><p><strong>目的</strong></p>
<p>优化查询以及检索性能</p>
</li>
<li><p>创建索引：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">index</span> t1_index <span class="keyword">on</span> <span class="keyword">table</span> psn(<span class="keyword">name</span>) </span><br><span class="line"><span class="keyword">as</span> <span class="string">'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler'</span> </span><br><span class="line"><span class="keyword">with</span> <span class="keyword">deferred</span> <span class="keyword">rebuild</span> </span><br><span class="line"><span class="keyword">in</span> <span class="keyword">table</span> t1_index_table;</span><br><span class="line"><span class="comment">-- as：指定索引器；</span></span><br><span class="line"><span class="comment">-- in table：指定索引表，若不指定默认生成在default__psn2_t1_index__表中</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">index</span> t1_index <span class="keyword">on</span> <span class="keyword">table</span> psn2(<span class="keyword">name</span>) </span><br><span class="line"><span class="keyword">as</span> <span class="string">'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler'</span> </span><br><span class="line"><span class="keyword">with</span> <span class="keyword">deferred</span> <span class="keyword">rebuild</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>查询索引</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">index</span> <span class="keyword">on</span> psn2;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>重建索引</strong>（建立索引之后必须重建索引才能生效）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">INDEX</span> t1_index <span class="keyword">ON</span> psn <span class="keyword">REBUILD</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除索引</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">INDEX</span> <span class="keyword">IF</span> <span class="keyword">EXISTS</span> t1_index <span class="keyword">ON</span> psn;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="Hive-运行方式"><a href="#Hive-运行方式" class="headerlink" title="Hive 运行方式"></a>Hive 运行方式</h2><ol>
<li><p><strong>命令行方式cli：控制台模式</strong></p>
<ul>
<li>与hdfs交互<br>执行执行dfs命令<br>例：<code>dfs –ls /</code></li>
<li>与Linux交互<br>！开头<br>例：<code>!pwd</code></li>
</ul>
</li>
<li><p><strong>脚本运行方式（实际生产环境中用最多）</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive -e ""</span><br><span class="line">hive -e ""&gt;aaa</span><br><span class="line">hive -S -e ""&gt;aaa</span><br><span class="line">hive -f file</span><br><span class="line">hive -i /home/my/hive-init.sql</span><br><span class="line"><span class="meta">hive&gt;</span> source file (在hive cli中运行)</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>JDBC方式：hiveserver2</strong></p>
</li>
<li><p><strong>web GUI接口 （hwi、hue等）</strong></p>
</li>
</ol>
<h2 id="Hive-权限管理"><a href="#Hive-权限管理" class="headerlink" title="Hive 权限管理"></a>Hive 权限管理</h2><p>官方文档地址：</p>
<p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Authorization" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Authorization</a></p>
<p><strong>三种授权模型：</strong></p>
<ol>
<li><p><strong>Storage Based Authorization in the Metastore Server</strong></p>
<p>基于存储的授权 - 可以对Metastore中的元数据进行保护，但是没有提供更加细粒度的访问控制（例如：列级别、行级别）。</p>
</li>
<li><p><strong><font color="red">SQL Standards Based Authorization in HiveServer2</font></strong></p>
<p>基于SQL标准的Hive授权 - 完全兼容SQL的授权模型，推荐使用该模式。<br><a href="https://cwiki.apache.org/confluence/display/Hive/SQL+Standard+Based+Hive+Authorization" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/SQL+Standard+Based+Hive+Authorization</a></p>
</li>
<li><p><strong>Default Hive Authorization (Legacy Mode)</strong></p>
<pre><code>hive默认授权 - 设计目的仅仅只是为了防止用户产生误操作，而不是防止恶意用户访问未经授权的数据。</code></pre></li>
</ol>
<p><strong><font color="red">SQL Standards Based Authorization in HiveServer2</font></strong></p>
<ul>
<li><p>完全兼容SQL的授权模型</p>
</li>
<li><p>除支持对于用户的授权认证，还支持角色 role 的授权认证</p>
<p>role可理解为是一组权限的集合，通过role为用户授权</p>
<p>一个用户可以具有一个或多个角色</p>
<p>默认包含另种角色：public、admin</p>
</li>
<li><p><strong>限制：</strong><br>1、启用当前认证方式之后，dfs, add, delete, compile, and reset等命令被禁用。</p>
<p>2、通过set命令设置hive configuration的方式被限制某些用户使用。</p>
<p>（可通过修改配置文件hive-site.xml中hive.security.authorization.sqlstd.confwhitelist进行配置）</p>
<p>3、添加、删除函数以及宏的操作，仅为具有admin的用户开放。</p>
<p>4、用户自定义函数（开放支持永久的自定义函数），可通过具有admin角色的用户创建，其他用户都可以使用。</p>
<p>5、Transform功能被禁用。</p>
</li>
<li><p><strong>在hive服务端修改配置文件hive-site.xml添加以下配置内容</strong>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.security.authorization.enabled&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.server2.enable.doAs&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.users.in.admin.role&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.security.authorization.manager&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.security.authenticator.manager&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.hive.ql.security.SessionStateUserAuthenticator&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>服务端启动hiveserver2；客户端通过beeline进行连接</p>
</li>
</ul>
<h2 id="Hive-优化"><a href="#Hive-优化" class="headerlink" title=" Hive 优化*"></a><font color="pinkbrown" size="6px"> Hive 优化*</font></h2><blockquote>
<p>核心思想：把 Hive SQL 当做Mapreduce程序去优化</p>
</blockquote>
<p>以下 SQL 不会转为Mapreduce来执行：</p>
<ol>
<li><p>select 仅查询本表字段</p>
</li>
<li><p>where 仅对本表字段做条件过滤</p>
</li>
</ol>
<p>Explain 显示执行计划</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">EXPLAIN</span> [<span class="keyword">EXTENDED</span>] <span class="keyword">query</span></span><br></pre></td></tr></table></figure>

<h3 id="Hive抓取策略"><a href="#Hive抓取策略" class="headerlink" title="Hive抓取策略"></a>Hive抓取策略</h3><p>Hive中对某些情况的查询不需要使用 MapReduce 计算</p>
<p>抓取策略 </p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Set</span> hive.fetch.task.conversion=<span class="keyword">none</span>/more;</span><br></pre></td></tr></table></figure>

<h3 id="Hive运行方式"><a href="#Hive运行方式" class="headerlink" title="Hive运行方式"></a>Hive运行方式</h3><ul>
<li><p>本地模式</p>
</li>
<li><p>集群模式</p>
</li>
</ul>
<p><strong>开启本地模式</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.mode.local.auto=true;</span><br></pre></td></tr></table></figure>

<p>注意：<br><code>hive.exec.mode.local.auto.inputbytes.max</code>  默认值为128M<br>表示加载文件的最大值，若大于该配置仍会以集群方式来运行</p>
<h3 id="并行计算"><a href="#并行计算" class="headerlink" title="并行计算"></a>并行计算</h3><p>通过设置以下参数开启并行模式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.parallel=true;</span><br></pre></td></tr></table></figure>

<p>注意：hive.exec.parallel.thread.number<br>（一次SQL计算中允许并行执行的job个数的最大值）</p>
<h3 id="严格模式"><a href="#严格模式" class="headerlink" title="严格模式"></a>严格模式</h3><ul>
<li>通过设置以下参数开启严格模式：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.mapred.mode=strict;</span><br></pre></td></tr></table></figure>

<p>（默认为：nonstrict非严格模式）</p>
<ul>
<li><p>查询限制</p>
<p>1、对于分区表，必须添加where对于分区字段的条件过滤；</p>
<p>2、order by语句必须包含limit输出限制；</p>
<p>3、限制执行笛卡尔积的查询。</p>
</li>
</ul>
<h3 id="Hive排序"><a href="#Hive排序" class="headerlink" title="Hive排序"></a>Hive排序</h3><ul>
<li>Order By - 对于查询结果做全排序，只允许有一个reduce处理<br>（当数据量较大时，应慎用。严格模式下，必须结合limit来使用）</li>
<li><strong>Sort By</strong> - 对于单个reduce的数据进行排序</li>
<li>Distribute By - 分区排序，经常和Sort By结合使用</li>
<li>Cluster By - 相当于 Sort By + Distribute By<br>（Cluster By不能通过asc、desc的方式指定排序规则；<br>可通过 distribute by column sort by column asc|desc 的方式）</li>
</ul>
<h3 id="Hive-Join"><a href="#Hive-Join" class="headerlink" title="Hive Join"></a>Hive Join</h3><p>Join计算时，将小表（驱动表）放在join的左边</p>
<p>Map Join：在Map端完成Join</p>
<p>两种实现方式：</p>
<ol>
<li>SQL方式，在SQL语句中添加 MapJoin 标记（mapjoin hint）<br>语法：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  <span class="comment">/*+ MAPJOIN(smallTable) */</span>  smallTable.key,  bigTable.value </span><br><span class="line"><span class="keyword">FROM</span>  smallTable  <span class="keyword">JOIN</span>  bigTable  <span class="keyword">ON</span>  smallTable.key  =  bigTable.key;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p>开启自动的MapJoin</p>
<p>自动的mapjoin<br>通过修改以下配置启用自动的 mapjoin：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.auto.convert.join = true;</span><br></pre></td></tr></table></figure>

<p>（该参数为true时，Hive 自动对左边的表统计量，如果是小表就加入内存，即对小表使用 Map join）</p>
<p>相关配置参数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.mapjoin.smalltable.filesize;</span><br></pre></td></tr></table></figure>

<p>（大表小表判断的阈值，如果表的大小小于该值则会被加载到内存中运行）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.ignore.mapjoin.hint；</span><br></pre></td></tr></table></figure>

<p>（默认值：true；是否忽略mapjoin hint 即mapjoin标记）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.auto.convert.join.noconditionaltask;</span><br></pre></td></tr></table></figure>

<p>（默认值：true；将普通的join转化为普通的mapjoin时，是否将多个mapjoin转化为一个mapjoin）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.auto.convert.join.noconditionaltask.size;</span><br></pre></td></tr></table></figure>

<p>（将多个mapjoin转化为一个mapjoin时，其表的最大值）</p>
<p>注意：<code>hive.exec.parallel.thread.number</code>（一次SQL计算中允许并行执行的job个数的最大值）</p>
<ul>
<li>尽可能使用相同的连接键（会转化为一个MapReduce作业）</li>
</ul>
</li>
</ol>
<ul>
<li><p>大表join大表</p>
<p>空key过滤：有时join超时是因为某些key对应的数据太多，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。此时我们应该仔细分析这些异常的key，很多情况下，这些key对应的数据是异常数据，我们需要在SQL语句中进行过滤。<br>   空key转换：有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，此时我们可以表a中key为空的字段赋一个随机的值，使得数据随机均匀地分不到不同的reducer上</p>
</li>
</ul>
<h3 id="Map-Side聚合"><a href="#Map-Side聚合" class="headerlink" title="Map-Side聚合"></a>Map-Side聚合</h3><p>通过设置以下参数开启在Map端的聚合：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.map.aggr=true;</span><br></pre></td></tr></table></figure>

<p>相关配置参数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.groupby.mapaggr.checkinterval：</span><br></pre></td></tr></table></figure>

<p>map 端 group by 执行聚合时处理的多少行数据（默认：100000）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.map.aggr.hash.min.reduction：</span><br></pre></td></tr></table></figure>

<p>进行聚合的最小比例（预先对100000条数据做聚合，若聚合之后的数据量/100000的值大于该配置0.5，则不会聚合）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.map.aggr.hash.percentmemory：</span><br></pre></td></tr></table></figure>

<p>map端聚合使用的内存的最大值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.map.aggr.hash.force.flush.memory.threshold：</span><br></pre></td></tr></table></figure>

<p>map端做聚合操作是hash表的最大可用内容，大于该值则会触发flush</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.groupby.skewindata</span><br></pre></td></tr></table></figure>

<p>是否对GroupBy产生的数据倾斜做优化，默认为false</p>
<p>相关配置参数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.groupby.mapaggr.checkinterval：</span><br></pre></td></tr></table></figure>

<p>map端group by执行聚合时处理的多少行数据（默认：100000）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.map.aggr.hash.min.reduction：</span><br></pre></td></tr></table></figure>

<p>进行聚合的最小比例（预先对100000条数据做聚合，若聚合之后的数据量/100000的值大于该配置0.5，则不会聚合）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.map.aggr.hash.percentmemory：</span><br></pre></td></tr></table></figure>

<p>map端聚合使用的内存的最大值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.map.aggr.hash.force.flush.memory.threshold：</span><br></pre></td></tr></table></figure>

<p>map端做聚合操作是hash表的最大可用内容，大于该值则会触发flush</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.groupby.skewindata</span><br></pre></td></tr></table></figure>

<p>是否对GroupBy产生的数据倾斜做优化，默认为false</p>
<h3 id="合并小文件"><a href="#合并小文件" class="headerlink" title="合并小文件"></a>合并小文件</h3><p>文件数目小，容易在文件存储端造成压力，给hdfs造成压力，影响效率</p>
<ul>
<li><p><strong>设置合并属性</strong></p>
<p>是否合并map输出文件：hive.merge.mapfiles=true<br>是否合并reduce输出文件：hive.merge.mapredfiles=true;<br>合并文件的大小：hive.merge.size.per.task=256<em>1000</em>1000</p>
</li>
<li><p><strong>去重统计</strong></p>
<p>数据量小的时候无所谓，数据量大的情况下，由于 COUNT DISTINCT 操作需要用一个 Reduce Task来完成，这一个Reduce需要处理的数据量太大，就会导致整个Job很难完成，一般COUNT DISTINCT使用先GROUP BY再COUNT的方式替换</p>
</li>
</ul>
<h3 id="控制Hive中Map以及Reduce的数量"><a href="#控制Hive中Map以及Reduce的数量" class="headerlink" title="控制Hive中Map以及Reduce的数量"></a>控制Hive中Map以及Reduce的数量</h3><ul>
<li><p><strong>Map 数量相关的参数</strong></p>
<table>
<thead>
<tr>
<th>参数设置</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>mapred.max.split.size</td>
<td>一个split的最大值，即每个map处理文件的最大值</td>
</tr>
<tr>
<td>mapred.min.split.size.per.node</td>
<td>一个节点上split的最小值</td>
</tr>
<tr>
<td>mapred.min.split.size.per.rack</td>
<td>一个机架上split的最小值</td>
</tr>
</tbody></table>
</li>
<li><p><strong>Reduce 数量相关的参数</strong><br>|    参数|    解释|<br>| —- | —- | —- |<br>| mapred.reduce.tasks     |      强制指定reduce任务的数量|<br>|  hive.exec.reducers.bytes.per.reducer     | 每个reduce任务处理的数据量     |<br>| hive.exec.reducers.max| 每个任务最大的reduce数|</p>
</li>
</ul>
<h3 id="Hive-JVM重用"><a href="#Hive-JVM重用" class="headerlink" title="Hive- JVM重用"></a>Hive- JVM重用</h3><blockquote>
<p>适用场景：<br>1、小文件个数过多<br>2、task个数过多</p>
</blockquote>
<p>通过 <code>set mapred.job.reuse.jvm.num.tasks=n;</code>来设置<br>（n为task插槽个数）</p>
<p>缺点：</p>
<p>设置开启之后，task插槽会一直占用资源，不论是否有task运行，</p>
<p>直到所有的 task 即整个 job 全部执行完成时，才会释放所有的 task 插槽资源！</p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://zwer.xyz/2019/10/09/20191009 Hadoop之MapReduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zwer">
      <meta itemprop="description" content="记录学习的日常">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zwer 的博客空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/10/09/20191009 Hadoop之MapReduce/" class="post-title-link" itemprop="url">20191009 Hadoop-MapReduce</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-10-09 00:00:00 / Modified: 21:31:04" itemprop="dateCreated datePublished" datetime="2019-10-09T00:00:00+08:00">2019-10-09</time>
            </span>
          
            

            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><blockquote>
<p>MapTask &amp; ReduceTask</p>
</blockquote>
<p>一个切片对应一个 Map，也就是说切片的数量决定了 Map 的数量</p>
<p>split 切片指逻辑上概念，用于指定 Map 处理数据的大小</p>
<p>切片用于将 HDFS中的块与 Map 之间解耦</p>
<p>Reduce 的数量由人来决定，根据前面的组的推导</p>
<p><img src="http://img.zwer.xyz/blog/20191009101915.png" alt></p>
<h3 id="MR-原语"><a href="#MR-原语" class="headerlink" title="MR  原语"></a><font color="green">MR  原语</font></h3><p>输入(格式化k,v)数据集 -&gt; map映射成一个中间数据集(k,v)  -&gt; reduce<br><font color="red">“相同”的 key 为一组，调用一次 reduce 方法，方法内迭代这一组数据进行计算</font></p>
<table>
<thead>
<tr>
<th>关系/对应比例</th>
<th>block &gt; split</th>
<th>split &gt; map</th>
<th>map &gt; reduce</th>
<th>group(key)&gt;partition</th>
<th>partition &gt; outputfile</th>
</tr>
</thead>
<tbody><tr>
<td>1:1</td>
<td>*</td>
<td>*</td>
<td>*</td>
<td>*</td>
<td></td>
</tr>
<tr>
<td>1:N</td>
<td>*</td>
<td></td>
<td>*</td>
<td><font color="red">违背了原语</font></td>
<td></td>
</tr>
<tr>
<td>N:1</td>
<td>*</td>
<td></td>
<td>*</td>
<td>*</td>
<td></td>
</tr>
<tr>
<td>N:M</td>
<td></td>
<td></td>
<td>*</td>
<td>*</td>
<td></td>
</tr>
</tbody></table>
<h3 id="Shuffler-lt-洗牌-gt"><a href="#Shuffler-lt-洗牌-gt" class="headerlink" title="Shuffler&lt;洗牌&gt;"></a>Shuffler&lt;洗牌&gt;</h3><blockquote>
<p>框架内部实现机制<br>分布式计算节点数据流转：连接 MapTask 与 ReduceTask</p>
</blockquote>
<p><img src="http://img.zwer.xyz/blog/20191009110701.png" alt></p>
<h3 id="计算框架"><a href="#计算框架" class="headerlink" title="计算框架"></a>计算框架</h3><p><img src="http://img.zwer.xyz/blog/20191009111332.png" alt></p>
<table>
<thead>
<tr>
<th></th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>Map</td>
<td>读懂数据<br>映射为KV模型<br>并行分布式<br><font color="red">计算向数据移动</font></td>
</tr>
<tr>
<td>Reduce</td>
<td>数据全量/分量加工<br>Reduce中可以包含不同的key<br>相同的Key汇聚到一个Reduce中<br>相同的Key调用一次reduce方法<br>排序实现key的汇聚<br></td>
</tr>
<tr>
<td>K,V使用自定义数据类型<br></td>
<td>作为参数传发成本，提高程序自由度<br>- Writable 序列化<br> - Comparable 比较器<br>实现具体排序（字典序，数值序等）</td>
</tr>
</tbody></table>
<h3 id="MapReduce-1-x"><a href="#MapReduce-1-x" class="headerlink" title="MapReduce 1.x"></a>MapReduce 1.x</h3><blockquote>
<p>计算向数据移动</p>
</blockquote>
<p><img src="http://img.zwer.xyz/blog/20191009113152.png" alt></p>
<h4 id="计算框架-Mapper"><a href="#计算框架-Mapper" class="headerlink" title="计算框架 Mapper"></a>计算框架 Mapper</h4><p><img src="http://img.zwer.xyz/blog/20191009113223.png" alt></p>
<h4 id="计算框架-Reducer"><a href="#计算框架-Reducer" class="headerlink" title="计算框架 Reducer"></a>计算框架 Reducer</h4><p><img src="http://img.zwer.xyz/blog/20191009113300.png" alt></p>
<table>
<thead>
<tr>
<th>MRv1角色：</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>JobTracker</td>
<td>核心，<font color="red">主</font>，单点<br>调度所有的作业<br>监控整个集群的资源负载</td>
</tr>
<tr>
<td>TaskTracker</td>
<td><font color="red">从</font>，自身节点资源管理<br>和 JobTracker 心跳，汇报资源，获取Task</td>
</tr>
<tr>
<td>Client</td>
<td>作业为单位<br>规划作业计算分布<br>提交作业资源到HDFS<br>最终提交作业到 JobTracker</td>
</tr>
<tr>
<td>弊端：</td>
<td>JobTracker：负载过重，单点故障<br>资源管理与计算调度强耦合，其他计算框架需要重复实现资源管理<br>不同框架对资源不能全局管理</td>
</tr>
</tbody></table>
<h3 id="MRV2-之-YARN"><a href="#MRV2-之-YARN" class="headerlink" title="MRV2 之 YARN"></a>MRV2 之 YARN</h3><blockquote>
<p> YARN：解耦资源与计算</p>
</blockquote>
<p><img src="http://img.zwer.xyz/blog/20191009140653.png" alt></p>
<table>
<thead>
<tr>
<th></th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>ResourceManager</td>
<td>主，核心<br>集群节点资源管理</td>
</tr>
<tr>
<td>NodeManager</td>
<td>与RM汇报资源<br>管理Container生命周期<br>计算框架中的角色都以Container表示</td>
</tr>
<tr>
<td>Container</td>
<td>【节点NM，CPU,MEM,I/O大小，启动命令】<br>默认NodeManager启动线程监控Container大小，超出申请资源额度，kill<br>支持Linux内核的Cgroup</td>
</tr>
<tr>
<td>MR</td>
<td>- MR-ApplicationMaster-Container<br>x作业为单位，避免单点故障，负载到不同的节点<br>创建Task需要和RM申请资源（Container）<br>- Task-Container</td>
</tr>
<tr>
<td>Client</td>
<td>RM-Client：请求资源创建AM<br>AM-Client：与AM交互</td>
</tr>
</tbody></table>
<h2 id="搭建-yarn"><a href="#搭建-yarn" class="headerlink" title="搭建 yarn"></a>搭建 yarn</h2><h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><table>
<thead>
<tr>
<th></th>
<th>NN-1</th>
<th>NN-2</th>
<th>DN</th>
<th>ZK</th>
<th>ZKFC</th>
<th>JNN</th>
<th>RM</th>
<th>NM</th>
</tr>
</thead>
<tbody><tr>
<td>node01</td>
<td>*</td>
<td></td>
<td></td>
<td></td>
<td>*</td>
<td>*</td>
<td></td>
<td></td>
</tr>
<tr>
<td>node02</td>
<td></td>
<td>*</td>
<td>*</td>
<td>*</td>
<td>*</td>
<td>*</td>
<td></td>
<td>*</td>
</tr>
<tr>
<td>node03</td>
<td></td>
<td></td>
<td>*</td>
<td>*</td>
<td></td>
<td>*</td>
<td>*</td>
<td>*</td>
</tr>
<tr>
<td>node04</td>
<td></td>
<td></td>
<td>*</td>
<td>*</td>
<td></td>
<td></td>
<td>*</td>
<td>*</td>
</tr>
</tbody></table>
<p>说明： </p>
<pre><code>1. HA 高可用 HDFS 
 2. RM 资源管理器采用主从架构，使用 Zookeeper 做分布式协调
 3. NM 的数量与 DN 的数量相同</code></pre><h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><ul>
<li>mapred-site.xml </li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>yarn-site.xml</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node03<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node04<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node02:2181,node03:2181,node04:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>分发</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 将 node01 修改的配置文件分发给 node02、node03、node04</span><br><span class="line">scp mapred-site.xml yarn-site.xml root@node02:`pwd`</span><br><span class="line">scp mapred-site.xml yarn-site.xml root@node03:`pwd`</span><br><span class="line">scp mapred-site.xml yarn-site.xml root@node04:`pwd`</span><br></pre></td></tr></table></figure>

<h3 id="部署-yarn"><a href="#部署-yarn" class="headerlink" title="部署 yarn"></a>部署 yarn</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 在 node01。 </span><br><span class="line"><span class="meta">#</span> node01 可以免秘钥直接访问其他三个节点 node02、node03、node04</span><br><span class="line"><span class="meta">#</span> 这样 node01 上 hadoop 管理脚本可以直接操纵其他其他机器上的 hadoop</span><br><span class="line">start-yarn.sh </span><br><span class="line"><span class="meta">#</span> 在 node03、node04</span><br><span class="line">yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure>

<h3 id="访问-yarn-web-界面"><a href="#访问-yarn-web-界面" class="headerlink" title="访问 yarn web 界面"></a>访问 yarn web 界面</h3><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">http://node03:8088</span></span><br></pre></td></tr></table></figure>

<p><img src="http://img.zwer.xyz/blog/20191009153119.png" alt></p>
<p>直接访问 <a href="http://node04:8088" target="_blank" rel="noopener">http://node04:8088</a> ,会自动重定向到  <a href="http://node03:8088" target="_blank" rel="noopener">http://node03:8088</a></p>
<p><img src="http://img.zwer.xyz/blog/20191009153209.png" alt></p>
<h3 id="测试-运行-wordCount-程序"><a href="#测试-运行-wordCount-程序" class="headerlink" title="测试-运行 wordCount 程序"></a>测试-运行 wordCount 程序</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 进入 hadoop-2.6.5/share/hadoop/mapreduce 目录下</span><br><span class="line">hadoop jar hadoop-mapreduce-examples-2.6.5.jar wordcount /user/root/test.txt /data/wc/output</span><br></pre></td></tr></table></figure>

<h2 id="手写-wordcount-程序"><a href="#手写-wordcount-程序" class="headerlink" title="手写 wordcount 程序"></a>手写 wordcount 程序</h2><h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MainClient</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration(<span class="keyword">true</span>);</span><br><span class="line">		Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// Create a new Job</span></span><br><span class="line">		<span class="comment">// Job job = Job.getInstance();</span></span><br><span class="line">		job.setJarByClass(MainClient.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// Specify various job-specific parameters</span></span><br><span class="line">		job.setJobName(<span class="string">"myjob"</span>);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// job.setInputPath(new Path("in"));</span></span><br><span class="line">		<span class="comment">// job.setOutputPath(new Path("out"));</span></span><br><span class="line">		<span class="comment">// import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span></span><br><span class="line">		Path path = <span class="keyword">new</span> Path(<span class="string">"/user/root/test.txt"</span>);</span><br><span class="line">		FileInputFormat.addInputPath(job, path);</span><br><span class="line">		</span><br><span class="line">		Path output = <span class="keyword">new</span> Path(<span class="string">"/data/wc/output"</span>);</span><br><span class="line">		<span class="keyword">if</span>(output.getFileSystem(conf).exists(output))&#123;</span><br><span class="line">			output.getFileSystem(conf).delete(output, <span class="keyword">true</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		FileOutputFormat.setOutputPath(job, output );</span><br><span class="line">		</span><br><span class="line">		job.setMapperClass(MyMapper.class);</span><br><span class="line">		job.setMapOutputKeyClass(Text.class);</span><br><span class="line">		job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		job.setReducerClass(MyReducer.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// Submit the job, then poll for progress until the job is complete</span></span><br><span class="line">		job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Mapper"><a href="#Mapper" class="headerlink" title="Mapper"></a>Mapper</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 自定义 Mapper</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> zwer Hadoop 对基本数据类型进行了包装</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line">	<span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">		<span class="comment">// StringTokenizer 对单词数字进行分割</span></span><br><span class="line">		StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());</span><br><span class="line">		<span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">			word.set(itr.nextToken());</span><br><span class="line">			context.write(word, one);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Reducer"><a href="#Reducer" class="headerlink" title="Reducer"></a>Reducer</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();</span><br><span class="line">	<span class="comment">//相同的 key 为一组，调用一次 reduce 方法，方法内迭代这一组数据进行计算 (sum count max min)</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span></span></span><br><span class="line"><span class="function">			<span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">		<span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">			sum += val.get();</span><br><span class="line">		&#125;</span><br><span class="line">		result.set(sum);</span><br><span class="line">		context.write(key, result);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意： 导出 jar 的 JDK 版本与 Linux 上 JDK 版本（大版本号）一致</p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://zwer.xyz/2019/10/08/20191018 Hadoop-网站日志分析系统/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zwer">
      <meta itemprop="description" content="记录学习的日常">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zwer 的博客空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/10/08/20191018 Hadoop-网站日志分析系统/" class="post-title-link" itemprop="url">20191018 Hadoop 网站日志分析系统</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-10-08 00:00:00" itemprop="dateCreated datePublished" datetime="2019-10-08T00:00:00+08:00">2019-10-08</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-29 22:17:38" itemprop="dateModified" datetime="2019-10-29T22:17:38+08:00">2019-10-29</time>
              </span>
            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><h3 id="数据流图"><a href="#数据流图" class="headerlink" title="数据流图"></a>数据流图</h3><p><img src="http://img.zwer.xyz/blog/20191018204503.png" alt></p>
<h3 id="JS-SDK"><a href="#JS-SDK" class="headerlink" title="JS-SDK"></a>JS-SDK</h3><h3 id="Java-SDK"><a href="#Java-SDK" class="headerlink" title="Java-SDK"></a>Java-SDK</h3><p>BlockingQueue 使用 ：</p>
<p><a href="https://app.yinxiang.com/shard/s66/nl/15607671/d69a1aac-5cd6-46fd-ad1f-b28a4d7850b4" target="_blank" rel="noopener">https://app.yinxiang.com/shard/s66/nl/15607671/d69a1aac-5cd6-46fd-ad1f-b28a4d7850b4</a></p>
<h2 id="Nginx-搭建"><a href="#Nginx-搭建" class="headerlink" title="Nginx 搭建"></a>Nginx 搭建</h2><h3 id="注册-Nginx-服务"><a href="#注册-Nginx-服务" class="headerlink" title="注册 Nginx 服务"></a>注册 Nginx 服务</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line">安装之前准备</span><br><span class="line">1、依赖 gcc openssl-devel pcre-devel zlib-devel</span><br><span class="line">	安装：yum install gcc openssl-devel pcre-devel zlib-devel -y</span><br><span class="line"></span><br><span class="line">安装Nginx</span><br><span class="line">./configure </span><br><span class="line"></span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"></span><br><span class="line">默认安装目录：</span><br><span class="line">/usr/local/nginx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">配置Nginx为系统服务，以方便管理</span><br><span class="line">  1、在/etc/rc.d/init.d/目录中建立文本文件nginx</span><br><span class="line">  2、在文件中粘贴下面的内容：</span><br><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> nginx - this script starts and stops the nginx daemon</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> chkconfig:   - 85 15 </span><br><span class="line"><span class="meta">#</span> description:  Nginx is an HTTP(S) server, HTTP(S) reverse \</span><br><span class="line"><span class="meta">#</span>               proxy and IMAP/POP3 proxy server</span><br><span class="line"><span class="meta">#</span> processname: nginx</span><br><span class="line"><span class="meta">#</span> config:      /etc/nginx/nginx.conf</span><br><span class="line"><span class="meta">#</span> config:      /etc/sysconfig/nginx</span><br><span class="line"><span class="meta">#</span> pidfile:     /var/run/nginx.pid</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Source function library.</span><br><span class="line">. /etc/rc.d/init.d/functions</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Source networking configuration.</span><br><span class="line">. /etc/sysconfig/network</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> Check that networking is up.</span><br><span class="line">[ "$NETWORKING" = "no" ] &amp;&amp; exit 0</span><br><span class="line"> </span><br><span class="line">nginx="/usr/local/nginx/sbin/nginx"</span><br><span class="line">prog=$(basename $nginx)</span><br><span class="line"> </span><br><span class="line">NGINX_CONF_FILE="/usr/local/nginx/conf/nginx.conf"</span><br><span class="line"> </span><br><span class="line">[ -f /etc/sysconfig/nginx ] &amp;&amp; . /etc/sysconfig/nginx</span><br><span class="line"> </span><br><span class="line">lockfile=/var/lock/subsys/nginx</span><br><span class="line"> </span><br><span class="line">make_dirs() &#123;</span><br><span class="line"><span class="meta">   #</span> make required directories</span><br><span class="line">   user=`nginx -V 2&gt;&amp;1 | grep "configure arguments:" | sed 's/[^*]*--user=\([^ ]*\).*/\1/g' -`</span><br><span class="line">   options=`$nginx -V 2&gt;&amp;1 | grep 'configure arguments:'`</span><br><span class="line">   for opt in $options; do</span><br><span class="line">       if [ `echo $opt | grep '.*-temp-path'` ]; then</span><br><span class="line">           value=`echo $opt | cut -d "=" -f 2`</span><br><span class="line">           if [ ! -d "$value" ]; then</span><br><span class="line">               # echo "creating" $value</span><br><span class="line">               mkdir -p $value &amp;&amp; chown -R $user $value</span><br><span class="line">           fi</span><br><span class="line">       fi</span><br><span class="line">   done</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">start() &#123;</span><br><span class="line">    [ -x $nginx ] || exit 5</span><br><span class="line">    [ -f $NGINX_CONF_FILE ] || exit 6</span><br><span class="line">    make_dirs</span><br><span class="line">    echo -n $"Starting $prog: "</span><br><span class="line">    daemon $nginx -c $NGINX_CONF_FILE</span><br><span class="line">    retval=$?</span><br><span class="line">    echo</span><br><span class="line">    [ $retval -eq 0 ] &amp;&amp; touch $lockfile</span><br><span class="line">    return $retval</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">stop() &#123;</span><br><span class="line">    echo -n $"Stopping $prog: "</span><br><span class="line">    killproc $prog -QUIT</span><br><span class="line">    retval=$?</span><br><span class="line">    echo</span><br><span class="line">    [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile</span><br><span class="line">    return $retval</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">restart() &#123;</span><br><span class="line">    configtest || return $?</span><br><span class="line">    stop</span><br><span class="line">    sleep 1</span><br><span class="line">    start</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">reload() &#123;</span><br><span class="line">    configtest || return $?</span><br><span class="line">    echo -n $"Reloading $prog: "</span><br><span class="line">    killproc $nginx -HUP</span><br><span class="line">    RETVAL=$?</span><br><span class="line">    echo</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">force_reload() &#123;</span><br><span class="line">    restart</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">configtest() &#123;</span><br><span class="line"><span class="meta">  $</span>nginx -t -c $NGINX_CONF_FILE</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">rh_status() &#123;</span><br><span class="line">    status $prog</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">rh_status_q() &#123;</span><br><span class="line">    rh_status &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">case "$1" in</span><br><span class="line">    start)</span><br><span class="line">        rh_status_q &amp;&amp; exit 0</span><br><span class="line">        $1</span><br><span class="line">        ;;</span><br><span class="line">    stop)</span><br><span class="line">        rh_status_q || exit 0</span><br><span class="line">        $1</span><br><span class="line">        ;;</span><br><span class="line">    restart|configtest)</span><br><span class="line">        $1</span><br><span class="line">        ;;</span><br><span class="line">    reload)</span><br><span class="line">        rh_status_q || exit 7</span><br><span class="line">        $1</span><br><span class="line">        ;;</span><br><span class="line">    force-reload)</span><br><span class="line">        force_reload</span><br><span class="line">        ;;</span><br><span class="line">    status)</span><br><span class="line">        rh_status</span><br><span class="line">        ;;</span><br><span class="line">    condrestart|try-restart)</span><br><span class="line">        rh_status_q || exit 0</span><br><span class="line">            ;;</span><br><span class="line">    *)</span><br><span class="line">        echo $"Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;"</span><br><span class="line">        exit 2</span><br><span class="line">esac</span><br><span class="line"></span><br><span class="line">3、修改nginx文件的执行权限</span><br><span class="line">	chmod +x nginx</span><br><span class="line">4、添加该文件到系统服务中去</span><br><span class="line">	chkconfig --add nginx</span><br><span class="line">	查看是否添加成功</span><br><span class="line">	chkconfig --list nginx</span><br><span class="line"></span><br><span class="line">启动，停止，重新装载</span><br><span class="line">service nginx start|stop</span><br></pre></td></tr></table></figure>

<h3 id="Nginx-conf-配置"><a href="#Nginx-conf-配置" class="headerlink" title="Nginx.conf   配置"></a>Nginx.conf   配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>user  nobody;</span><br><span class="line">worker_processes  1;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line">    </span><br><span class="line">    log_format my_format '$remote_addr^A$msec^A$http_host^A$request_uri';</span><br><span class="line">    </span><br><span class="line">    sendfile        on;</span><br><span class="line">    #tcp_nopush     on;</span><br><span class="line"></span><br><span class="line">    #keepalive_timeout  0;</span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">            root   html;</span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line">        location = /log.gif &#123;</span><br><span class="line">            default_type image/gif;</span><br><span class="line">            access_log /opt/data/access.log my_format;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page   500 502 503 504  /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">      </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Flume"><a href="#Flume" class="headerlink" title="Flume"></a>Flume</h2><h3 id="Flume-简介"><a href="#Flume-简介" class="headerlink" title="Flume 简介"></a>Flume 简介</h3><blockquote>
<p>Flume is a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of log data.</p>
</blockquote>
<p>It has a simple and flexible architecture based on streaming data flows. It is robust and fault tolerant with tunable reliability mechanisms and many failover and recovery mechanisms. It uses a simple extensible data model that allows for online analytic application.</p>
<p><img src="http://flume.apache.org/_images/DevGuide_image00.png" alt></p>
<p>Flume 官网：<a href="http://flume.apache.org/" target="_blank" rel="noopener">http://flume.apache.org/</a></p>
<h3 id="Flume-安装配置及案例"><a href="#Flume-安装配置及案例" class="headerlink" title="Flume 安装配置及案例"></a>Flume 安装配置及案例</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br></pre></td><td class="code"><pre><span class="line">安装</span><br><span class="line">1、上传</span><br><span class="line">2、解压</span><br><span class="line">3、修改conf/flume-env.sh  文件中的JDK目录</span><br><span class="line"> 注意：JAVA_OPTS 配置  如果我们传输文件过大 报内存溢出时 需要修改这个配置项</span><br><span class="line">4、验证安装是否成功  ./flume-ng version</span><br><span class="line">5、配置环境变量</span><br><span class="line">	export FLUME_HOME=/home/apache-flume-1.6.0-bin</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Source、Channel、Sink有哪些类型</span><br><span class="line">    Flume Source</span><br><span class="line">	Source类型 	              | 说明</span><br><span class="line">	Avro Source 	            | 支持Avro协议（实际上是Avro RPC），内置支持</span><br><span class="line">	Thrift Source 	          | 支持Thrift协议，内置支持</span><br><span class="line">	Exec Source 	            | 基于Unix的command在标准输出上生产数据</span><br><span class="line">	JMS Source 	              | 从JMS系统（消息、主题）中读取数据</span><br><span class="line">	Spooling Directory Source | 监控指定目录内数据变更</span><br><span class="line">	Twitter 1% firehose Source|	通过API持续下载Twitter数据，试验性质</span><br><span class="line">	Netcat Source 	          | 监控某个端口，将流经端口的每一个文本行数据作为Event输入</span><br><span class="line">	Sequence Generator Source | 序列生成器数据源，生产序列数据</span><br><span class="line">	Syslog Sources 	          | 读取syslog数据，产生Event，支持UDP和TCP两种协议</span><br><span class="line">	HTTP Source 	            | 基于HTTP POST或GET方式的数据源，支持JSON、BLOB表示形式</span><br><span class="line">	Legacy Sources 	          | 兼容老的Flume OG中Source（0.9.x版本）</span><br><span class="line"></span><br><span class="line">    Flume Channel</span><br><span class="line">	Channel类型 	  说明</span><br><span class="line">	Memory Channel 	           | Event数据存储在内存中</span><br><span class="line">	JDBC Channel   	           | Event数据存储在持久化存储中，当前Flume Channel内置支持Derby</span><br><span class="line">	File Channel   	           | Event数据存储在磁盘文件中</span><br><span class="line">	Spillable Memory Channel   | Event数据存储在内存中和磁盘上，当内存队列满了，会持久化到磁盘文件</span><br><span class="line">	Pseudo Transaction Channel | 测试用途</span><br><span class="line">	Custom Channel 	           | 自定义Channel实现</span><br><span class="line"></span><br><span class="line">    Flume Sink</span><br><span class="line">	Sink类型 	说明</span><br><span class="line">	HDFS Sink 	        | 数据写入HDFS</span><br><span class="line">	Logger Sink 	      | 数据写入日志文件</span><br><span class="line">	Avro Sink 	        | 数据被转换成Avro Event，然后发送到配置的RPC端口上</span><br><span class="line">	Thrift Sink 	      | 数据被转换成Thrift Event，然后发送到配置的RPC端口上</span><br><span class="line">	IRC Sink    	      | 数据在IRC上进行回放</span><br><span class="line">	File Roll Sink 	    | 存储数据到本地文件系统</span><br><span class="line">	Null Sink 	        | 丢弃到所有数据</span><br><span class="line">	HBase Sink 	        | 数据写入HBase数据库</span><br><span class="line">	Morphline Solr Sink | 数据发送到Solr搜索服务器（集群）</span><br><span class="line">	ElasticSearch Sink 	| 数据发送到Elastic Search搜索服务器（集群）</span><br><span class="line">	Kite Dataset Sink 	| 写数据到Kite Dataset，试验性质的</span><br><span class="line">	Custom Sink 	      | 自定义Sink实现</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">案例1、 A simple example</span><br><span class="line">	http://flume.apache.org/FlumeUserGuide.html#a-simple-example</span><br><span class="line">	</span><br><span class="line">	配置文件</span><br><span class="line"><span class="meta">	#</span>###########################################################</span><br><span class="line"><span class="meta">	#</span> Name the components on this agent</span><br><span class="line">	a1.sources = r1</span><br><span class="line">	a1.sinks = k1</span><br><span class="line">	a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Describe/configure the source</span><br><span class="line">	a1.sources.r1.type = netcat</span><br><span class="line">	a1.sources.r1.bind = localhost // 改成主机名</span><br><span class="line">	a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Describe the sink</span><br><span class="line">	a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Use a channel which buffers events in memory</span><br><span class="line">	a1.channels.c1.type = memory</span><br><span class="line">	a1.channels.c1.capacity = 1000</span><br><span class="line">	a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Bind the source and sink to the channel</span><br><span class="line">	a1.sources.r1.channels = c1</span><br><span class="line">	a1.sinks.k1.channel = c1</span><br><span class="line"><span class="meta">	#</span>###########################################################</span><br><span class="line"></span><br><span class="line">启动flume</span><br><span class="line">flume-ng agent -n a1 -c conf -f simple.conf -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">安装telnet</span><br><span class="line">yum install telnet</span><br><span class="line">退出 ctrl+]  quit</span><br><span class="line"></span><br><span class="line">Memory Chanel 配置</span><br><span class="line">  capacity：默认该通道中最大的可以存储的event数量是100，</span><br><span class="line">  trasactionCapacity：每次最大可以source中拿到或者送到sink中的event数量也是100</span><br><span class="line">  keep-alive：event添加到通道中或者移出的允许时间</span><br><span class="line">  byte**：即event的字节量的限制，只包括eventbody</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">案例2、两个flume做集群</span><br><span class="line"></span><br><span class="line">	node01服务器中，配置文件</span><br><span class="line"><span class="meta">	#</span>###########################################################</span><br><span class="line"><span class="meta">	#</span> Name the components on this agent</span><br><span class="line">	a1.sources = r1</span><br><span class="line">	a1.sinks = k1</span><br><span class="line">	a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Describe/configure the source</span><br><span class="line">	a1.sources.r1.type = netcat</span><br><span class="line">	a1.sources.r1.bind = node1</span><br><span class="line">	a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Describe the sink</span><br><span class="line"><span class="meta">	#</span> a1.sinks.k1.type = logger</span><br><span class="line">	a1.sinks.k1.type = avro</span><br><span class="line">	a1.sinks.k1.hostname = node2</span><br><span class="line">	a1.sinks.k1.port = 60000</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Use a channel which buffers events in memory</span><br><span class="line">	a1.channels.c1.type = memory</span><br><span class="line">	a1.channels.c1.capacity = 1000</span><br><span class="line">	a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Bind the source and sink to the channel</span><br><span class="line">	a1.sources.r1.channels = c1</span><br><span class="line">	a1.sinks.k1.channel = c1</span><br><span class="line"><span class="meta">	#</span>###########################################################</span><br><span class="line">	</span><br><span class="line">	node02服务器中，安装Flume（步骤略）</span><br><span class="line">	配置文件</span><br><span class="line"><span class="meta">	#</span>###########################################################</span><br><span class="line"><span class="meta">	#</span> Name the components on this agent</span><br><span class="line">	a1.sources = r1</span><br><span class="line">	a1.sinks = k1</span><br><span class="line">	a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Describe/configure the source</span><br><span class="line">	a1.sources.r1.type = avro</span><br><span class="line">	a1.sources.r1.bind = node2</span><br><span class="line">	a1.sources.r1.port = 60000</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Describe the sink</span><br><span class="line">	a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Use a channel which buffers events in memory</span><br><span class="line">	a1.channels.c1.type = memory</span><br><span class="line">	a1.channels.c1.capacity = 1000</span><br><span class="line">	a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Bind the source and sink to the channel</span><br><span class="line">	a1.sources.r1.channels = c1</span><br><span class="line">	a1.sinks.k1.channel = c1</span><br><span class="line"><span class="meta">	#</span>###########################################################</span><br><span class="line">	</span><br><span class="line">	先启动node02的Flume</span><br><span class="line">	flume-ng agent  -n a1 -c conf -f avro.conf -Dflume.root.logger=INFO,console</span><br><span class="line">	</span><br><span class="line">	再启动node01的Flume</span><br><span class="line">	flume-ng agent  -n a1 -c conf -f simple.conf2 -Dflume.root.logger=INFO,console</span><br><span class="line">	</span><br><span class="line">	打开telnet 测试  node02控制台输出结果</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">案例3、Exec Source</span><br><span class="line">		http://flume.apache.org/FlumeUserGuide.html#exec-source</span><br><span class="line">		</span><br><span class="line">	配置文件</span><br><span class="line"><span class="meta">	#</span>###########################################################</span><br><span class="line">	a1.sources = r1</span><br><span class="line">	a1.sinks = k1</span><br><span class="line">	a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Describe/configure the source</span><br><span class="line">	a1.sources.r1.type = exec</span><br><span class="line">	a1.sources.r1.command = tail -F /home/flume.exec.log</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Describe the sink</span><br><span class="line">	a1.sinks.k1.type = logger</span><br><span class="line">	</span><br><span class="line"><span class="meta">	#</span> Use a channel which buffers events in memory</span><br><span class="line">	a1.channels.c1.type = memory</span><br><span class="line">	a1.channels.c1.capacity = 1000</span><br><span class="line">	a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Bind the source and sink to the channel</span><br><span class="line">	a1.sources.r1.channels = c1</span><br><span class="line">	a1.sinks.k1.channel = c1</span><br><span class="line"><span class="meta">	#</span>###########################################################</span><br><span class="line">	</span><br><span class="line">	启动Flume</span><br><span class="line">	flume-ng agent -n a1 -c conf -f exec.conf -Dflume.root.logger=INFO,console</span><br><span class="line">	</span><br><span class="line">	创建空文件演示 touch flume.exec.log</span><br><span class="line">	循环添加数据</span><br><span class="line">	for i in &#123;1..50&#125;; do echo "$i hi flume" &gt;&gt; flume.exec.log ; sleep 0.1; done</span><br><span class="line">		</span><br><span class="line">案例4、Spooling Directory Source</span><br><span class="line">		http://flume.apache.org/FlumeUserGuide.html#spooling-directory-source</span><br><span class="line">	配置文件</span><br><span class="line"><span class="meta">	#</span>###########################################################</span><br><span class="line">	a1.sources = r1</span><br><span class="line">	a1.sinks = k1</span><br><span class="line">	a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Describe/configure the source</span><br><span class="line">	a1.sources.r1.type = spooldir</span><br><span class="line">	a1.sources.r1.spoolDir = /home/logs</span><br><span class="line">	a1.sources.r1.fileHeader = true</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Describe the sink</span><br><span class="line">	a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Use a channel which buffers events in memory</span><br><span class="line">	a1.channels.c1.type = memory</span><br><span class="line">	a1.channels.c1.capacity = 1000</span><br><span class="line">	a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Bind the source and sink to the channel</span><br><span class="line">	a1.sources.r1.channels = c1</span><br><span class="line">	a1.sinks.k1.channel = c1</span><br><span class="line"><span class="meta">	#</span>###########################################################</span><br><span class="line"></span><br><span class="line">	启动Flume</span><br><span class="line">	flume-ng agent -n a1 -c conf -f spool.conf -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">	拷贝文件演示</span><br><span class="line">	mkdir logs</span><br><span class="line">	cp flume.exec.log logs/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">案例5、hdfs sink</span><br><span class="line">		http://flume.apache.org/FlumeUserGuide.html#hdfs-sink</span><br><span class="line">	</span><br><span class="line">		配置文件</span><br><span class="line"><span class="meta">	#</span>###########################################################</span><br><span class="line">	a1.sources = r1</span><br><span class="line">	a1.sinks = k1</span><br><span class="line">	a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Describe/configure the source</span><br><span class="line">	a1.sources.r1.type = spooldir</span><br><span class="line">	a1.sources.r1.spoolDir = /home/logs</span><br><span class="line">	a1.sources.r1.fileHeader = true</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Describe the sink</span><br><span class="line">	***只修改上一个spool sink的配置代码块 a1.sinks.k1.type = logger</span><br><span class="line">	a1.sinks.k1.type=hdfs</span><br><span class="line">	a1.sinks.k1.hdfs.path=hdfs://bjsxt/flume/%Y-%m-%d/%H%M</span><br><span class="line">	</span><br><span class="line"><span class="meta">	#</span>#每隔60s或者文件大小超过10M的时候产生新文件</span><br><span class="line"><span class="meta">	#</span> hdfs有多少条消息时新建文件，0不基于消息个数</span><br><span class="line">	a1.sinks.k1.hdfs.rollCount=0</span><br><span class="line"><span class="meta">	#</span> hdfs创建多长时间新建文件，0不基于时间,时间单位 s</span><br><span class="line">	a1.sinks.k1.hdfs.rollInterval=60</span><br><span class="line"><span class="meta">	#</span> hdfs多大时新建文件，0不基于文件大小</span><br><span class="line">	a1.sinks.k1.hdfs.rollSize=10240</span><br><span class="line"><span class="meta">	#</span> 当目前被打开的临时文件在该参数指定的时间（秒）内，没有任何数据写入，则将该临时文件关闭并重命名成目标文件</span><br><span class="line">	a1.sinks.k1.hdfs.idleTimeout=3</span><br><span class="line">	</span><br><span class="line">	a1.sinks.k1.hdfs.fileType=DataStream</span><br><span class="line">	a1.sinks.k1.hdfs.useLocalTimeStamp=true</span><br><span class="line">	</span><br><span class="line"><span class="meta">	#</span># 每五分钟生成一个目录:</span><br><span class="line"><span class="meta">	#</span> 是否启用时间上的”舍弃”，这里的”舍弃”，类似于”四舍五入”，后面再介绍。如果启用，则会影响除了%t的其他所有时间表达式</span><br><span class="line">	a1.sinks.k1.hdfs.round=true</span><br><span class="line"><span class="meta">	#</span> 时间上进行“舍弃”的值；</span><br><span class="line">	a1.sinks.k1.hdfs.roundValue=5</span><br><span class="line"><span class="meta">	#</span> 时间上进行”舍弃”的单位，包含：second,minute,hour</span><br><span class="line">	a1.sinks.k1.hdfs.roundUnit=minute</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Use a channel which buffers events in memory</span><br><span class="line">	a1.channels.c1.type = memory</span><br><span class="line">	a1.channels.c1.capacity = 1000</span><br><span class="line">	a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"><span class="meta">	#</span> Bind the source and sink to the channel</span><br><span class="line">	a1.sources.r1.channels = c1</span><br><span class="line">	a1.sinks.k1.channel = c1</span><br><span class="line"><span class="meta">	#</span>###########################################################</span><br><span class="line">	创建HDFS目录</span><br><span class="line">	hadoop fs -mkdir /flume</span><br><span class="line">	</span><br><span class="line">	启动Flume</span><br><span class="line">	flume-ng agent -n a1 -c conf -f hdfs.conf -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">	查看hdfs文件</span><br><span class="line">	hadoop fs -ls /flume/...</span><br><span class="line">	hadoop fs -get /flume/...</span><br><span class="line"></span><br><span class="line">作业：</span><br><span class="line">1、flume如何收集java请求数据</span><br><span class="line">2、项目当中如何来做？ 日志存放/log/目录下 以yyyyMMdd为子目录 分别存放每天的数据</span><br></pre></td></tr></table></figure>

<h2 id="项目模块设计"><a href="#项目模块设计" class="headerlink" title="项目模块设计*"></a><font color="pinbrown">项目模块设计*</font></h2><p>Map（k：按照所需的维度划分 v：唯一标志（便于后面去重））</p>
<p>Reduce（将相同的 k 汇聚到起来，对 value 的值进行去重累加）</p>
<h2 id="ETL-MR"><a href="#ETL-MR" class="headerlink" title="ETL -MR"></a>ETL -MR</h2><p>抽取 extract </p>
<p>转换 transform</p>
<p>加载 load</p>
<h2 id="Hive-与-Hbase-整合"><a href="#Hive-与-Hbase-整合" class="headerlink" title="Hive 与 Hbase 整合"></a>Hive 与 Hbase 整合</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">hive和hbase同步</span><br><span class="line">https://cwiki.apache.org/confluence/display/Hive/HBaseIntegration</span><br><span class="line"></span><br><span class="line">1、在hive的配置文件增加属性：</span><br><span class="line">&lt;property&gt;</span><br><span class="line">   &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;node2,node3,node4&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">2、在hive中创建临时表</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> tmp_order </span><br><span class="line">(<span class="keyword">key</span> <span class="keyword">string</span>, <span class="keyword">id</span> <span class="keyword">string</span>, user_id <span class="keyword">string</span>)  </span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">BY</span> <span class="string">'org.apache.hadoop.hive.hbase.HBaseStorageHandler'</span>  </span><br><span class="line"><span class="keyword">WITH</span> SERDEPROPERTIES (<span class="string">"hbase.columns.mapping"</span> = <span class="string">":key,order:order_id,order:user_id"</span>)  TBLPROPERTIES (<span class="string">"hbase.table.name"</span> = <span class="string">"t_order"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 内部表</span></span><br><span class="line"><span class="comment">-- </span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hbasetbl(<span class="keyword">key</span> <span class="built_in">int</span>, <span class="keyword">value</span> <span class="keyword">string</span>) </span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">BY</span> <span class="string">'org.apache.hadoop.hive.hbase.HBaseStorageHandler'</span></span><br><span class="line"><span class="keyword">WITH</span> SERDEPROPERTIES (<span class="string">"hbase.columns.mapping"</span> = <span class="string">":key,cf1:val"</span>)</span><br><span class="line">TBLPROPERTIES (<span class="string">"hbase.table.name"</span> = <span class="string">"xyz"</span>, <span class="string">"hbase.mapred.output.outputtable"</span> = <span class="string">"xyz"</span>);</span><br></pre></td></tr></table></figure>

<h2 id="Apache-Sqoop"><a href="#Apache-Sqoop" class="headerlink" title="Apache Sqoop"></a>Apache Sqoop</h2><blockquote>
<p>Sqoop 中导入和导出是相对于 HDFS的。</p>
</blockquote>
<h3 id="Sqoop-简介"><a href="#Sqoop-简介" class="headerlink" title="Sqoop 简介"></a>Sqoop 简介</h3><p>Sqoop:将关系数据库（oracle、mysql、postgresql等）数据与 hadoop 数据进行转换的工具</p>
<p>官网：<a href="http://sqoop.apache.org/" target="_blank" rel="noopener">http://sqoop.apache.org/</a></p>
<p>版本：（两个版本完全不兼容，sqoop1使用最多）</p>
<p>sqoop1：1.4.x</p>
<p>sqoop2：1.99.x</p>
<p>同类产品</p>
<p>DataX：阿里顶级数据交换工具                                                                                                                                                                                                                                                                                                                                                                                                                                       </p>
<h3 id="Sqoop-架构"><a href="#Sqoop-架构" class="headerlink" title="Sqoop 架构"></a>Sqoop 架构</h3><ul>
<li>sqoop 架构非常简单，是 hadoop 生态系统的架构最简单的框架。</li>
<li>sqoop1 由 client 端直接接入 hadoop ，任务通过解析生成对应的 maprecue 执行</li>
</ul>
<p><img src="http://img.zwer.xyz/blog/20191024165218.png" alt></p>
<h3 id="Sqoop-导入"><a href="#Sqoop-导入" class="headerlink" title="Sqoop 导入"></a>Sqoop 导入</h3><blockquote>
<p>将数据从 DataBase table 经由 MR 程序导入到 HDFS 中</p>
</blockquote>
<p><img src="http://img.zwer.xyz/blog/20191024192805.png" alt></p>
<h3 id="Sqoop-导出"><a href="#Sqoop-导出" class="headerlink" title="Sqoop 导出"></a>Sqoop 导出</h3><blockquote>
<p>将数据从 HDFS 经由 MR 作业导出到DataBase table 中</p>
</blockquote>
<p><img src="http://img.zwer.xyz/blog/20191024192833.png" alt></p>
<h3 id="Sqoop-安装"><a href="#Sqoop-安装" class="headerlink" title="Sqoop 安装"></a>Sqoop 安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">安装步骤：</span><br><span class="line">1、解压</span><br><span class="line">2、配置环境变量 </span><br><span class="line">export SQOOP_HOME=/XX/sqoop.xx</span><br><span class="line">source /etc/profile</span><br><span class="line">3、添加数据库驱动包</span><br><span class="line">cp mysql-connector-java-5.1.10.jar /sqoop-install-path/lib</span><br><span class="line">4、重命名配置文件</span><br><span class="line">mv sqoop-env-template.sh sqoop-env.sh</span><br><span class="line">5、修改配置configure-sqoop</span><br><span class="line">去掉未安装服务相关内容；例如（HBase、HCatalog、Accumulo）：</span><br><span class="line"><span class="meta">#</span>if [ ! -d "$&#123;HBASE_HOME&#125;" ]; then</span><br><span class="line"><span class="meta">#</span>  echo "Error: $HBASE_HOME does not exist!"</span><br><span class="line"><span class="meta">#</span>  echo 'Please set $HBASE_HOME to the root of your HBase installation.'</span><br><span class="line"><span class="meta">#</span>  exit 1</span><br><span class="line">6、测试</span><br><span class="line">sqoop version</span><br><span class="line">sqoop list-databases -connect jdbc:mysql://node3:3306/ -username root -password 123</span><br></pre></td></tr></table></figure>

<h3 id="Sqoop-工具"><a href="#Sqoop-工具" class="headerlink" title="Sqoop 工具*"></a>Sqoop 工具*</h3><ul>
<li>连接</li>
</ul>
<table>
<thead>
<tr>
<th>选项</th>
<th>含义说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>--connect&lt;jdbc-uri&gt;</code></td>
<td>指定JDBC 连接字符串</td>
</tr>
<tr>
<td><code>--connection-manager&lt;class-name&gt;</code></td>
<td>指定要使用的连接管理器类</td>
</tr>
<tr>
<td><code>--driver&lt;class-name&gt;</code></td>
<td>指定要使用的 JDBC 驱动类</td>
</tr>
<tr>
<td><code>--hadoop-mapred-home&lt;dir&gt;</code></td>
<td>指定 <code>$HADOOP_MAPRED_HOME</code>路径</td>
</tr>
<tr>
<td><code>--help</code></td>
<td>万能帮助</td>
</tr>
<tr>
<td><code>--password-file</code></td>
<td>设置用于存放认证的密码的信息文件的路径</td>
</tr>
<tr>
<td><code>-P</code></td>
<td>从控制台读取输入的密码</td>
</tr>
<tr>
<td><code>--password&lt;password&gt;</code></td>
<td>设置认证密码</td>
</tr>
<tr>
<td><code>--username&lt;username&gt;</code></td>
<td>设置认证用户名</td>
</tr>
<tr>
<td><code>--verbose</code></td>
<td>打印详细的运行信息</td>
</tr>
<tr>
<td><code>--connection-param-file&lt;filename&gt;</code></td>
<td>可选，指定存储数据库连接参数的属性文件</td>
</tr>
</tbody></table>
<ul>
<li>导入工具</li>
</ul>
<p><img src="http://img.zwer.xyz/blog/20191024195013.png" alt></p>
<ul>
<li><p>导出工具 </p>
<p><img src="http://img.zwer.xyz/blog/20191024200334.png" alt></p>
</li>
<li><p>将 MySQL 中数据导入到 HDFS 中</p>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vi 编辑文件 option</span></span><br><span class="line"><span class="comment"># 连接 MySQL 数据库，将表中数据导入 HDFS 中</span></span><br><span class="line">import</span><br><span class="line"><span class="comment">--connect</span></span><br><span class="line">jdbc:mysql://node01:3306/result_db</span><br><span class="line"><span class="comment">--username</span></span><br><span class="line">root</span><br><span class="line"><span class="comment">--password</span></span><br><span class="line">123</span><br><span class="line"><span class="comment">--as-textfile</span></span><br><span class="line"><span class="comment">--columns</span></span><br><span class="line">browser_name,browser_version</span><br><span class="line"><span class="comment">--table</span></span><br><span class="line">dimension_browser</span><br><span class="line"><span class="comment">--delete-target-dir</span></span><br><span class="line"><span class="comment">--target-dir</span></span><br><span class="line">/sqoop/data</span><br><span class="line">-m</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行</span></span><br><span class="line">sqoop <span class="comment">--options-file option</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># vi 编辑文件 option2</span></span><br><span class="line">import</span><br><span class="line"><span class="comment">--connect</span></span><br><span class="line">jdbc:mysql://node01:3306/result_db</span><br><span class="line"><span class="comment">--username</span></span><br><span class="line">root</span><br><span class="line"><span class="comment">--password</span></span><br><span class="line">123</span><br><span class="line"><span class="comment">--as-textfile</span></span><br><span class="line"><span class="comment">--delete-target-dir</span></span><br><span class="line"><span class="comment">--target-dir</span></span><br><span class="line">/sqoop/data</span><br><span class="line">-m</span><br><span class="line">1</span><br><span class="line">-e</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> dimension_browser <span class="keyword">where</span> $CONDITIONS   </span><br><span class="line"></span><br><span class="line"><span class="comment"># sqoop --options-file option2</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>将 MySQL 数据导入到 Hive 中</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import</span><br><span class="line"><span class="comment">--connect</span></span><br><span class="line">jdbc:mysql://node01/result_db</span><br><span class="line"><span class="comment">--username</span></span><br><span class="line">root</span><br><span class="line"><span class="comment">--password</span></span><br><span class="line">123</span><br><span class="line"><span class="comment">--as-textfile</span></span><br><span class="line"><span class="comment">--query</span></span><br><span class="line">'<span class="keyword">select</span> * <span class="keyword">from</span> dimension_browser <span class="keyword">where</span> $CONDITIONS<span class="string">'</span></span><br><span class="line"><span class="string">--delete-target-dir</span></span><br><span class="line"><span class="string">--target-dir</span></span><br><span class="line"><span class="string">/sqoop/tmp</span></span><br><span class="line"><span class="string">-m</span></span><br><span class="line"><span class="string">1</span></span><br><span class="line"><span class="string">--hive-home</span></span><br><span class="line"><span class="string">/user/hive/warehouse</span></span><br><span class="line"><span class="string">--hive-import</span></span><br><span class="line"><span class="string">--create-hive-table</span></span><br><span class="line"><span class="string">--hive-table</span></span><br><span class="line"><span class="string">t_browser</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>将 Hive 中导出到 MySQL 表中</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">    export</span><br><span class="line">    --connect</span><br><span class="line">jdbc:mysql://node01/test</span><br><span class="line">    --username</span><br><span class="line">    root</span><br><span class="line">    --password</span><br><span class="line">    123</span><br><span class="line">    -m</span><br><span class="line">    1</span><br><span class="line">    --columns</span><br><span class="line">    id,browser_name,browser_version</span><br><span class="line">    --export-dir</span><br><span class="line">    /sqoop/data</span><br><span class="line">    --table</span><br><span class="line">    h_browser</span><br></pre></td></tr></table></figure>


</li>
</ul>
<pre><code>注意：MySQL中 test.h_browser   需要提前创建</code></pre><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><h3 id="调优的目的"><a href="#调优的目的" class="headerlink" title="调优的目的"></a>调优的目的</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">充分的利用机器的性能，更快的完成 mr 程序的计算任务。</span><br><span class="line">甚至是在有限的机器条件下，能够支持运行足够多的mr程序。</span><br></pre></td></tr></table></figure>

<h3 id="调优的总体概述"><a href="#调优的总体概述" class="headerlink" title="调优的总体概述"></a>调优的总体概述</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">从mr程序的内部运行机制，我们可以了解到一个mr程序由mapper和reducer两个阶段组成，其中mapper阶段包括数据的读取、map处理以及写出操作(排序和合并/sort&amp;merge)，而reducer阶段包含mapper输出数据的获取、数据合并(sort&amp;merge)、reduce处理以及写出操作。那么在这七个子阶段中，能够进行较大力度的进行调优的就是map输出、reducer数据合并以及reducer个数这三个方面的调优操作。</span><br><span class="line">也就是说虽然性能调优包括cpu、内存、磁盘io以及网络这四个大方面，但是从mr程序的执行流程中，我们可以知道主要有调优的是内存、磁盘io以及网络。</span><br><span class="line">在mr程序中调优，主要考虑的就是减少网络传输和减少磁盘IO操作，故本次课程的mr调优主要包括服务器调优、代码调优、mapper调优、reducer调优以及runner调优这五个方面。</span><br></pre></td></tr></table></figure>

<h3 id="服务器调优"><a href="#服务器调优" class="headerlink" title="服务器调优"></a>服务器调优</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">服务器调优主要包括服务器参数调优和jvm调优。在本次项目中，由于我们使用hbase作为我们分析数据的原始数据存储表，所以对于hbase我们也需要进行一些调优操作。除了参数调优之外，和其他一般的java程序一样，还需要进行一些jvm调优。</span><br></pre></td></tr></table></figure>

<p>推荐书籍： 《深入理解 Java 虚拟机 -周志明》</p>
<h3 id="hdfs-调优"><a href="#hdfs-调优" class="headerlink" title="hdfs 调优"></a>hdfs 调优</h3><pre><code>1. dfs.datanode.failed.volumes.tolerated: 允许发生磁盘错误的磁盘数量，默认为0，表示不允许datanode发生磁盘异常。当挂载多个磁盘的时候，可以修改该值。
2. dfs.replication: 复制因子，默认3
3. dfs.namenode.handler.count: namenode节点并发线程量，默认10
4. dfs.datanode.handler.count：datanode之间的并发线程量，默认10。
5. dfs.datanode.max.transfer.threads：datanode提供的数据流操作的并发线程量，默认4096。
    一般将其设置为linux系统的文件句柄数的85%~90%之间，查看文件句柄数语句ulimit -a，修改vim /etc/security/limits.conf, 不能设置太大
    文件末尾，添加
        * soft nofile 65535
        * hard nofile 65535
        注意：句柄数不能够太大，可以设置为1000000以下的所有数值，一般不设置为-1。
        异常处理：当设置句柄数较大的时候，重新登录可能出现unable load session的提示信息，这个时候采用单用户模式进行修改操作即可。
            单用户模式：
                启动的时候按&apos;a&apos;键，进入选择界面，然后按&apos;e&apos;键进入kernel修改界面，然后选择第二行&apos;kernel...&apos;，按&apos;e&apos;键进行修改，在最后添加空格+single即可，按回车键回到修改界面，最后按&apos;b&apos;键进行单用户模式启动，当启动成功后，还原文件后保存，最后退出(exit)重启系统即可。
6. io.file.buffer.size: 读取/写出数据的buffer大小，默认4096，一般不用设置，推荐设置为4096的整数倍(物理页面的整数倍大小)。</code></pre><h3 id="hbase调优"><a href="#hbase调优" class="headerlink" title="hbase调优"></a>hbase调优</h3><pre><code>1. 设置regionserver的内存大小，默认为1g，推荐设置为4g。
    修改conf/hbase-env.sh中的HBASE_HEAPSIZE=4g
2. hbase.regionserver.handler.count: 修改客户端并发线程数，默认为10。设置规则为，当put和scans操作比较的多的时候，将其设置为比较小的值；当get和delete操作比较多的时候，将其设置为比较大的值。原因是防止频繁GC操作导致内存异常。
3. 自定义hbase的分割和紧缩操作，默认情况下hbase的分割机制是当region大小达到hbase.hregion.max.filesize(10g)的时候进行自动分割，推荐每个regionserver的region个数在20~500个为最佳。hbase的紧缩机制是hbase的一个非常重要的管理机制，hbase的紧缩操作是非常消耗内存和cpu的，所以一般机器压力比较大的话，推荐将其关闭，改为手动控制。
4. hbase.balancer.period： 设置hbase的负载均衡时间，默认为300000(5分钟)，在负载比较高的集群上，将其值可以适当的改大。
5. hfile.block.cache.size：修改hflie文件块在内存的占比，默认0.4。在读应用比较多的系统中，可以适当的增大该值，在写应用比较多的系统中，可以适当的减少该值，不过不推荐修改为0。
6. hbase.regionserver.global.memstore.upperLimit：修改memstore的内存占用比率上限，默认0.4，当达到该值的时候，会进行flush操作将内容写的磁盘中。
7. hbase.regionserver.global.memstore.lowerLimit: 修改memstore的内存占用比率下限，默认0.38，进行flush操作后，memstore占用的内存比率必须不大于该值。
8. hbase.hregion.memstore.flush.size: 当memstore的值大于该值的时候，进行flush操作。默认134217728(128M)。
9. hbase.hregion.memstore.block.multiplier: 修改memstore阻塞块大小比率值，默认为4。也就是说在memstore的大小超过4*hbase.hregion.memstore.flush.size的时候就会触发写阻塞操作。最终可能会导致出现oom异常。</code></pre><h3 id="mapreduce调优"><a href="#mapreduce调优" class="headerlink" title="mapreduce调优"></a>mapreduce调优</h3><pre><code>1. mapreduce.task.io.sort.factor: mr程序进行合并排序的时候，打开的文件数量，默认为10个.
2. mapreduce.task.io.sort.mb: mr程序进行合并排序操作的时候或者mapper写数据的时候，内存大小，默认100M
3. mapreduce.map.sort.spill.percent： mr程序进行flush操作的阀值，默认0.80。
4. mapreduce.reduce.shuffle.parallelcopies：mr程序reducer copy数据的线程数，默认5。
5. mapreduce.reduce.shuffle.input.buffer.percent: reduce复制map数据的时候指定的内存堆大小百分比，默认为0.70，适当的增加该值可以减少map数据的磁盘溢出，能够提高系统性能。
6. mapreduce.reduce.shuffle.merge.percent：reduce进行shuffle的时候，用于启动合并输出和磁盘溢写的过程的阀值，默认为0.66。如果允许，适当增大其比例能够减少磁盘溢写次数，提高系统性能。同mapreduce.reduce.shuffle.input.buffer.percent一起使用。
7. mapreduce.task.timeout：mr程序的task执行情况汇报过期时间，默认600000(10分钟)，设置为0表示不进行该值的判断。</code></pre><h3 id="代码调优"><a href="#代码调优" class="headerlink" title="代码调优"></a>代码调优</h3><p>​    代码调优，主要是mapper和reducer中，针对多次创建的对象，进行代码提出操作。这个和一般的java程序的代码调优一样。</p>
<ul>
<li><strong>mapper 调优</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mapper调优主要就是就一个目标：减少输出量。我们可以通过增加combine阶段以及对输出进行压缩设置进行mapper调优。</span><br><span class="line">combine介绍：</span><br><span class="line">实现自定义combine要求继承reducer类，特点：</span><br><span class="line">以map的输出key/value键值对作为输入输出键值对，作用是减少网络输出，在map节点上就合并一部分数据。</span><br><span class="line">比较适合，map的输出是数值型的，方便进行统计。</span><br><span class="line">压缩设置：</span><br><span class="line">在提交job的时候分别设置启动压缩和指定压缩方式。</span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>reducer 调优</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">reducer调优主要是通过参数调优和设置reducer的个数来完成。</span><br><span class="line">reducer个数调优：</span><br><span class="line">要求：一个reducer和多个reducer的执行结果一致，不能因为多个reducer导致执行结果异常。</span><br><span class="line">规则：一般要求在hadoop集群中的执行mr程序，map执行完成100%后，尽量早的看到reducer执行到33%，可以通过命令hadoop job -status job_id或者web页面来查看。</span><br><span class="line">原因： map的执行process数是通过inputformat返回recordread来定义的；而reducer是有三部分构成的，分别为读取mapper输出数据、合并所有输出数据以及reduce处理，其中第一步要依赖map的执行，所以在数据量比较大的情况下，一个reducer无法满足性能要求的情况下，我们可以通过调高reducer的个数来解决该问题。</span><br><span class="line">优点：充分利用集群的优势。</span><br><span class="line">缺点：有些mr程序没法利用多reducer的优点，比如获取top n的mr程序。</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>runner 调优</strong></p>
<pre><code>runner 调优其实就是在提交job的时候设置 job 参数，一般都可以通过代码和xml文件两种方式进行设置。
  1~8详见ActiveUserRunner(before和configure方法)，9详解TransformerBaseRunner(initScans方法)</code></pre><ol>
<li>mapred.child.java.opts: 修改childyard进程执行的jvm参数，针对map和reducer均有效，默认：-Xmx200m </li>
<li>mapreduce.map.java.opts： 需改map阶段的childyard进程执行jvm参数，默认为空，当为空的时候，使用mapred.child.java.opts。</li>
<li>mapreduce.reduce.java.opts：修改reducer阶段的childyard进程执行jvm参数，默认为空，当为空的时候，使用mapred.child.java.opts。</li>
<li>mapreduce.job.reduces： 修改reducer的个数，默认为1。可以通过job.setNumReduceTasks方法来进行更改。</li>
<li>mapreduce.map.speculative：是否启动map阶段的推测执行，默认为true。其实一般情况设置为false比较好。可通过方法job.setMapSpeculativeExecution来设置。</li>
<li>mapreduce.reduce.speculative：是否需要启动reduce阶段的推测执行，默认为true，其实一般情况设置为fase比较好。可通过方法job.setReduceSpeculativeExecution来设置。</li>
<li>mapreduce.map.output.compress：设置是否启动map输出的压缩机制，默认为false。在需要减少网络传输的时候，可以设置为true。</li>
<li>mapreduce.map.output.compress.codec：设置map输出压缩机制，默认为org.apache.hadoop.io.compress.DefaultCodec，推荐使用SnappyCodec(在之前版本中需要进行安装操作，现在版本不太清楚，安装参数：<a href="http://www.cnblogs.com/chengxin1982/p/3862309.html" target="_blank" rel="noopener">http://www.cnblogs.com/chengxin1982/p/3862309.html</a>)</li>
<li>hbase参数设置</li>
</ol>
</li>
</ul>
<pre><code>由于hbase默认是一条一条数据拿取的，在mapper节点上执行的时候是每处理一条数据后就从hbase中获取下一条数据，通过设置cache值可以一次获取多条数据，减少网络数据传输。</code></pre>
        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://zwer.xyz/2019/10/01/README/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zwer">
      <meta itemprop="description" content="记录学习的日常">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zwer 的博客空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/10/01/README/" class="post-title-link" itemprop="url">流年</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-10-01 00:00:00" itemprop="dateCreated datePublished" datetime="2019-10-01T00:00:00+08:00">2019-10-01</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-09 21:53:10" itemprop="dateModified" datetime="2019-10-09T21:53:10+08:00">2019-10-09</time>
              </span>
            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>我只想拉住流年</li>
<li>好好地说声再见</li>
<li>遗憾感谢 都回不去昨天</li>
<li>我只想铭记这瞬间</li>
<li>我们一去走过的流年</li>
</ul>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://zwer.xyz/2019/09/28/201909028 Hadoop之分布式系统 HDFS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zwer">
      <meta itemprop="description" content="记录学习的日常">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zwer 的博客空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/09/28/201909028 Hadoop之分布式系统 HDFS/" class="post-title-link" itemprop="url">20190928 Hadoop</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-09-28 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-28T00:00:00+08:00">2019-09-28</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-09 21:31:09" itemprop="dateModified" datetime="2019-10-09T21:31:09+08:00">2019-10-09</time>
              </span>
            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>是什么</p>
<p>为什么</p>
<p>如何去使用</p>
<h2 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h2><blockquote>
<p>Hadoop简介：<a href="http://hadoop.apache.org" target="_blank" rel="noopener">http://hadoop.apache.org</a></p>
<p>The Apache™ Hadoop® project develops open-source software for reliable, scalable, distributed computing.The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver high-availability, the library itself is designed to detect and handle failures at the application layer, so delivering a highly-available service on top of a cluster of computers, each of which may be prone to failures.</p>
</blockquote>
<table>
<thead>
<tr>
<th>模块</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>分布式存储系统HDFS （Hadoop Distributed File System ）POSIX</td>
<td>提供了 高可靠性、高扩展性和高吞吐率的数据存储服务</td>
</tr>
<tr>
<td>分布式计算框架MapReduce分布式计算框架（计算向数据移动）</td>
<td>具有 易于编程、高容错性和高扩展性等优点。</td>
</tr>
<tr>
<td>分布式资源管理框架YARN（Yet Another Resource Management）</td>
<td>负责集群资源的管理和调度</td>
</tr>
</tbody></table>
<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><h3 id="存储模型：字节"><a href="#存储模型：字节" class="headerlink" title="存储模型：字节*"></a>存储模型：字节*</h3><blockquote>
<p>文件线性切割成块（Block）:<font color="red">偏移量 offset （byte）</font></p>
<ul>
<li>Block 分散存储在集群节点中单一文件Block<font color="red">大小一致，文件与文件可以不一致</font></li>
<li>Block可以设置<font color="red">副本数</font>，副本分散在不同节点中副本数不要超过节点数量</li>
<li>文件上传可以设置Block大小和副本数</li>
<li>已上传的文件Block副本数可以调整</li>
<li><strong>大小不变</strong>只支持一次写入多次读取，同一时刻只有一个写入者可以 append 追加数据</li>
</ul>
</blockquote>
<p>在一个文件中 Block 的大小保持一致，在不同文件中 Block 的大小可以不一致。</p>
<p>注意：同一个机器不能存储两个相同的副本，副本应该存在不同的机器上的。</p>
<p><img src="http://img.zwer.xyz/blog/20190928193642.png" alt></p>
<h3 id="架构模型"><a href="#架构模型" class="headerlink" title="架构模型"></a>架构模型</h3><blockquote>
<p>文件元数据 MetaData，文件数据<br>元数据:数据本身<br>NameNode(主)节点保存文件元数据：单节点   posix<br>DataNode(从)节点保存文件Block数据：<font color="red">多节点</font><br>DataNode与 NameNode <font color="red">保持心跳</font>，提交Block列表<br>HdfsClient 与 NameNode 交互元数据信息<br>HdfsClient 与 DataNode 交互文件Block数据</p>
</blockquote>
<p><img src="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.png" alt></p>
<h3 id="NameNode-NN"><a href="#NameNode-NN" class="headerlink" title="NameNode(NN)"></a>NameNode(NN)</h3><table>
<thead>
<tr>
<th>定义</th>
<th>主要功能</th>
</tr>
</thead>
<tbody><tr>
<td>基于内存存储 ：不会和磁盘发生交换<br>- 只存在内存中<br>- 持久化（fsimage、edits）</td>
<td>接受客户端的读写服务<br>收集 DataNode 汇报的 Block 列表信息<br>NameNode 保存 metadata 信息包括<br>文件 owership 和 permissions <br>文件大小，时间<br>（Block列表：Block偏移量），<font color="red">位置信息</font><br>Block每副本位置（由DataNode上报）</td>
</tr>
</tbody></table>
<p><strong>注意： NameNode 记录快照时是不包括 DataNode 的位置信息的。</strong></p>
<h4 id="NameNode-持久化"><a href="#NameNode-持久化" class="headerlink" title="NameNode 持久化"></a>NameNode 持久化</h4><ul>
<li>NameNode 的 metadate 信息在启动后会加载到内存</li>
<li>metadata 存储到磁盘文件名为”fsimage”</li>
<li><strong>Block 的位置信息不会保存到 fsimage</strong></li>
<li>edits记录对 metadata 的操作日志</li>
</ul>
<p>若 NameNode  发生故障，首先会从磁盘 fsimage 文件中恢复到上一次记录快照的状态，然后在根据 edits 记录执行从上一次记录快照的时刻到 NameNode 宕机前的操作。</p>
<h3 id="DataNode（DN）"><a href="#DataNode（DN）" class="headerlink" title="DataNode（DN）"></a>DataNode（DN）</h3><blockquote>
<p>本地磁盘目录存储数据（Block），文件形式</p>
<p>同时存储Block的元数据信息文件</p>
<p>启动 DN 时会向 NN 汇报 block 信息</p>
<p>通过向 NN 发送心跳保持与其联系（3秒一次），</p>
<p>如果 NN 10分钟没有收到 DN 的心跳，则认为其已经 lost，并 copy <strong>其上</strong>的 block 到其它 DN</p>
<p>注意：若一台 DN 宕机了，NN 10 分钟才会认为该 DN 已经丢失。这时 NN 会根据之前该 DN 上传的 block 信息，去其他 DN 上寻找这些 block 的副本。</p>
</blockquote>
<h3 id="HDFS-优缺点"><a href="#HDFS-优缺点" class="headerlink" title="HDFS 优缺点"></a>HDFS 优缺点</h3><table>
<thead>
<tr>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td><strong>1. 高容错性</strong><br>  数据自动保存多个副本  副本丢失后，自动恢复 <br><strong>2. 适合批处理</strong> <br>  移动计算而非数据 数据位置暴露给计算框架（Block偏移量） <br><strong>3. 适合大数据处理</strong><br> GB 、TB 、甚至PB 级数据 百万规模以上的文件数量 10K+ 节点 <br><strong>4. 可构建在廉价机器上</strong> <br>通过多副本提高可靠性 提供了容错和恢复 机制</td>
<td>低延迟数据访问<br>比如毫秒级<br>低延迟与高吞吐率<br>小文件存取<br>占用NameNode 大量内存<br>寻道时间超过读取时间<br>并发写入、文件随机修改<br>一个文件只能有一个写者<br>仅支持append</td>
</tr>
</tbody></table>
<h3 id="SecondaryNameNode（SNN）"><a href="#SecondaryNameNode（SNN）" class="headerlink" title="SecondaryNameNode（SNN）"></a>SecondaryNameNode（SNN）</h3><blockquote>
<p>它不是NN的备份（但可以做备份），它的主要工作是帮助NN合并edits log，减少NN启动时间。<br>SNN执行合并时机<br>根据配置文件设置的时间间隔 fs.checkpoint.period  默认3600秒<br>根据配置文件设置edits log大小 fs.checkpoint.size 规定edits文件的最大值默认是64MB    </p>
</blockquote>
<h4 id="SNN合并流程"><a href="#SNN合并流程" class="headerlink" title="SNN合并流程"></a>SNN合并流程</h4><ol>
<li>在 PN 合并之前，会将 edits 和 fsimage 文件发送给 SN，然后 PN 创建一个新的 edits.new 文件继续记录 PN 的操作。</li>
<li>PN 将之前的 edits 和 fsimage 发送给 SN 后，SN 会将 fsimage 加载到内存，edits 也加载到内存</li>
<li>根据 edits 中操作记录执行相应的指令，当 edits 的所有操作记录对应的指令执行完毕，会生成一个新的 fsimage.ckpt 快照。</li>
<li>将新生成的 fsimage.ckpt 再发送给 PN ，这时 PN 就拥有 edits.new 创建之前的快照记录</li>
<li>若 PN 发生了宕机，可以根据 fsimage 和 edits.new 恢复到宕机前的状态</li>
</ol>
<p><img src="http://img.zwer.xyz/blog/20190929192321.png" alt></p>
<h3 id="副本放置策略"><a href="#副本放置策略" class="headerlink" title="副本放置策略"></a>副本放置策略</h3><blockquote>
<p>第一个副本：放置在上传文件的 DN；如果是集群外提交，则随机挑选一台磁盘不太满，CPU不太忙的节点。</p>
<p>第二个副本：放置在于第一个副本不同的 机架的节点上。</p>
<p>第三个副本：与第二个副本相同机架的节点。</p>
<p>更多副本：随机节点</p>
</blockquote>
<p><strong>注意：第一个副本与第二个副本不在同一台机架上</strong></p>
<p>服务器的种类： 1.塔式（就像家里的台式机主机箱那样）2. 机箱（像 DVD机那样）3. 刀片（像厨房放刀的刀架）</p>
<p><img src="http://img.zwer.xyz/blog/20190929203934.png" alt></p>
<h3 id="HDFS-写流程"><a href="#HDFS-写流程" class="headerlink" title="HDFS 写流程*"></a>HDFS 写流程*</h3><blockquote>
<p>Client：</p>
<ul>
<li><p>切分文件 Block</p>
</li>
<li><p>按 Block 线性和 NN 获取 DN 列表（副本数）</p>
</li>
<li><p>验证DN列表后以<strong>更小的单位</strong>流式传输数据</p>
</li>
<li><p>各节点，两两通信确定可用</p>
</li>
<li><p>Block传输结束后：</p>
<ul>
<li><p>DN 向 NN汇报Block信息</p>
</li>
<li><p>DN 向 Client汇报完成</p>
</li>
<li><p>Clien t向 NN 汇报完成</p>
</li>
</ul>
</li>
<li><p>获取下一个 Block 存放的 DN 列表<br>循环往复之前的操作 …</p>
</li>
<li><p>最终Client汇报完成</p>
</li>
<li><p>NN会在写流程更新文件状态</p>
</li>
</ul>
</blockquote>
<p>注意：</p>
<ol>
<li>client 向 DataNode 写数据，分为许多小数据包，一次次的传递，直到所有数据包都发送完毕</li>
</ol>
<p><img src="http://img.zwer.xyz/blog/20190929204035.png" alt></p>
<h3 id="HDFS-读流程"><a href="#HDFS-读流程" class="headerlink" title="HDFS 读流程*"></a>HDFS 读流程*</h3><blockquote>
<p>Client：</p>
<ul>
<li>和 NN 获取一部分 Block 副本位置列表</li>
<li>线性和 DN 获取 Block，最终合并为一个文件</li>
<li>在Block副本列表中<strong>按距离择优选取</strong></li>
</ul>
</blockquote>
<p><img src="http://img.zwer.xyz/blog/20190929204234.png" alt></p>
<ol>
<li>HDFS 发送请求到 DistributedFileSystem，DistributedFileSystem 会向 NameNode 索要指定文件所有块信息，并返回所有块副本信息（按副本顺序按距离排序）</li>
<li>通过 HDFS，可以读取文件任意块的位置</li>
</ol>
<p><strong>记： 分布式文件系统很好的支持计算层的本地化读取</strong></p>
<h3 id="HDFS文件权限-POSIX"><a href="#HDFS文件权限-POSIX" class="headerlink" title="HDFS文件权限  POSIX"></a>HDFS文件权限  POSIX</h3><p>与Linux文件权限类似</p>
<p>r: read; w:write; x:execute</p>
<p>权限x对于文件忽略，对于文件夹表示是否允许访问其内容</p>
<p>如果Linux系统用户zhangsan使用hadoop命令创建一个文件，那么这个文件在HDFS中owner就是zhangsan。</p>
<p>HDFS的权限目的：阻止好人错错事，而不是阻止坏人做坏事。HDFS相信，你告诉我你是谁，我就认为你是谁。</p>
<h3 id="安全模式"><a href="#安全模式" class="headerlink" title="安全模式"></a>安全模式</h3><p>namenode启动的时候，首先将映像文件(fsimage)载入内存，并执行编辑日志(edits)中的各项操作。</p>
<p>一旦在内存中成功建立文件系统元数据的映射，则创建一个新的fsimage文件(这个操作不需要</p>
<p>SecondaryNameNode)和一个空的编辑日志。</p>
<p>此刻namenode运行在安全模式。即namenode的文件系统对于客户端来说是只读的。(显示目录，显示文件内容</p>
<p>等。写、删除、重命名都会失败)。<br>在此阶段Namenode收集各个datanode的报告，当数据块达到最小副本数以上时，会被认为是“安全”的， 在一定</p>
<p>比例（可设置）的数据块被确定为“安全”后，再过若干时间，安全模式结束</p>
<p>当检测到副本数不足的数据块时，该块会被复制直到达到最小副本数，系统中数据块的位置并不是由namenode</p>
<p>维护的，而是以块列表形式存储在datanode中。</p>
<h3 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h3><table>
<thead>
<tr>
<th>角色（进程）</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>NameNode</td>
<td>数据元数据<br>内存存储，不会有磁盘交换<br>持久化（fsimage，eidts log）<br>不会持久化block的位置信息</td>
</tr>
<tr>
<td>block</td>
<td>偏移量，因为block不可以调整大小，hdfs，不支持修改文件<br>偏移量不会改变<br>datanode<br>block块</td>
</tr>
<tr>
<td>磁盘</td>
<td>面向文件，大小一样，不能调整<br>副本数，调整，（备份，高可用，容错/可以调整很多个，为了计算向数据移动）</td>
</tr>
<tr>
<td>SN</td>
<td></td>
</tr>
<tr>
<td>NN &amp; DN</td>
<td>心跳机制<br>DN 向 NN 汇报block信息<br>安全模式</td>
</tr>
<tr>
<td>client</td>
<td></td>
</tr>
</tbody></table>
<h2 id="搭建-Hadoop-伪分布式"><a href="#搭建-Hadoop-伪分布式" class="headerlink" title="搭建 Hadoop 伪分布式"></a>搭建 Hadoop 伪分布式</h2><h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><h4 id="时间同步"><a href="#时间同步" class="headerlink" title="时间同步"></a>时间同步</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">type ntpdate</span><br><span class="line"><span class="meta">#</span> 安装 ntpdate</span><br><span class="line">yum install -y ntpdate</span><br><span class="line"><span class="meta">#</span> 同步网络时</span><br><span class="line">ntpdate -u ntp.api.bz</span><br></pre></td></tr></table></figure>

<h4 id="操作系统环境设置"><a href="#操作系统环境设置" class="headerlink" title="操作系统环境设置"></a>操作系统环境设置</h4><ul>
<li>确认主机名一致</li>
</ul>
<p><img src="http://img.zwer.xyz/blog/20190930112247.png" alt></p>
<ul>
<li>ssh 免密钥</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 在另外一台机器上远程执行 192.168.170.101 机器上的命令(验证)</span><br><span class="line">ssh root@192.168.170.101 'ls ~' </span><br><span class="line"></span><br><span class="line"><span class="meta">$</span> ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa  # 生成密钥</span><br><span class="line"><span class="meta">$</span> cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys  # 对自己免密钥</span><br></pre></td></tr></table></figure>

<ul>
<li>安装 Java 并配置环境变量</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh jdk-7u67-linux-x64.rpm</span><br><span class="line"><span class="meta">#</span> 修改 /etc/profile</span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.7.0_67</span><br><span class="line">export PATH=$PATH:$JAVA_HOME</span><br></pre></td></tr></table></figure>

<h4 id="Hadoop-配置"><a href="#Hadoop-配置" class="headerlink" title="Hadoop 配置"></a>Hadoop 配置</h4><ul>
<li>安装 Hadoop 并配置环境变量</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">tar xf hadoop-2.6.5.tar.gz </span><br><span class="line">mkdir /opt/sxt</span><br><span class="line">mv hadoop-2.6.5 /opt/sxt/</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>  配置 hadoop 环境变量</span><br><span class="line">export HADOOP_HOME=/opt/sxt/hadoop-2.6.5</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> cd /opt/sxt/hadoop-2.6.5/</span><br><span class="line"><span class="meta">#</span> 进入 etc 目录中</span><br><span class="line"><span class="meta">#</span> 修改 Java 环境路径，export JAVA_HOME=/usr/java/jdk1.7.0_67</span><br><span class="line"><span class="meta">#</span> 目的是 hadoop 管理脚本操作机器不能读取 /etc/profile 文件，所以需要改 Java 的绝对路径</span><br><span class="line">vi hadoop-env.sh</span><br><span class="line">vi mapred-env.sh</span><br><span class="line">vi yarn-env.sh</span><br></pre></td></tr></table></figure>

<ul>
<li>修改  slaves</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">将 localhsot 改为 node01</span><br><span class="line">node01</span><br></pre></td></tr></table></figure>

<ul>
<li>修改 core-site.xml</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node01:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/var/sxt/hadoop/local<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>修改 hdfs-site.xml</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>配置文件</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>etc/hadoop/core-site.xml</td>
<td>决定 NameNode 的启动</td>
</tr>
<tr>
<td>etc/hadoop/slaves</td>
<td>决定 DataNode 的启动</td>
</tr>
<tr>
<td>etc/hadoop/hdfs-site.xml</td>
<td>决定 SecondaryNode 的启动</td>
</tr>
</tbody></table>
<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 格式化</span><br><span class="line"><span class="meta">$</span>hdfs namenode -format</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span>ls /var/sxt/hodoop/local/dfs/name/current/</span><br><span class="line">fsimage_0000000000000000000  fsimage_0000000000000000000.md5  seen_txid  VERSION</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 启动  NN、DN、SN</span><br><span class="line"><span class="meta">$</span>start-dfs.sh</span><br><span class="line"><span class="meta">#</span> jps 查看 Java 进程，是否有 NN、DN、SN</span><br><span class="line"><span class="meta">$</span>jps</span><br><span class="line">3385 DataNode</span><br><span class="line">3543 SecondaryNameNode</span><br><span class="line">3674 Jps</span><br><span class="line">3306 NameNode</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>访问 http://192.168.170.101:50070</span><br></pre></td></tr></table></figure>

<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir /user</span><br><span class="line">hdfs dfs -ls /user</span><br><span class="line">hdfs dfs -mkdir /user/root</span><br><span class="line">hdfs dfs -D dfs.blocksize=1048576 -put hadoop-2.6.5.tar.gz </span><br><span class="line"><span class="meta">#</span> 展示当前目录，并显示文件大小 </span><br><span class="line">ll -h</span><br></pre></td></tr></table></figure>

<h2 id="搭建-Hadoop-全分布式"><a href="#搭建-Hadoop-全分布式" class="headerlink" title="搭建 Hadoop 全分布式"></a>搭建 Hadoop 全分布式</h2><h3 id="准备-1"><a href="#准备-1" class="headerlink" title="准备"></a>准备</h3><table>
<thead>
<tr>
<th></th>
<th>NN</th>
<th>SNN</th>
<th>DN</th>
</tr>
</thead>
<tbody><tr>
<td>node01</td>
<td>*</td>
<td></td>
<td></td>
</tr>
<tr>
<td>node02</td>
<td></td>
<td>*</td>
<td>*</td>
</tr>
<tr>
<td>node03</td>
<td></td>
<td></td>
<td>*</td>
</tr>
<tr>
<td>node04</td>
<td></td>
<td></td>
<td>*</td>
</tr>
</tbody></table>
<h3 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 关闭 Hadoop 伪分布式</span><br><span class="line">stop-dfs.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 配置节点 node02、node03、node04 的 java 环境 和 ssh</span><br><span class="line">cat ~/node01.pub  &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 以下操作针对 node01 ---------------------------------------------</span><br><span class="line"><span class="meta">#</span> 修改 Hadoop 配置文件</span><br><span class="line"><span class="meta">#</span> 编辑 etc/core-site.xml 文件</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://node01:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/var/sxt/hadoop/full&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"><span class="meta">#</span> 编辑 etc/hdfs-site.xml 文件</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;2&lt;/value&gt;</span><br><span class="line">     &lt;/property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;node02:50090&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"><span class="meta">#</span> 编辑 etc/slaves 文件</span><br><span class="line">node02</span><br><span class="line">node03</span><br><span class="line">node04</span><br><span class="line"><span class="meta">#</span> ------------------------------------------------------------------</span><br><span class="line"><span class="meta">#</span> 在 node02、node03、node04 下创建文件夹</span><br><span class="line">mkdir /opt/sxt</span><br><span class="line"><span class="meta">#</span> 在 node01 节点的 /opt/sxt 目录下执行</span><br><span class="line">scp -r ./hadoop-2.6.5/ node02:`pwd`</span><br><span class="line">scp -r ./hadoop-2.6.5/ node03:`pwd`</span><br><span class="line">scp -r ./hadoop-2.6.5/ node04:`pwd`</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 在 node01 节点上执行  ---------------------------</span><br><span class="line">hdfs namenode -format</span><br><span class="line">start-dfd.sh</span><br></pre></td></tr></table></figure>

<p>在 node01 节点上执行 格式化</p>
<p><img src="http://img.zwer.xyz/blog/20190930163010.png" alt="启动 hdfsnamenode -format 截图"></p>
<p>在 node01 节点启动 hadoop </p>
<p><img src="http://img.zwer.xyz/blog/20190930163212.png" alt></p>
<h2 id="Hadoop-2-x"><a href="#Hadoop-2-x" class="headerlink" title="Hadoop 2.x"></a>Hadoop 2.x</h2><p><img src="http://img.zwer.xyz/blog/20191008194300.png" alt></p>
<ul>
<li>主备 NameNode<br>解决单点故障（属性，位置）<br>主NameNode对外提供服务，备NameNode同步主NameNode元数据，以待切换<br>所有DataNode同时向两个NameNode汇报数据块信息（位置）</li>
<li>JNN:集群（属性）</li>
<li>standby：备，完成了 edits.log 文件的合并产生新的image，推送回 ANN<br>两种切换选择<br>手动切换：通过命令实现主备之间的切换，可以用HDFS升级等场合<br>自动切换：基于Zookeeper实现<br>基于Zookeeper自动切换方案</li>
<li>ZooKeeper Failover Controller：监控NameNode健康状态，并向Zookeeper注册NameNode<br>NameNode挂掉后，ZKFC为NameNode竞争锁，获得ZKFC 锁的NameNode变为active</li>
</ul>
<h3 id="Hadoop-2-x-联邦"><a href="#Hadoop-2-x-联邦" class="headerlink" title="Hadoop 2.x 联邦"></a>Hadoop 2.x 联邦</h3><blockquote>
<p>联邦：不同应用间是相互隔离</p>
</blockquote>
<ol>
<li>通过多个namenode/namespace把元数据的存储和管理分散到多个节点中，使到namenode/namespace可以通过增加机器来进行水平扩展。</li>
<li>能把单个 namenode 的负载分散到多个节点中，在 HDFS 数据规模较大的时候不会也降低 HDFS 的性能。可以通过多个 namespace 来隔离不同类型的应用，把不同类型应用的HDFS元数据的存储和管理分派到不同的namenode中。</li>
</ol>
<p><img src="http://img.zwer.xyz/blog/20191008194818.png" alt></p>
<h2 id="HA-高可用"><a href="#HA-高可用" class="headerlink" title="HA 高可用"></a>HA 高可用</h2><h3 id="准备-2"><a href="#准备-2" class="headerlink" title="准备"></a>准备</h3><table>
<thead>
<tr>
<th></th>
<th>NN-1</th>
<th>NN-2</th>
<th>DN</th>
<th>ZK</th>
<th>ZKFC</th>
<th>JNN</th>
</tr>
</thead>
<tbody><tr>
<td>node01</td>
<td>*</td>
<td></td>
<td></td>
<td></td>
<td>*</td>
<td>*</td>
</tr>
<tr>
<td>node02</td>
<td></td>
<td>*</td>
<td>*</td>
<td>*</td>
<td>*</td>
<td>*</td>
</tr>
<tr>
<td>node03</td>
<td></td>
<td></td>
<td>*</td>
<td>*</td>
<td></td>
<td>*</td>
</tr>
<tr>
<td>node04</td>
<td></td>
<td></td>
<td>*</td>
<td>*</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h3 id="搭建-Zookeeper-集群"><a href="#搭建-Zookeeper-集群" class="headerlink" title="搭建 Zookeeper 集群"></a>搭建 Zookeeper 集群</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 解压 Zookeeper 压缩包，并移动到 /opt/sxt 目录下</span><br><span class="line"><span class="meta">#</span> 配置 Zookeeper 环境变量</span><br><span class="line"><span class="meta">#</span> 到 zookeeper 目录下，进入 conf 目录下</span><br><span class="line"><span class="meta">#</span> 复制 zoo_simple.cfg 到 zoo.cfg</span><br><span class="line"><span class="meta">#</span> 修改 zoo.cfg 配置文件</span><br><span class="line">dataDir=/var/sxt/hadoop/zk</span><br><span class="line">clientPort=2181</span><br><span class="line"><span class="meta">#</span> 配置 zk 集群，第一次启动按 serverid 区分 leader 和  fellower</span><br><span class="line">server.1=192.168.170.102:2888:3888</span><br><span class="line">server.2=192.168.170.103:2888:3888</span><br><span class="line">server.3=192.168.170.104:2888:3888</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>创建  /var/sxt/hadoop/zk 目录，将当前机器 zk 的 id 写入 myid 文件中</span><br><span class="line">mkdir /var/sxt/hadoop/zk -p</span><br><span class="line">echo "1"&gt;/var/sxt/hadoop/zk/myid</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> 分发 zookeeper 目录到其他机器上(node03、node04)</span><br><span class="line">scp -r ./zookeeper-3.4.6/ root@node03:`pwd`</span><br><span class="line">scp -r ./zookeeper-3.4.6/ root@node04:`pwd`</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 在 node03、node04 机器上</span><br><span class="line"><span class="meta">#</span> 1. 配置 zookeeper 的环境变量 </span><br><span class="line"><span class="meta">#</span> 2. 增加 myid 文件，将当前机器 zk 的 serverid 写入</span><br></pre></td></tr></table></figure>

<h3 id="HA-搭建"><a href="#HA-搭建" class="headerlink" title="HA 搭建"></a>HA 搭建</h3><blockquote>
<ol>
<li>逻辑到物理的映射</li>
<li>JNode 位置信息相关配置</li>
<li>出现故障的处理方式及 SSH 免密钥配置</li>
</ol>
</blockquote>
<h4 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node02:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>node02:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://node01:8485;node02:8485;node03:8485/mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/var/sxt/hadoop/ha/jn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">      org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</span><br><span class="line">    <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/root/.ssh/id_dsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h3><blockquote>
<p>注意：hadoop.tmp.dir的配置要变更：/var/sxt/hadoop-2.6/ha ###</p>
</blockquote>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>node02:2181,node03:2181,node04:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="HA-部署"><a href="#HA-部署" class="headerlink" title="HA 部署"></a>HA 部署</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 第一次部署</span><br><span class="line"><span class="meta">#</span> 1.启动 node01、node02、node03 的 journalnode</span><br><span class="line">hadoop-daemon.sh start journalnode</span><br><span class="line"><span class="meta">#</span> 2.格式化 node01 dfs</span><br><span class="line">hdfs namenode –format</span><br><span class="line"><span class="meta">#</span> 3.启动 node01 的 NN ，启动 node02 的 standyNN</span><br><span class="line">hadoop-daemon.sh start namenode   # 在 node01</span><br><span class="line">hdfs namenode -bootstrapStandby   # 在 node02</span><br><span class="line"><span class="meta">#</span> 4.格式化 zk </span><br><span class="line">hdfs zkfc -formatZK</span><br><span class="line"><span class="meta">#</span> 5.启动 hdfs</span><br><span class="line">start-dfs.sh </span><br><span class="line"><span class="meta">#</span>测试 </span><br><span class="line">kill -9 进程号    强制清除</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 第二次启动 </span><br><span class="line">1，启动zk</span><br><span class="line">2，start-dfs.sh</span><br></pre></td></tr></table></figure>

<h3 id="SSH-免密钥的应用场景"><a href="#SSH-免密钥的应用场景" class="headerlink" title="SSH 免密钥的应用场景"></a>SSH 免密钥的应用场景</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 管理脚本管理服务的开启与关闭</span><br><span class="line">2. 搭建 HA 时，ZKFC 需要控制自己及对方</span><br><span class="line"></span><br><span class="line">ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa  # 生成密钥</span><br><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys  # 对自己免密钥</span><br></pre></td></tr></table></figure>

<h2 id="Windows-下开发大数据"><a href="#Windows-下开发大数据" class="headerlink" title="Windows 下开发大数据"></a>Windows 下开发大数据</h2><h3 id="添加-Hadoop-环境变量和指定用户"><a href="#添加-Hadoop-环境变量和指定用户" class="headerlink" title="添加 Hadoop 环境变量和指定用户"></a>添加 Hadoop 环境变量和指定用户</h3><ul>
<li>新建系统环境变量 </li>
</ul>
<p><img src="http://img.zwer.xyz/blog/20191008211933.png" alt></p>
<ul>
<li>修改系统环境变量 path</li>
</ul>
<p><img src="http://img.zwer.xyz/blog/20191008212035.png" alt></p>
<h3 id="Eclipse-中自定义用户库"><a href="#Eclipse-中自定义用户库" class="headerlink" title="Eclipse 中自定义用户库"></a>Eclipse 中自定义用户库</h3><ol>
<li><p>打开 Eclipse 的首选项:点击菜单栏下 window &gt; Perferences </p>
</li>
<li><p>搜索 user ，即可找到 User Libraries 的位置并点击</p>
</li>
<li><p>点击 New 按钮，新建一个用户库，自定义库的名称</p>
</li>
<li><p>选择刚创建自定义用户库，点击 Add Exteral JARs …点击，选择需要添加 jar 包，最后确定即可</p>
</li>
</ol>
<p><img src="http://img.zwer.xyz/blog/20191008211524.png" alt></p>
<h3 id="HDFS-api"><a href="#HDFS-api" class="headerlink" title="HDFS-api"></a>HDFS-api</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span>  <span class="title">TestHDFS</span></span>&#123;</span><br><span class="line">	</span><br><span class="line">	Configuration conf = <span class="keyword">null</span>;</span><br><span class="line">	FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Before</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">before</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		conf = <span class="keyword">new</span> Configuration(<span class="keyword">true</span>);</span><br><span class="line">		fs = FileSystem.get(conf);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@After</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">after</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		fs.close(); <span class="comment">//关闭资源</span></span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 创建目录</span></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">mkdir</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		<span class="comment">// 给定一个目录，若该目录存在，则直接删除再创建</span></span><br><span class="line">		<span class="comment">// 若该目录不存在，直接创建</span></span><br><span class="line">		Path f = <span class="keyword">new</span> Path(<span class="string">"/hello"</span>);</span><br><span class="line">		<span class="keyword">if</span>(fs.exists(f))&#123;</span><br><span class="line">			fs.delete(f, <span class="keyword">true</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		fs.mkdirs(f);	</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 上传文件</span></span><br><span class="line">	<span class="meta">@Test</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">upload</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		</span><br><span class="line">		InputStream is = </span><br><span class="line">				<span class="keyword">new</span> BufferedInputStream(</span><br><span class="line">            <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(<span class="string">"D:\\hello.txt"</span>)));</span><br><span class="line"></span><br><span class="line">		Path p = <span class="keyword">new</span> Path(<span class="string">"/user/root/test-h.txt"</span>);</span><br><span class="line">		FSDataOutputStream out = fs.create(p);</span><br><span class="line">		</span><br><span class="line">		IOUtils.copyBytes(is, out, conf, <span class="keyword">true</span>);</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 下载文件</span></span><br><span class="line">	<span class="meta">@Test</span> </span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">download</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		Path path = <span class="keyword">new</span> Path(<span class="string">"/user/root/test.txt"</span>);</span><br><span class="line">		InputStream in = fs.open(path);</span><br><span class="line">		<span class="comment">// 输入流</span></span><br><span class="line">		FSDataInputStream fsin = <span class="keyword">new</span> FSDataInputStream(in);</span><br><span class="line">		<span class="comment">// 输出流</span></span><br><span class="line">		OutputStream ops = </span><br><span class="line">			<span class="keyword">new</span> BufferedOutputStream(</span><br><span class="line">            	<span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(<span class="string">"D:\\hadoop.txt"</span>)));</span><br><span class="line">		<span class="comment">// 流对接</span></span><br><span class="line">		IOUtils.copyBytes(fsin, ops, conf);</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 块</span></span><br><span class="line">	<span class="meta">@Test</span> </span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testBlockLocation</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		Path path = <span class="keyword">new</span> Path(<span class="string">"/user/root/test.txt"</span>);</span><br><span class="line">		FileStatus fStatus = fs.getFileStatus(path);</span><br><span class="line">		BlockLocation[] bkls = </span><br><span class="line">            fs.getFileBlockLocations(fStatus , <span class="number">0</span>, fStatus.getLen());</span><br><span class="line">		<span class="keyword">for</span> (BlockLocation bkl : bkls) &#123;</span><br><span class="line">			System.out.println(bkl);</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		FSDataInputStream in = fs.open(path);</span><br><span class="line">	</span><br><span class="line">		in.seek(<span class="number">1048576</span>);</span><br><span class="line">		System.out.println((<span class="keyword">char</span>)in.readByte());</span><br><span class="line">		System.out.println((<span class="keyword">char</span>)in.readByte());</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://zwer.xyz/2019/09/24/20190924  TCP、keepalived、Nginx/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zwer">
      <meta itemprop="description" content="记录学习的日常">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zwer 的博客空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/09/24/20190924  TCP、keepalived、Nginx/" class="post-title-link" itemprop="url">20190924 高并发</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-09-24 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-24T00:00:00+08:00">2019-09-24</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-09 21:30:52" itemprop="dateModified" datetime="2019-10-09T21:30:52+08:00">2019-10-09</time>
              </span>
            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h2><p>高并发 -&gt; 日志* -&gt; 分析行为 -&gt;画像 -&gt;推荐 -&gt; 服务*</p>
<h2 id="TCP-IP-网络模型"><a href="#TCP-IP-网络模型" class="headerlink" title="TCP/IP 网络模型"></a>TCP/IP 网络模型</h2><p>三次握手：确认客户端和服务端的收发正常（IO 正常），可以进行连接</p>
<ul>
<li><p>C -&gt; S : 发送 sync 包给服务端，表示客户端想与服务端建立连接</p>
</li>
<li><p>S -&gt; C：服务端接收到客户端的 sync 包，并将 sync +ack  包，发送给客户端</p>
<p>表示服务端接收到客户端的请求，并回复客户端可以与服务端建立连接</p>
</li>
<li><p>C -&gt; S: 客户端接收到服务端的 ack 包，将 ack 包发送给服务端，表示客户端马上与服务端建立连接，让服务端做好准备</p>
</li>
</ul>
<p>四次离手：TCP 是稳定的连接，对于连接断开需要经过 Client 与 Server 双方都确认后，才可关闭</p>
<ul>
<li>C - &gt;S: 发送 fin 包给服务端，表示客户端想与服务端断开连接</li>
<li>S -&gt; C: 发送 ack包给客户端，表示接收到服务端的断开请求</li>
<li>S -&gt; C: 发送 fin 包给客户端，表示服务端想与客户端断开连接</li>
<li></li>
<li>C -&gt; S: 发送 ack 包给服务端，服务端接收到后，表示与客户端断开连接。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">TCP/IP协议  OSI 7L参考模型</span><br><span class="line">GET / www.baidu.com/</span><br><span class="line">7:应用层www.baidu.com  IP:80  1212</span><br><span class="line">http，smtp，ssh</span><br><span class="line">4:传输层控制：【三次握手&gt;&gt;（传输数据）&gt;&gt;四次分手】</span><br><span class="line">tcp，udp</span><br><span class="line">SOCKET：IP:PORT-IP:PORT</span><br><span class="line">netstat -natp</span><br><span class="line">3:网络层： 192.168.9.11</span><br><span class="line">ip，icmp</span><br><span class="line">ROUTE：下一跳</span><br><span class="line">route -n</span><br><span class="line">2:链路层</span><br><span class="line">以太网：Ethernet：MAC</span><br><span class="line">ARP：全F，两点通信，交换机学习</span><br><span class="line">arp -a</span><br></pre></td></tr></table></figure>

<p><img src="http://img.zwer.xyz/blog/20190924154314.png" alt></p>
<p>注意： 三次握手和四次离手中间不可拆分，一定针对于两台特定  IP:Port - IP:Port</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">netstat antp</span><br><span class="line"></span><br><span class="line">route -n # -n 查看 IP 地址</span><br><span class="line"></span><br><span class="line">arp -a  </span><br><span class="line">0.0.0.0 默认网关</span><br></pre></td></tr></table></figure>

<h3 id="功能分层"><a href="#功能分层" class="headerlink" title="功能分层"></a>功能分层</h3><p>层与层依赖<br>1，能够申请到端口号<br>2，路由表有下一跳条目<br>3，ARP能请求到下一跳MAC<br>4，三次握手<br>5，传输数据<br>6，四次分手</p>
<p><img src="http://img.zwer.xyz/blog/20190924202409.png" alt></p>
<h3 id="下一跳"><a href="#下一跳" class="headerlink" title="下一跳"></a>下一跳</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">整个互联网建立在下一跳的模式下</span><br><span class="line">IP是逻辑上的两个端点</span><br><span class="line">MAC是物理上连接的两个节点</span><br><span class="line">端点间TCP传输过程中</span><br><span class="line">确认机制</span><br><span class="line">状态机制</span><br><span class="line">不可分割</span><br><span class="line">解析数据包需要成本</span><br><span class="line">交换机：二层，只关心MAC地址</span><br><span class="line">学习机制：</span><br><span class="line">路由器：三层，只关心IP和路由表</span><br><span class="line">LVS服务器：四层，只关心PORT，状态</span><br><span class="line">nginx：七层，关心socket对应关系</span><br><span class="line"></span><br><span class="line">## 负载均衡 ##</span><br></pre></td></tr></table></figure>

<h2 id="LVS"><a href="#LVS" class="headerlink" title="LVS"></a>LVS</h2><blockquote>
<p>LVS技术要达到的目标是：通过LVS提供的负载均衡技术和Linux操作系统实现一个高性能、高可用的服务器群集，它具有良好可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的服务性能。</p>
<p>LVS自从1998年开始，发展到现在已经是一个比较成熟的技术项目了。可以利用LVS技术实现高可伸缩的、高可用的网络服务，例如WWW服务、Cache服务、DNS服务、FTP服务、MAIL服务、视频/音频点播服务等等，有许多比较著名网站和组织都在使用LVS架设的集群系统，例如：Linux的门户网站（<a href="http://www.linux.com/" target="_blank" rel="noopener">www.linux.com</a>）、向RealPlayer提供音频视频服务而闻名的Real公司（<a href="http://www.real.com/" target="_blank" rel="noopener">www.real.com</a>）、全球最大的开源网站（sourceforge.net）等</p>
</blockquote>
<p><strong>LVS 参考</strong> <a href="https://superproxy.github.io/docs/lvs/index.html" target="_blank" rel="noopener">https://superproxy.github.io/docs/lvs/index.html</a></p>
<h3 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">昂贵，性能优越</span><br><span class="line">F5 BIG-IP </span><br><span class="line">Citrix NetScaler</span><br><span class="line">A10</span><br></pre></td></tr></table></figure>

<h3 id="软件"><a href="#软件" class="headerlink" title="软件"></a>软件</h3><blockquote>
<p>便宜，灵活度（开源）</p>
</blockquote>
<table>
<thead>
<tr>
<th></th>
<th>四层</th>
<th>七层</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>tcp 之上的第四层协议</td>
<td>LVS 只能操作IP,端口 ，在操作系统内核中。</td>
</tr>
<tr>
<td></td>
<td></td>
<td>nginx<br>haproxy<br>httpd  “apache”webserver</td>
</tr>
</tbody></table>
<h3 id="LVS-DR"><a href="#LVS-DR" class="headerlink" title="LVS -DR"></a>LVS -DR</h3><blockquote>
<p>Director 接收用户的请求，然后根据负载均衡算法选取一台 realserver，将包转发过去，最后由realserver直接回复给用户。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">DR：Director</span><br><span class="line">客户端发送对VIP的请求</span><br><span class="line">lvs负载到后端某一台server</span><br><span class="line">后端server处理后，直接封包回送客户端</span><br><span class="line">源IP地址一定是lvs上面陪的那个公网服务地址</span><br><span class="line">也就后端server要配置这个ip</span><br><span class="line">后端server收到的数据包是lvs没有变动过的（IP：vip）</span><br><span class="line">目标ip一定是自己持有的</span><br><span class="line">so：多个server，接入互联网的server持有相同的IP，是不对的</span><br><span class="line">必须将后端server中的vip隐藏起来（对外隐藏）</span><br><span class="line"></span><br><span class="line">VIP: 虚拟服务器地址</span><br><span class="line">DIP: 转发的网络地址</span><br><span class="line">1，和RIP通信：ARP协议，获取Real Server的RIP：MAC地址</span><br><span class="line">2，转发Client的数据包到RIP上（隐藏的VIP）</span><br><span class="line">RIP: 后端真实主机(后端服务器)</span><br><span class="line"></span><br><span class="line">CIP: 客户端IP地址</span><br></pre></td></tr></table></figure>

<p><img src="http://img.zwer.xyz/blog/20190927160750.png" alt></p>
<h3 id="LVS-配置实验"><a href="#LVS-配置实验" class="headerlink" title="LVS 配置实验"></a>LVS 配置实验</h3><h4 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h4><table>
<thead>
<tr>
<th>主机名</th>
<th>node01</th>
<th>node02</th>
<th>node03</th>
</tr>
</thead>
<tbody><tr>
<td>IP 类型</td>
<td>DIP</td>
<td>RIP</td>
<td>RIP</td>
</tr>
<tr>
<td>IP</td>
<td>192.168.170.101</td>
<td>192.168.170.102</td>
<td>192.168.170.103</td>
</tr>
</tbody></table>
<h4 id="实验图"><a href="#实验图" class="headerlink" title="实验图"></a>实验图</h4><p><img src="http://img.zwer.xyz/blog/20190928094014.png" alt></p>
<h4 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h4><ol>
<li><p>配置 LVS 服务器的虚拟IP 和开启 IPv4 转发</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 ~]# ifconfig eth0:0 192.168.170.100/24  # 临时生效</span><br><span class="line">echo “1” &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改 RP 服务器的文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">echo 1 &gt; /proc/sys/net/ipv4/conf/eth0/arp_ignore </span><br><span class="line">echo 2 &gt; /proc/sys/net/ipv4/conf/eth0/arp_announce </span><br><span class="line">echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore </span><br><span class="line">echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置 RP 服务器的本地环回地址</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig lo:0 192.168.170.100 netmask 255.255.255.255</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 RP 服务器上安装 httpd 服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y httpd</span><br></pre></td></tr></table></figure>
</li>
<li><p>设置 主页</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /var/www/html</span><br><span class="line">vi index.html</span><br><span class="line">内容： from 192.168.170.102</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动 httpd 服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service httpd start</span><br></pre></td></tr></table></figure>
</li>
<li><p>LVS 配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> yum install ipvsadm -y</span><br><span class="line">ipvsadm -A -t 192.168.170.100:80 -s rr </span><br><span class="line">ipvsadm -a -t 192.168.170.100:80 -r 192.168.170.102 -g</span><br><span class="line">ipvsadm -a -t 192.168.170.100:80 -r 192.168.170.103 -g</span><br><span class="line"></span><br><span class="line">ipvsadm -ln</span><br><span class="line">浏览器刷新: 访问vip</span><br><span class="line">ipvsadm –lnc</span><br><span class="line">netstat -natp</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="keepalived"><a href="#keepalived" class="headerlink" title="keepalived"></a>keepalived</h2><blockquote>
<p>集群管理中保证集群高可用的服务软件</p>
<p>用于做健康检查和主备切换，这里用在 LVS 服务器，使用 LVS 服务器达到高可用 HA(High Availability)</p>
<p>高可用 High Available</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、需要心跳机制探测后端RS是否提供服务。</span><br><span class="line">	a) 探测down，需要从lvs中删除该RS</span><br><span class="line">	b) 探测发送从down到up，需要从lvs中再次添加RS。</span><br><span class="line">2、Lvs DR，需要主备（HA）</span><br></pre></td></tr></table></figure>

<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="环境-1"><a href="#环境-1" class="headerlink" title="环境"></a>环境</h4><table>
<thead>
<tr>
<th>主机名</th>
<th>node01</th>
<th>node02</th>
<th>node03</th>
<th>node04</th>
</tr>
</thead>
<tbody><tr>
<td>类型</td>
<td>LVS(MASTER)</td>
<td>RIP1</td>
<td>RIP2</td>
<td>LVS(BACKUP)</td>
</tr>
<tr>
<td>IP</td>
<td>192.168.170.101</td>
<td>192.168.170.102</td>
<td>192.168.170.103</td>
<td>192.168.170.104</td>
</tr>
</tbody></table>
<h5 id="实验图-1"><a href="#实验图-1" class="headerlink" title="实验图"></a>实验图</h5><p><img src="http://img.zwer.xyz/blog/20190928100941.png" alt></p>
<h4 id="步骤-1"><a href="#步骤-1" class="headerlink" title="步骤"></a>步骤</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>  node01 上LVS 服务器上关闭之前的 ipvsadm 设置</span><br><span class="line">ipvsadm -C  #              Clear the virtual server table.</span><br><span class="line">ifconfig eth0:0 down  </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 在 node01、node04上安装 keepalived </span><br><span class="line">yum install -y keepalived </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 安装完成后， 进入 cd /etc/keepalived 目录下,备份 keepalived.conf 文件</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   notification_email &#123;</span><br><span class="line">     acassen@firewall.loc</span><br><span class="line">     failover@firewall.loc</span><br><span class="line">     sysadmin@firewall.loc</span><br><span class="line">   &#125;</span><br><span class="line">   notification_email_from Alexandre.Cassen@firewall.loc</span><br><span class="line">   smtp_server 192.168.200.1</span><br><span class="line">   smtp_connect_timeout 30</span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER   # 主节点</span><br><span class="line">    interface eth0  # 操作的网卡</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100  # 优先级</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;  # VIP  虚拟IP配置</span><br><span class="line">	192.168.170.100/24 dev eth0 label eth0:3 </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_server 192.168.170.100 80 &#123;</span><br><span class="line">    delay_loop 6</span><br><span class="line">    lb_algo rr</span><br><span class="line">    lb_kind DR   # 指定 LVS DR模式</span><br><span class="line">    nat_mask 255.255.255.0</span><br><span class="line">    persistence_timeout 0 # 同一个IP地址在50秒内lvs转发给同一个后端服务器</span><br><span class="line">    protocol TCP</span><br><span class="line"></span><br><span class="line">    real_server 192.168.170.102 80 &#123; #设置真实服务器的心跳机制 RID PORT</span><br><span class="line">        weight 1</span><br><span class="line">        HTTP_GET &#123;  #心跳检测的方式</span><br><span class="line">            url &#123;</span><br><span class="line">              path /   # 心跳检查的地址</span><br><span class="line">	    	  status_code 200      #心跳检查返回的状态</span><br><span class="line">            &#125;</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    real_server 192.168.170.103 80 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        HTTP_GET &#123;</span><br><span class="line">            url &#123;</span><br><span class="line">              path /</span><br><span class="line">	      status_code 200</span><br><span class="line">            &#125;</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> 配置完成 keepalived.conf ，将文件拷贝到 node04 上，并修改</span><br><span class="line">scp ./keepalived.conf root@192.168.170.104:/`pwd`</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> keepalived.conf 修改 node04 部分内容</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP   # 从节点</span><br><span class="line">    interface eth0  # 操作的网卡</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 50  # 优先级，从节点的优先级应低于主节点的优先级</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;  # VIP  虚拟IP配置</span><br><span class="line">	192.168.170.100/24 dev eth0 label eth0:3 </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> -------------------------------------------------------------------</span><br><span class="line"><span class="meta">#</span> 在 node01、node04 上启动 keepalived 服务</span><br><span class="line">service keepalived start</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 在 ifconfig 命令查看</span><br><span class="line">ifocnifg</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 查看路由</span><br><span class="line">ipvsadm -ln</span><br></pre></td></tr></table></figure>

<h2 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h2><blockquote>
<p>Nginx (“engine x”) 是一个高性能的 HTTP 和 反向代理 服务器，也是一个 IMAP/POP3/SMTP 代理服务器。</p>
</blockquote>
<h3 id="Apache-与-Nginx-的比较"><a href="#Apache-与-Nginx-的比较" class="headerlink" title="Apache 与 Nginx 的比较"></a>Apache 与 Nginx 的比较</h3><table>
<thead>
<tr>
<th></th>
<th>Apache</th>
<th>Nginx</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>一个客户端连接开辟一个进程处理</td>
<td>仅有一个进程</td>
</tr>
<tr>
<td></td>
<td>同步阻塞</td>
<td>异步非阻塞</td>
</tr>
</tbody></table>
<h3 id="nginx-conf"><a href="#nginx-conf" class="headerlink" title="nginx.conf"></a>nginx.conf</h3><h4 id="events"><a href="#events" class="headerlink" title="events"></a>events</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">#工作模式与连接数上限</span><br><span class="line">events</span><br><span class="line">&#123;</span><br><span class="line">    #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ];</span><br><span class="line">    epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。</span><br><span class="line">    use epoll;</span><br><span class="line">    #单个进程最大连接数（最大连接数=连接数*进程数）</span><br><span class="line">    worker_connections 65535;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">event下的一些配置及其意义</span><br><span class="line">#单个后台worker process进程的最大并发链接数    </span><br><span class="line">worker_connections  1024;</span><br><span class="line"># 并发总数是 worker_processes 和 worker_connections 的乘积</span><br><span class="line"># 即 max_clients = worker_processes * worker_connections</span><br><span class="line"># 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4  为什么</span><br><span class="line"># 为什么上面反向代理要除以4，应该说是一个经验值</span><br><span class="line"># 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000</span><br><span class="line"># worker_connections 值的设置跟物理内存大小有关</span><br><span class="line"># 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数</span><br><span class="line">    </span><br><span class="line">event下的一些配置及其意义</span><br><span class="line"># 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右</span><br><span class="line"># 我们来看看360M内存的VPS可以打开的文件句柄数是多少：</span><br><span class="line"># $ cat /proc/sys/fs/file-max</span><br><span class="line"># 输出 34336</span><br><span class="line"># 32000 &lt; 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内</span><br><span class="line"># 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置</span><br><span class="line"># 使得并发总数小于操作系统可以打开的最大文件数目</span><br><span class="line"># 其实质也就是根据主机的物理CPU和内存进行配置</span><br><span class="line"># 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。</span><br><span class="line"># ulimit -SHn 65535</span><br><span class="line"></span><br><span class="line">#定义Nginx运行的用户和用户组</span><br><span class="line">user www www;</span><br><span class="line"></span><br><span class="line">#nginx进程数，建议设置为等于CPU总核心数。</span><br><span class="line">worker_processes 8;</span><br><span class="line"></span><br><span class="line">#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]</span><br><span class="line">error_log /var/log/nginx/error.log info;</span><br><span class="line"></span><br><span class="line">#进程文件</span><br><span class="line">pid /var/run/nginx.pid;</span><br><span class="line"></span><br><span class="line">#一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。</span><br><span class="line">worker_rlimit_nofile 65535;</span><br></pre></td></tr></table></figure>

<h4 id="httpd"><a href="#httpd" class="headerlink" title="httpd"></a>httpd</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#设定http服务器</span><br><span class="line">http</span><br><span class="line">&#123;</span><br><span class="line">include mime.types; #文件扩展名与文件类型映射表</span><br><span class="line">default_type application/octet-stream; #默认文件类型</span><br><span class="line">#charset utf-8; #默认编码</span><br><span class="line">server_names_hash_bucket_size 128; #服务器名字的hash表大小</span><br><span class="line">client_header_buffer_size 32k; #上传文件大小限制</span><br><span class="line">large_client_header_buffers 4 64k; #设定请求缓</span><br><span class="line">client_max_body_size 8m; #设定请求缓</span><br><span class="line">sendfile on; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。</span><br><span class="line">autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。</span><br><span class="line">tcp_nopush on; #防止网络阻塞</span><br><span class="line">tcp_nodelay on; #防止网络阻塞</span><br><span class="line">keepalive_timeout 120; #长连接超时时间，单位是秒</span><br></pre></td></tr></table></figure>

<h4 id="gzip"><a href="#gzip" class="headerlink" title="gzip"></a>gzip</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">gzip的一些配置及其意义</span><br><span class="line">#gzip模块设置gzip on;</span><br><span class="line">#开启gzip压缩输出 gzip_min_length 1k; </span><br><span class="line">#最小压缩文件大小 gzip_buffers 4 16k;</span><br><span class="line">#压缩缓冲区 gzip_http_version 1.0; </span><br><span class="line">#压缩版本（默认1.1，前端如果是squid2.5请使用1.0）</span><br><span class="line">gzip_comp_level 2; </span><br><span class="line">#压缩等级</span><br><span class="line">gzip_types text/plain application/x-javascript text/css application/xml;</span><br><span class="line">#压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，</span><br><span class="line">但是会有一个warn。</span><br><span class="line">gzip_vary on;</span><br><span class="line">#limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用</span><br></pre></td></tr></table></figure>

<h4 id="虚拟主机"><a href="#虚拟主机" class="headerlink" title="虚拟主机"></a>虚拟主机</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">虚拟主机一些配置及其意义</span><br><span class="line">#虚拟主机的配置</span><br><span class="line">server&#123;</span><br><span class="line">    #监听端口 listen 80;</span><br><span class="line">    #域名可以有多个，用空格隔开</span><br><span class="line">    server_name www.ha97.com ha97.com;</span><br><span class="line">    index index.html index.htm index.jsp;</span><br><span class="line">    root /data/www/ha97;</span><br><span class="line">    location ~ .*\.(php|php5)?$&#123;</span><br><span class="line">        fastcgi_pass 127.0.0.1:9000;</span><br><span class="line">        fastcgi_index index.jsp;</span><br><span class="line">        include fastcgi.conf;</span><br><span class="line">&#125;</span><br><span class="line">通过nginx可以实现虚拟主机的配置，nginx支持三种类型的虚拟主机配置，</span><br><span class="line">1、基于ip的虚拟主机， （一块主机绑定多个ip地址）</span><br><span class="line">2、基于域名的虚拟主机（servername）</span><br><span class="line">3、基于端口的虚拟主机（listen如果不写ip端口模式）</span><br><span class="line">示例基于虚拟机ip的配置，这里需要配置多个ip</span><br><span class="line">server</span><br><span class="line">&#123;</span><br><span class="line">    listen 192.168.20.20:80;</span><br><span class="line">    server_name www.linuxidc.com;</span><br><span class="line">    root /data/www;</span><br><span class="line">&#125;</span><br><span class="line">server</span><br><span class="line">&#123;</span><br><span class="line">    listen 192.168.20.21:80;</span><br><span class="line">    server_name www.linuxidc.com;</span><br><span class="line">    root /data/www;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="location"><a href="#location" class="headerlink" title="location"></a>location</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">location 映射（ngx_http_core_module）</span><br><span class="line">location [ = | ~ | ~* | ^~ ] uri &#123; ... &#125;</span><br><span class="line">location URI &#123;&#125;:</span><br><span class="line">对当前路径及子路径下的所有对象都生效；</span><br><span class="line">location = URI &#123;&#125;: 注意URL最好为具体路径。</span><br><span class="line">精确匹配指定的路径，不包括子路径，因此，只对当前资源生效；</span><br><span class="line">location ~ URI &#123;&#125;:</span><br><span class="line">location ~* URI &#123;&#125;:</span><br><span class="line">模式匹配URI，此处的URI可使用正则表达式，~区分字符大小写，~*不区分字符大小写；</span><br><span class="line">location ^~ URI &#123;&#125;:</span><br><span class="line">不使用正则表达式</span><br><span class="line">优先级：= &gt; ^~ &gt; ~|~* &gt;  /|/dir/</span><br><span class="line"></span><br><span class="line">/loghaha.html</span><br><span class="line">/logheihei.html</span><br><span class="line">^/log.*html$</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span># location 配置规则</span><br><span class="line">=前缀的指令严格匹配这个查询。如果找到，停止搜索。</span><br><span class="line">所有剩下的常规字符串，最长的匹配。如果这个匹配使用^〜前缀，搜索停止。</span><br><span class="line">正则表达式，在配置文件中定义的顺序。</span><br><span class="line">如果第3条规则产生匹配的话，结果被使用。否则，如同从第2条规则被使用</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span># location配置规则</span><br><span class="line">location 的执行逻辑跟 location 的编辑顺序无关。</span><br><span class="line">矫正：这句话不全对，“普通 location ”的匹配规则是“最大前缀”，</span><br><span class="line">因此“普通 location ”的确与 location 编辑顺序无关；</span><br><span class="line"></span><br><span class="line">但是“正则 location ”的匹配规则是“顺序匹配，且只要匹配到第一个就停止后面的匹配”；</span><br><span class="line">“普通location ”与“正则 location ”之间的匹配顺序是？</span><br><span class="line">先匹配普通 location ，再“考虑”匹配正则 location 。</span><br><span class="line">注意这里的“考虑”是“可能”的意思，也就是说匹配完“普通 location ”后，有的时候需要继续匹配“正则 location ”，有的时候则不需要继续匹配“正则 location ”。两种情况下，不需要继续匹配正则 location ：</span><br><span class="line">（ 1 ）当普通 location 前面指定了“ ^~ ”，特别告诉 Nginx 本条普通 location 一旦匹配上，则不需要继续正则匹配；</span><br><span class="line">（ 2 ）当普通location 恰好严格匹配上，不是最大前缀匹配，则不再继续匹配正则</span><br><span class="line"></span><br><span class="line">loghaha.html</span><br><span class="line">l:  logha</span><br><span class="line">l:  ^~ loghah</span><br><span class="line">l:  loghaha.html</span><br><span class="line">l:  =loghaha.html</span><br><span class="line">l:   ^logh.*html$</span><br><span class="line">l:   ^logha.*html$</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 总结</span><br><span class="line">nginx  收到请求头：判定ip，port，hosts决定server</span><br><span class="line">nginx location匹配：用客户端的uri匹配location的uri</span><br><span class="line">先普通</span><br><span class="line">顺序无关</span><br><span class="line">最大前缀</span><br><span class="line">匹配规则简单</span><br><span class="line">打断：</span><br><span class="line">^~</span><br><span class="line">完全匹配</span><br><span class="line">再正则</span><br><span class="line">不完全匹配</span><br><span class="line">正则特殊性：一条URI可以和多条location匹配上</span><br><span class="line">有顺序的</span><br><span class="line">先匹配，先应用，即时退出匹配</span><br></pre></td></tr></table></figure>

<h4 id="请求头"><a href="#请求头" class="headerlink" title="请求头"></a>请求头</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">请求头</span><br><span class="line">host：决策server负责处理</span><br><span class="line">uri：决策location</span><br><span class="line">反向代理：proxy_pass  ip:port[uri];</span><br></pre></td></tr></table></figure>

<h4 id="IP-访问控制"><a href="#IP-访问控制" class="headerlink" title="IP 访问控制"></a>IP 访问控制</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">IP访问控制</span><br><span class="line">location  &#123;</span><br><span class="line">	   deny  IP /IP段</span><br><span class="line">	   deny  192.168.1.109;</span><br><span class="line">	   allow 192.168.1.0/24;192.168.0.0/16;192.0.0.0/8</span><br><span class="line">	&#125;</span><br><span class="line">规则：按照顺序依次检测，直到匹配到第一条规则</span><br></pre></td></tr></table></figure>

<h3 id="Nginx-的-session-一致性问题"><a href="#Nginx-的-session-一致性问题" class="headerlink" title="Nginx 的 session 一致性问题"></a>Nginx 的 session 一致性问题</h3><p>​        http协议是无状态的，即你连续访问某个网页100次和访问1次对服务器来说是没有区别对待的，因为它记不住你。那么，在一些场合，确实需要服务器记住当前用户怎么办？比如用户登录邮箱后，接下来要收邮件、写邮件，总不能每次操作都让用户输入用户名和密码吧，为了解决这个问题，session的方案就被提了出来，事实上它并不是什么新技术，而且也不能脱离http协议以及任何现有的web技术</p>
<p>​        session的常见实现形式是会话cookie（session cookie），即未设置过期时间的cookie，这个cookie的默认生命周期为浏览器会话期间，只要关闭浏览器窗口，cookie就消失了。实现机制是当用户发起一个请求的时候，服务器会检查该请求中是否包含sessionid，如果未包含，则系统会创造一个名为JSESSIONID的输出 cookie返回给浏览器(只放入内存，并不存在硬盘中)，并将其以HashTable的形式写到服务器的内存里面；当已经包含sessionid是，服务端会检查找到与该session相匹配的信息，如果存在则直接使用该sessionid，若不存在则重新生成新的 session。这里需要注意的是session始终是有服务端创建的，并非浏览器自己生成的。　但是浏览器的cookie被禁止后session就需要用get方法的URL重写的机制或使用POST方法提交隐藏表单的形式来实现</p>
<h4 id="Session共享"><a href="#Session共享" class="headerlink" title="Session共享"></a>Session共享</h4><p>​        首先我们应该明白，为什么要实现共享，如果你的网站是存放在一个机器上，那么是不存在这个问题的，因为会话数据就在这台机器，但是如果你使用了负载均衡把请求分发到不同的机器呢？这个时候会话id在客户端是没有问题的，但是如果用户的两次请求到了两台不同的机器，而它的session数据可能存在其中一台机器，这个时候就会出现取不到session数据的情况，于是session的共享就成了一个问题</p>
<h4 id="Session一致性解决方案"><a href="#Session一致性解决方案" class="headerlink" title="Session一致性解决方案"></a>Session一致性解决方案</h4><p>​    1、session复制<br>​        tomcat 本身带有复制session的功能。（不讲）<br>​    2、共享session<br>​        需要专门管理session的软件，<br>​        memcached 缓存服务，可以和tomcat整合，帮助tomcat共享管理session。</p>
<ul>
<li><strong>安装 memecache 缓存服务</strong></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">安装memcached</span><br><span class="line">1、安装libevent</span><br><span class="line">2、安装memcached</span><br><span class="line">3、启动memcached</span><br><span class="line">	memcached -d -m 128m -p 11211 -l 192.168.170.101 -u root -P /tmp/</span><br><span class="line">	-d:后台启动服务</span><br><span class="line">	-m:缓存大小</span><br><span class="line">	-p：端口</span><br><span class="line">	-l:IP</span><br><span class="line">	-P:服务器启动后的系统进程ID，存储的文件</span><br><span class="line">	-u:服务器启动是以哪个用户名作为管理用户</span><br><span class="line">如果源配置了也可以用</span><br><span class="line">	yum –y install memcached</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>tomcat 配置 session共享</strong></li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">配置session共享如下：</span><br><span class="line">3、拷贝jar到tomcat的lib下，jar包见附件</span><br><span class="line">4、配置tomcat，每个tomcat里面的context.xml中加入</span><br><span class="line"><span class="tag">&lt;<span class="name">Manager</span> <span class="attr">className</span>=<span class="string">"de.javakaffee.web.msm.MemcachedBackupSessionManager"</span> </span></span><br><span class="line"><span class="tag">	<span class="attr">memcachedNodes</span>=<span class="string">"n1:192.168.170.101:11211"</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">sticky</span>=<span class="string">"false"</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">lockingMode</span>=<span class="string">"auto"</span></span></span><br><span class="line"><span class="tag">    <span class="attr">sessionBackupAsync</span>=<span class="string">"false"</span></span></span><br><span class="line"><span class="tag">	<span class="attr">requestUriIgnorePattern</span>=<span class="string">".*\.(ico|png|gif|jpg|css|js)$"</span></span></span><br><span class="line"><span class="tag">    <span class="attr">sessionBackupTimeout</span>=<span class="string">"1000"</span> <span class="attr">transcoderFactoryClass</span>=<span class="string">"de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory"</span> </span></span><br><span class="line"><span class="tag">/&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>注意： tomcat 集群一定要保持时间一致性</strong></p>
<p><img src="http://img.zwer.xyz/blog/20190928155702.png" alt></p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://zwer.xyz/2019/09/21/20190921 Linux 基础/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zwer">
      <meta itemprop="description" content="记录学习的日常">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zwer 的博客空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/09/21/20190921 Linux 基础/" class="post-title-link" itemprop="url">20190921 Linux 基础</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-09-21 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-21T00:00:00+08:00">2019-09-21</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-08 11:30:44" itemprop="dateModified" datetime="2019-10-08T11:30:44+08:00">2019-10-08</time>
              </span>
            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Linux-基础"><a href="#Linux-基础" class="headerlink" title="Linux  基础"></a>Linux  基础</h1><h2 id="Linux-开始"><a href="#Linux-开始" class="headerlink" title="Linux 开始"></a>Linux 开始</h2><h3 id="虚拟机-Linux-准备工作"><a href="#虚拟机-Linux-准备工作" class="headerlink" title="虚拟机 Linux 准备工作"></a>虚拟机 Linux 准备工作</h3><h4 id="Linux-安装步骤"><a href="#Linux-安装步骤" class="headerlink" title="Linux 安装步骤"></a>Linux 安装步骤</h4><ul>
<li>选择稍后安装</li>
</ul>
<p><img src="http://img.zwer.xyz/blog/20190921110238.png" alt></p>
<ul>
<li>网络类型选择 NAT</li>
</ul>
<p><img src="http://img.zwer.xyz/blog/20190921110512.png" alt></p>
<ul>
<li>修改最大磁盘大小（这里最大磁盘大小指给虚拟机分配的，但不真正使用不是这么多）</li>
</ul>
<p><img src="http://img.zwer.xyz/blog/20190921110550.png" alt></p>
<p>注意： Linux 版本根据自己的Linux 版本选择。列如：我这用的是 CentOS-6.5-x86_64-minimal.iso，</p>
<p>所以选择 Linux 版本时选择时 Centos 64位</p>
<ul>
<li>添加 ISO 镜像文件，之后开启虚拟机即可<ol>
<li>选择编辑虚拟机设置</li>
</ol>
</li>
</ul>
<p><img src="http://img.zwer.xyz/blog/20190921110728.png" alt></p>
<p>​    2. 挂载 iso 镜像文件</p>
<p><img src="http://img.zwer.xyz/blog/20190921110819.png" alt></p>
<ul>
<li><p>虚拟机安装配置（若特殊说明，则选择默认即可）</p>
<ul>
<li><p>跳过磁盘检查，否则磁盘检查时间会很长</p>
<p><img src="http://img.zwer.xyz/blog/20190921111022.png" alt></p>
<ul>
<li><p>语言、键盘都选择英文即可。</p>
</li>
<li><p>选择第一个</p>
<p><img src="http://img.zwer.xyz/blog/20190921111435.png" alt></p>
</li>
<li><p>选择 yes，discard any data</p>
<p><img src="http://img.zwer.xyz/blog/20190921111512.png" alt></p>
</li>
<li><p>自定义 Linux 虚拟机名称</p>
<p><img src="http://img.zwer.xyz/blog/20190921111635.png" alt></p>
</li>
<li><p>选择时区</p>
<p><img src="http://img.zwer.xyz/blog/20190921111735.png" alt></p>
</li>
<li><p>密码设置要简单、透明（大家都知道的，不属于个人重要密码）</p>
<p><img src="http://img.zwer.xyz/blog/20190921111806.png" alt></p>
</li>
<li><p><strong>自定义磁盘分区</strong></p>
<p><img src="http://img.zwer.xyz/blog/20190921111959.png" alt></p>
</li>
</ul>
</li>
<li><p><img src="http://img.zwer.xyz/blog/20190921112133.png" alt></p>
</li>
<li><p><img src="http://img.zwer.xyz/blog/20190921112737.png" alt></p>
</li>
<li><p><img src="http://img.zwer.xyz/blog/20190921112755.png" alt></p>
</li>
<li><p><img src="http://img.zwer.xyz/blog/20190921112814.png" alt></p>
</li>
</ul>
</li>
</ul>
<p>注意事项：</p>
<ol>
<li>VM 安装选择自定义安装，便于之后的自定义硬件配置（如：磁盘大小等）</li>
<li>语言、键盘都选择英文</li>
<li>时区选择亚洲/上海</li>
<li>密码设置要简单透明</li>
<li>磁盘需要手动分区  boot（200MB） swap(2G) /(剩余所有)</li>
</ol>
<h4 id="Linux-静态-IP-设置"><a href="#Linux-静态-IP-设置" class="headerlink" title="Linux 静态 IP 设置"></a>Linux 静态 IP 设置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 设置静态 IP </span><br><span class="line"><span class="meta">#</span> 编辑   vi   /etc/sysconfig/network-scripts/ifcfg-eth0 </span><br><span class="line">[root@node01 network-scripts]# cd /etc/sysconfig/network-scripts/</span><br><span class="line">[root@node01 network-scripts]# vi ifcfg-eth0 </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> ifcfg-eth0 网卡配置，使用打开后编辑，</span><br><span class="line"><span class="meta">#</span> ONBOOT=on 开机自启 </span><br><span class="line"><span class="meta">#</span> BOOTPROTO=static 表示 IP 使用静态IP</span><br><span class="line">DEVICE=eth0</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">ONBOOT=yes</span><br><span class="line">NM_CONTROLLED=yes</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">IPADDR=192.168.170.101</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">GATEWAY=192.168.170.2</span><br><span class="line">DNS1=144.144.144.144</span><br><span class="line">DNS2=8.8.8.8</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 删除 rm -f 70-persistent-net.rules </span><br><span class="line"><span class="meta">#</span> 70-persistent-net.rules  该文件的作用是将 IP 地址与 MAC 地址绑定</span><br><span class="line">[root@node01 etc]# cd /etc/udev/rules.d/</span><br><span class="line">[root@node01 rules.d]# ll</span><br><span class="line">total 16</span><br><span class="line">-rw-r--r--. 1 root root 316 Nov 22  2013 60-raw.rules</span><br><span class="line">-rw-r--r--. 1 root root 789 Sep 21 19:33 70-persistent-cd.rules</span><br><span class="line">-rw-r--r--. 1 root root 420 Sep 21 19:28 70-persistent-net.rules</span><br><span class="line">-rw-r--r--. 1 root root  54 Dec  8  2011 99-fuse.rules</span><br><span class="line">[root@node01 rules.d]# rm -f 70-persistent-net.rules </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 关机 </span><br><span class="line">poweroff </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 修改主机名</span><br><span class="line">[root@node01 ~]# vi /etc/sysconfig/network</span><br><span class="line"><span class="meta">#</span> 编辑 network 文件</span><br><span class="line">NETWORKING=yes</span><br><span class="line">HOSTNAME=node01</span><br></pre></td></tr></table></figure>

<h5 id="Linux-网络配置文件位置"><a href="#Linux-网络配置文件位置" class="headerlink" title="Linux 网络配置文件位置"></a>Linux 网络配置文件位置</h5><table>
<thead>
<tr>
<th>文件位置</th>
<th>文件作用说明</th>
</tr>
</thead>
<tbody><tr>
<td>/etc/sysconfig/network-scripts/ifcfg-eth0</td>
<td>配置静态 IP 地址</td>
</tr>
<tr>
<td>/etc/udev/rules.d/70-persistent-net.rules</td>
<td>将 IP 地址与 MAC 地址绑定</td>
</tr>
<tr>
<td>/etc/sysconfig/network</td>
<td>配置主机名</td>
</tr>
</tbody></table>
<h4 id="使用-VM-软件-记录快照"><a href="#使用-VM-软件-记录快照" class="headerlink" title="使用 VM 软件 记录快照"></a>使用 VM 软件 记录快照</h4><p><img src="http://img.zwer.xyz/blog/20190921140910.png" alt></p>
<h4 id="Linux-关机和重启命令"><a href="#Linux-关机和重启命令" class="headerlink" title="Linux 关机和重启命令"></a>Linux 关机和重启命令</h4><table>
<thead>
<tr>
<th>关机</th>
<th>重启</th>
</tr>
</thead>
<tbody><tr>
<td>poweroff</td>
<td>reboot</td>
</tr>
<tr>
<td>init 0</td>
<td>init 6</td>
</tr>
</tbody></table>
<h3 id="Linux-常用命令"><a href="#Linux-常用命令" class="headerlink" title="Linux 常用命令"></a>Linux 常用命令</h3><table>
<thead>
<tr>
<th>命令</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>ls</td>
<td>显示目录内容  ll –i</td>
</tr>
<tr>
<td>pwd</td>
<td>显示当前目录的绝对路径</td>
</tr>
<tr>
<td>cd</td>
<td>切换目录</td>
</tr>
<tr>
<td>mkdir</td>
<td>文件夹 -p    {}</td>
</tr>
<tr>
<td>cp</td>
<td>复制  -r</td>
</tr>
<tr>
<td>mv</td>
<td>移动</td>
</tr>
<tr>
<td>touch</td>
<td>创建文件夹、文件</td>
</tr>
<tr>
<td>type 命令名</td>
<td>查看指定命令的文件的存放位置 外部命令 &amp; 内部命令</td>
</tr>
<tr>
<td>cat</td>
<td>查看文件内容</td>
</tr>
<tr>
<td>file</td>
<td>查看文件详细信息 (ELF 表示二进制文件)</td>
</tr>
<tr>
<td>echo</td>
<td>回声，打印标椎输出 <br><code>echo $PATH 查看环境变量路径</code><br><code>echo $$  当前shell的PID</code></td>
</tr>
<tr>
<td>help</td>
<td>查看内部命令</td>
</tr>
<tr>
<td>man</td>
<td>查看外部命令命令</td>
</tr>
<tr>
<td>whereis</td>
<td>定位命令位置</td>
</tr>
<tr>
<td>hash</td>
<td>查看 hash 表</td>
</tr>
<tr>
<td>ps -ef</td>
<td>查看当前进程信息</td>
</tr>
<tr>
<td>df -h</td>
<td>显示文件系统使用情况[甩锅]</td>
</tr>
<tr>
<td>du -h</td>
<td>查看某种文件使用状况[甩锅]</td>
</tr>
<tr>
<td>mount/unmout</td>
<td>挂载/卸载磁盘文件</td>
</tr>
<tr>
<td>#### ls 命令 ####</td>
<td></td>
</tr>
</tbody></table>
<p>文件类型：<br>    -：普通文件 (f)<br>    d: 目录文件</p>
<p>​    b: 块设备文件 (block)<br>​    c: 字符设备文件 (character)</p>
<p>​    l: 符号链接文件(symbolic link file)</p>
<p>​    p: 命令管道文件(pipe)<br>​    s: 套接字文件(socket)<br>文件权限：9位，每3位一组，3组 权限（U,G,O）每一组：rwx(读，写，执行), r–<br>文件硬链接的次数<br>文件的属主(owner)<br>文件的属组(group)<br>文件大小(size)，单位是字节<br>时间戳(timestamp)：最近一次被修改的时间<br>​    访问:access<br>​    修改:modify，文件内容发生了改变<br>​    改变:change，metadata，元数据</p>
<p><strong>使用  ls 同时展示多个目录</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 god]# ls ~  /usr/local</span><br><span class="line">/root:</span><br><span class="line">anaconda-ks.cfg  install.log  install.log.syslog</span><br><span class="line"></span><br><span class="line">/usr/local:</span><br><span class="line">bin  etc  games  include  lib  lib64  libexec  sbin  share  src</span><br></pre></td></tr></table></figure>

<p><strong>使用 mkdir 命令同时创建多个文件夹</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 c]# mkdir Hello/&#123;a,b,c&#125;A -p</span><br><span class="line">[root@node01 c]# ll</span><br><span class="line">total 4</span><br><span class="line">drwxr-xr-x. 5 root root 4096 Sep 22 00:45 Hello</span><br><span class="line">[root@node01 c]# cd Hello</span><br><span class="line">[root@node01 Hello]# ll</span><br><span class="line">total 12</span><br><span class="line">drwxr-xr-x. 2 root root 4096 Sep 22 00:45 aA</span><br><span class="line">drwxr-xr-x. 2 root root 4096 Sep 22 00:45 bA</span><br><span class="line">drwxr-xr-x. 2 root root 4096 Sep 22 00:45 cA</span><br></pre></td></tr></table></figure>

<p><strong>查看文件系统和文件使用情况</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 /]# du -h /etc/udev</span><br><span class="line">4.0K	/etc/udev/makedev.d</span><br><span class="line">20K	/etc/udev/rules.d</span><br><span class="line">32K	/etc/udev</span><br><span class="line">[root@node01 /]# df -h </span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda3        97G  842M   91G   1% /</span><br><span class="line">tmpfs           491M     0  491M   0% /dev/shm</span><br><span class="line">/dev/sda1       194M   28M  157M  15% /boot</span><br><span class="line">/dev/sr0        398M  398M     0 100% /mnt</span><br></pre></td></tr></table></figure>

<p><strong>使用硬链接和软链接</strong></p>
<ul>
<li>硬链接类似于拷贝，即使原文件被删除了，硬链接生成文件仍可使用</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln --l  原文件名 硬链接文件名</span><br></pre></td></tr></table></figure>

<ul>
<li>软链接，原文件删除了，软链接生成文件不可使用</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s 原文件名 软链接文件名</span><br></pre></td></tr></table></figure>

<p>  <strong>安装 man 命令</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install man man-pages</span><br></pre></td></tr></table></figure>

<h4 id="Linux命令执行流程"><a href="#Linux命令执行流程" class="headerlink" title="Linux命令执行流程"></a>Linux命令执行流程</h4><p>​        用户通过客户端命令行输入命令以及命令参数， bash 解释器会根据空白符切割，得到的第一个元素，作为命令 command。通过判断该 command 命令是外部命令还是内部命令，若内部命令，则由 bash 执行器直接执行。若是外部命令，则 根据 $PATH 中给定的目录中从左向右寻找该命令文件的可执行程序文件，然后由 bash 执行器执行。</p>
<p><img src="http://img.zwer.xyz/blog/20190921145435.png" alt></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 ~]# type ls</span><br><span class="line">ls is aliased to `ls --color=auto'</span><br><span class="line">[root@node01 ~]# type -a ls</span><br><span class="line">ls is aliased to `ls --color=auto'</span><br><span class="line">ls is /bin/ls</span><br><span class="line">[root@node01 ~]# type ifconfig</span><br><span class="line">ifconfig is /sbin/ifconfig</span><br><span class="line">[root@node01 ~]# file /sbin/ifconfig</span><br><span class="line">/sbin/ifconfig: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.18, stripped</span><br><span class="line">[root@node01 ~]# echo $PATH</span><br><span class="line">/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin</span><br><span class="line">[root@node01 ~]# type yum</span><br><span class="line">yum is hashed (/usr/bin/yum)</span><br><span class="line">[root@node01 ~]# file /usr/bin/yum</span><br><span class="line">/usr/bin/yum: a /usr/bin/python script text executable</span><br></pre></td></tr></table></figure>

<p>小技巧：使用 xshell 登录 Linux  ssh root:<a href="mailto:123456@192.168.170.101" target="_blank" rel="noopener">123456@192.168.170.101</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh 用户名:密码@IP地址</span><br></pre></td></tr></table></figure>

<h3 id="Linux-文件系统"><a href="#Linux-文件系统" class="headerlink" title="Linux 文件系统"></a>Linux 文件系统</h3><h4 id="boot-目录的挂载与卸载"><a href="#boot-目录的挂载与卸载" class="headerlink" title="boot 目录的挂载与卸载"></a>boot 目录的挂载与卸载</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 /]# umount /boot</span><br><span class="line">[root@node01 /]# df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda3        97G  842M   91G   1% /</span><br><span class="line">tmpfs           491M     0  491M   0% /dev/shm</span><br><span class="line">[root@node01 /]# mount /dev/sda1 /boot</span><br><span class="line">[root@node01 /]# df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda3        97G  842M   91G   1% /</span><br><span class="line">tmpfs           491M     0  491M   0% /dev/shm</span><br><span class="line">/dev/sda1       194M   28M  157M  15% /boot</span><br></pre></td></tr></table></figure>

<h4 id="File-System-Hierarchy-Standard"><a href="#File-System-Hierarchy-Standard" class="headerlink" title="File System Hierarchy Standard"></a>File System Hierarchy Standard</h4><blockquote>
<p> 文件系统层次化标准</p>
</blockquote>
<table>
<thead>
<tr>
<th>目录</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>/boot</td>
<td>系统启动相关的文件，如内核、initrd，以及grub(bootloader)</td>
</tr>
<tr>
<td>/dev</td>
<td>设备文件</td>
</tr>
<tr>
<td>/etc</td>
<td>配置文件</td>
</tr>
<tr>
<td>/home</td>
<td>用户的家目录，每一个用户的家目录通常默认为/home/USERNAME</td>
</tr>
<tr>
<td>/root</td>
<td>管理员的家目录</td>
</tr>
<tr>
<td>/lib</td>
<td>库文件</td>
</tr>
<tr>
<td>/media</td>
<td>挂载点目录，移动设备</td>
</tr>
<tr>
<td>/mnt</td>
<td>挂载点目录，额外的临时文件系统</td>
</tr>
<tr>
<td>/opt</td>
<td>可选目录，第三方程序的安装目录</td>
</tr>
<tr>
<td>/proc</td>
<td>伪文件系统，跟硬件设备相关的属性映射文件</td>
</tr>
<tr>
<td>/sys</td>
<td>临时文件， /var/tmp</td>
</tr>
<tr>
<td>/tmp</td>
<td>可变化的文件</td>
</tr>
<tr>
<td>/bin</td>
<td>可执行文件， 用户命令</td>
</tr>
<tr>
<td>/sbin</td>
<td>管理命令</td>
</tr>
</tbody></table>
<p><strong>系统启动必须：</strong></p>
<ul>
<li><p><strong>/boot：</strong>存放的启动Linux 时使用的内核文件，包括连接文件以及镜像文件。</p>
</li>
<li><p><strong>/etc：</strong>存放<strong>所有</strong>的系统需要的<strong>配置文件</strong>和<strong>子目录列表，</strong>更改目录下的文件可能会导致系统不能启动。</p>
</li>
<li><p><strong>/lib</strong>：存放基本代码库（比如c++库），其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。</p>
</li>
<li><p><strong>/sys</strong>： 这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs 。sysfs文件系统集成了下面3种文件系统的信息：针对进程信息的proc文件系统、针对设备的devfs文件系统以及针对伪终端的devpts文件系统。该文件系统是内核设备树的一个直观反映。当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统中</p>
</li>
</ul>
<p><strong>指令集合：</strong></p>
<ul>
<li><p><strong>/bin：</strong>存放着最常用的程序和指令</p>
</li>
<li><p><strong>/sbin：</strong>只有系统管理员能使用的程序和指令。</p>
</li>
</ul>
<p><strong>外部文件管理：</strong></p>
<ul>
<li><p><strong>/dev ：</strong>Device(设备)的缩写, 存放的是Linux的外部设备。<strong>注意：</strong>在Linux中访问设备和访问文件的方式是相同的。</p>
</li>
<li><p><strong>/media</strong>：类windows的<strong>其他设备，</strong>例如U盘、光驱等等，识别后linux会把设备放到这个目录下。</p>
</li>
<li><p><strong>/mnt</strong>：临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。</p>
</li>
</ul>
<p><strong>临时文件：</strong></p>
<ul>
<li><p><strong>/run</strong>：是一个临时文件系统，存储系统启动以来的信息。当系统重启时，这个目录下的文件应该被删掉或清除。如果你的系统上有 /var/run 目录，应该让它指向 run。</p>
</li>
<li><p><strong>/lost+found</strong>：一般情况下为空的，系统非法关机后，这里就存放一些文件。</p>
</li>
<li><p><strong>/tmp</strong>：这个目录是用来存放一些临时文件的。</p>
</li>
</ul>
<p><strong>账户：</strong></p>
<ul>
<li><p><strong>/root</strong>：系统管理员的用户主目录。</p>
</li>
<li><p><strong>/home</strong>：用户的主目录，以用户的账号命名的。</p>
</li>
<li><p><strong>/usr</strong>：用户的很多应用程序和文件都放在这个目录下，类似于windows下的program files目录。</p>
</li>
<li><p><strong>/usr/bin：</strong>系统用户使用的应用程序与指令。</p>
</li>
<li><p><strong>/usr/sbin：</strong>超级用户使用的比较高级的管理程序和系统守护程序。</p>
</li>
<li><p><strong>/usr/src：</strong>内核源代码默认的放置目录。</p>
</li>
</ul>
<p><strong>运行过程中要用：</strong></p>
<ul>
<li><p><strong>/var</strong>：存放经常修改的数据，比如程序运行的日志文件（/var/log 目录下）。</p>
</li>
<li><p><strong>/proc</strong>：管理<strong>内存空间！</strong>虚拟的目录，是系统内存的映射，我们可以直接访问这个目录来，获取系统信息。这个目录的内容不在硬盘上而是在内存里，我们也可以直接修改里面的某些文件来做修改。</p>
</li>
</ul>
<p><strong>扩展用的：</strong></p>
<ul>
<li><p><strong>/opt</strong>：默认是空的，我们安装额外软件可以放在这个里面。</p>
</li>
<li><p><strong>/srv</strong>：存放服务启动后需要提取的数据<strong>（不用服务器就是空）</strong> </p>
</li>
</ul>
<p><strong>挂载 cdrom 到 /mnt 目录下</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/cdrom  /mnt</span><br></pre></td></tr></table></figure>

<h3 id="文本操作命令"><a href="#文本操作命令" class="headerlink" title="文本操作命令"></a>文本操作命令</h3><table>
<thead>
<tr>
<th>command</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>cat</td>
<td>显示全部文本文件内容</td>
</tr>
<tr>
<td>more</td>
<td>逐页显示文本文件内容</td>
</tr>
<tr>
<td>less</td>
<td>一次性读取全部文件内容，相比more，可以往回看</td>
</tr>
<tr>
<td>head</td>
<td>显示前 n 行的内容</td>
</tr>
<tr>
<td>tail</td>
<td>显示后 n 行的内容</td>
</tr>
<tr>
<td>|</td>
<td>管道</td>
</tr>
<tr>
<td>xargs</td>
<td></td>
</tr>
</tbody></table>
<p><strong>使用 head 和 tail 命令遍历每行</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 god]# cat profile | head -3 | tail -1</span><br><span class="line"># System wide environment and startup programs, for login setup</span><br></pre></td></tr></table></figure>

<p><strong>xargs 用法</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 god]# echo "/"  |xargs ls -l</span><br><span class="line">total 90</span><br><span class="line">dr-xr-xr-x.  2 root root  4096 Sep 21 19:29 bin</span><br><span class="line">dr-xr-xr-x.  5 root root  1024 Sep 21 19:29 boot</span><br><span class="line">drwxr-xr-x. 18 root root  3680 Sep 21 22:21 dev</span><br><span class="line"><span class="meta">#</span> ....</span><br></pre></td></tr></table></figure>

<h3 id="vi-全屏文本编辑器"><a href="#vi-全屏文本编辑器" class="headerlink" title="vi 全屏文本编辑器"></a>vi 全屏文本编辑器</h3><h4 id="打开方式"><a href="#打开方式" class="headerlink" title="打开方式"></a>打开方式</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim /path/to/somefile</span><br><span class="line">vim +# :打开文件，并定位于第#行 </span><br><span class="line">vim +：打开文件，定位至最后一行</span><br><span class="line">vim +/PATTERN : 打开文件，定位至第一次被PATTERN匹配到的行的行首</span><br></pre></td></tr></table></figure>

<h4 id="关闭文件"><a href="#关闭文件" class="headerlink" title="关闭文件"></a>关闭文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">末行模式：</span><br><span class="line">:q  退出  没有动过文件 </span><br><span class="line">:wq 保存并退出   动过了，不后悔</span><br><span class="line">:q! 不保存并退出  动过了，后悔了</span><br><span class="line">:w 保存</span><br><span class="line">:w! 强行保存</span><br><span class="line">:wq --&gt; :x</span><br><span class="line"></span><br><span class="line">ZZ: 保存并退出   不需要冒号，编辑模式   # 重点*</span><br></pre></td></tr></table></figure>

<h4 id="三种模式"><a href="#三种模式" class="headerlink" title="三种模式"></a>三种模式</h4><p>按键具有编辑文本功能：默认打开进入编辑模式<br>输入模式：按键本身意义<br>末行模式：接受用户命令输入</p>
<ul>
<li><p><strong>编辑模式</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>编辑--&gt;输入：</span><br><span class="line">	i: 在当前光标所在字符的前面，转为输入模式；*</span><br><span class="line">	a: 在当前光标所在字符的后面，转为输入模式；*</span><br><span class="line"></span><br><span class="line">	o: 在当前光标所在行的下方，新建一行，并转为输入模式；</span><br><span class="line">	O：在当前光标所在行的上方，新建一行，并转为输入模式；	</span><br><span class="line">	I：在当前光标所在行的行首，转换为输入模式</span><br><span class="line">	A：在当前光标所在行的行尾，转换为输入模式</span><br><span class="line">	输入--&gt;编辑：</span><br><span class="line">ESC</span><br><span class="line"><span class="meta">#</span>编辑--&gt;末行：</span><br><span class="line">：</span><br><span class="line"><span class="meta">#</span>末行--&gt;编辑：</span><br><span class="line">ESC, ESC</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>移动光标</span><br><span class="line">字符</span><br><span class="line">h: 左；j: 下；k: 上；l: 右</span><br><span class="line"><span class="meta">#</span> 单词</span><br><span class="line">w: 移至下一个单词的词首*</span><br><span class="line">e: 跳至当前或下一个单词的词尾</span><br><span class="line">b: 跳至当前或前一个单词的词首</span><br><span class="line"><span class="meta">#</span> 行内</span><br><span class="line">0: 绝对行首</span><br><span class="line">^: 行首的第一个非空白字符*</span><br><span class="line"><span class="meta">$</span>: 绝对行尾*</span><br><span class="line"><span class="meta">#</span> 行间</span><br><span class="line">G:文章末尾</span><br><span class="line">3G:第3行</span><br><span class="line">gg:文章开头</span><br><span class="line"><span class="meta">#</span> 翻屏</span><br><span class="line">ctrl：f，b</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 删除&amp;替换单个字符</span><br><span class="line">x:删除光标位置字符</span><br><span class="line">3x:删除光标开始3个字符</span><br><span class="line">r:替换光标位置字符</span><br><span class="line"><span class="meta">#</span> 删除命令 ： d </span><br><span class="line">dw，dd</span><br><span class="line"><span class="meta">#</span> 复制粘贴&amp;剪切	</span><br><span class="line">yw(复制一个词)，yy（复制一行）</span><br><span class="line">p（向下粘贴）</span><br><span class="line">P(向上粘贴)</span><br><span class="line"><span class="meta">#</span> 撤销&amp;重做</span><br><span class="line">u   撤销*</span><br><span class="line">ctrl+r  重做 撤销的操作*</span><br><span class="line"></span><br><span class="line">.  重复上一步的操作</span><br></pre></td></tr></table></figure>
</li>
<li><p>末行模式 （进入末行模式 shirt+: ）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">set：设置</span><br><span class="line">set nu  number</span><br><span class="line">set nonu nonumber</span><br><span class="line">set readonly</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/：查找</span><br><span class="line">/after</span><br><span class="line">n(向下查找)，N（向上查找）</span><br><span class="line">？向上查找</span><br><span class="line">！：执行命令</span><br><span class="line">:!ls -l /</span><br><span class="line"></span><br><span class="line">s查找并替换</span><br><span class="line">s/str1/str2/gi</span><br><span class="line">/：临近s命令的第一个字符为边界字符：/，@，#</span><br><span class="line">g：一行内全部替换（若没有选择，则替换当前行的第一个替换）</span><br><span class="line">i：忽略大小写</span><br><span class="line">范围</span><br><span class="line">n：行号</span><br><span class="line">.：当前光标行</span><br><span class="line">+n：偏移n行</span><br><span class="line"><span class="meta">$</span>：末尾行，$-3</span><br><span class="line"><span class="meta">%</span>：全文</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 替换查找从当前光标处，到文件末尾处</span><br><span class="line">eg: .,$s/str1/str2/gi</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="末行模式小技巧"><a href="#末行模式小技巧" class="headerlink" title="末行模式小技巧"></a>末行模式小技巧</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">编辑模式下 ：</span><br><span class="line">:Gd  清空内容</span><br><span class="line">:.,$d 删除从当前光标到末尾所有行</span><br><span class="line">:n,md 删除从第 n 行到 m 行的所有内容</span><br><span class="line">:n,my 复制从第 n 行到 m 行的所有内容</span><br></pre></td></tr></table></figure>

<h2 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">grep：显示匹配行</span><br><span class="line">- v：反显示</span><br><span class="line">- e：使用扩展正则表达式</span><br><span class="line"></span><br><span class="line">匹配操作符</span><br><span class="line">\                  转义字符</span><br><span class="line">. 	                 匹配任意单个字符</span><br><span class="line">[1249a]，[^12],[a-k]  字符序列单字符占位</span><br><span class="line">^                 行首</span><br><span class="line">$                  行尾</span><br><span class="line">\&lt;,\&gt;：\&lt;abc           单词首尾边界*</span><br><span class="line">|                   连接操作符</span><br><span class="line">(,)              选择操作符</span><br><span class="line">\n    	     反向引用</span><br><span class="line"></span><br><span class="line">重复操作符：</span><br><span class="line">?      	匹配0到1次。</span><br><span class="line">*      	匹配0到多次。</span><br><span class="line">+     	匹配1到多次。</span><br><span class="line">&#123;n&#125;   	匹配n次。</span><br><span class="line">&#123;n,&#125;  	匹配n到多次。</span><br><span class="line">&#123;n,m&#125;      匹配n到m次。</span><br><span class="line">与扩展正则表达式的区别:grep basic</span><br><span class="line">\?, \+, \&#123;, \|, \(, and \)</span><br><span class="line">匹配任意字符</span><br><span class="line">.*</span><br></pre></td></tr></table></figure>

<p><strong>注意：在未扩展正则表达式时，若匹配规则中含有 ？,+,{,},|,(,) ,都需要通过 \ 转义，否则匹配不到</strong></p>
<p><strong>查询文章中包括4位整数的行</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -E  &quot;([^0-9][0-9]|^[0-9])([0-9]&#123;2&#125;)([0-9][^0-9]|[0-9]$)&quot;  grep.txt</span><br></pre></td></tr></table></figure>

<p><strong>查看指定单词</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep “\&lt;单词名\&gt;”  file</span><br></pre></td></tr></table></figure>

<p><strong>反向引用</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 god]# grep  -E ".*(god).*(good).*\2.*\1" test</span><br><span class="line">asgodssgoodsssagoodssgod</span><br><span class="line">[root@node01 god]# grep  -E ".*(god).*(good).*\1.*\2" test</span><br><span class="line">asgodssgoodsssagodssgood</span><br></pre></td></tr></table></figure>

<h2 id="文本处理"><a href="#文本处理" class="headerlink" title="文本处理"></a>文本处理</h2><h4 id="cut-命令"><a href="#cut-命令" class="headerlink" title="cut 命令"></a>cut 命令</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cut：显示切割的行数据</span><br><span class="line">f：选择显示的列</span><br><span class="line">s：不显示没有分隔符的行</span><br><span class="line">d：自定义分隔符</span><br></pre></td></tr></table></figure>

<p>测试</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 god]# cut -d' ' -s  -f1-3 grep.txt </span><br><span class="line">ooxx 12121212</span><br><span class="line">oox 12121212</span><br><span class="line">1212 ooxx 1212</span><br><span class="line">[root@node01 god]# cut -d' ' -f1,2,3 grep.txt </span><br><span class="line">ooxx12121212ooxx</span><br><span class="line">ooxx 12121212</span><br><span class="line">oox 12121212</span><br><span class="line">1212 ooxx 1212</span><br><span class="line">oo3xx</span><br><span class="line">oo4xx</span><br><span class="line">ooWxx</span><br><span class="line">oomxx</span><br><span class="line"><span class="meta">$</span>ooxx</span><br><span class="line">oo1234xx</span><br><span class="line">ooxyzxx</span><br></pre></td></tr></table></figure>

<h4 id="sort命令"><a href="#sort命令" class="headerlink" title="sort命令"></a>sort命令</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sort：排序文件的行</span><br><span class="line">n：按数值排序</span><br><span class="line">r：倒序</span><br><span class="line">t：自定义分隔符</span><br><span class="line">k：选择排序列</span><br><span class="line">u：合并相同行</span><br><span class="line">f：忽略大小写</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 god]# sort  -k2 -n -r  fruits.txt </span><br><span class="line">orange--27</span><br><span class="line">banana--15</span><br><span class="line">apple--20</span><br><span class="line">apple--20</span><br><span class="line">[root@node01 god]# sort  -k2 -n -r fruits.txt</span><br></pre></td></tr></table></figure>

<h4 id="wc-命令"><a href="#wc-命令" class="headerlink" title="wc 命令"></a>wc 命令</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wc 打印每个文件的换行数、单词数和字节数</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 god]# wc fruits.txt </span><br><span class="line"> 4  4 42 fruits.txt</span><br><span class="line">[root@node01 god]# cat fruits.txt | wc</span><br><span class="line">      4       4      42</span><br><span class="line">[root@node01 god]# cat fruits.txt | wc -l</span><br><span class="line">4</span><br></pre></td></tr></table></figure>

<p><strong>统计当前目录中文件的个数</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls ./ | wc</span><br></pre></td></tr></table></figure>

<h3 id="行编辑器"><a href="#行编辑器" class="headerlink" title="行编辑器"></a>行编辑器</h3><h4 id="sed-命令"><a href="#sed-命令" class="headerlink" title="sed 命令"></a>sed 命令</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">sed [options] 'AddressCommand' file ...</span><br><span class="line">	-n: 静默模式，不再默认显示模式空间中的内容</span><br><span class="line">	-i: 直接修改原文件*</span><br><span class="line">	-e SCRIPT -e SCRIPT:可以同时执行多个脚本</span><br><span class="line">	-f /PATH/TO/SED_SCRIPT</span><br><span class="line">	-r: 表示使用扩展正则表达式*</span><br><span class="line">	</span><br><span class="line">d: 删除符合条件的行；</span><br><span class="line">p: 显示符合条件的行；</span><br><span class="line">a \string: 在指定的行后面追加新行，内容为string*</span><br><span class="line">\n：可以用于换行</span><br><span class="line">i \string: 在指定的行前面添加新行，内容为string*</span><br><span class="line">r FILE: 将指定的文件的内容添加至符合条件的行处</span><br><span class="line">w FILE: 将地址指定的范围内的行另存至指定的文件中; </span><br><span class="line">s/pattern/string/修饰符: 查找并替换，默认只替换每行中第一次被模式匹配到的字符串*</span><br><span class="line">g: 行内全局替换</span><br><span class="line">i: 忽略字符大小写</span><br><span class="line">s///: s###, s@@@	</span><br><span class="line">	\(\), \1, \2   *</span><br><span class="line"></span><br><span class="line">sed：行编辑器Address</span><br><span class="line">可以没有 </span><br><span class="line">给定范围</span><br><span class="line">查找指定行/str/</span><br></pre></td></tr></table></figure>

<p><strong>模糊匹配指定行，并替换</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> id:9:initdefault:</span><br><span class="line"></span><br><span class="line">sed "s/\(id:\)[0-9]\(:initdefault:\)/\19\2/" inittab</span><br></pre></td></tr></table></figure>

<p><strong>模糊匹配 IP 地址，并替换最后的主机号</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sed <span class="string">"s/\(IPADDR=\(\([0-9]\|[1-9][0-9]\|1[0-9][0-9]\|2[0-4][0-9]\|25[0-5]\)\.\)\&#123;3\&#125;\).*/\1144/"</span> ifcfg-eth0</span><br><span class="line"></span><br><span class="line">[root@node01 god]<span class="comment"># num=100</span></span><br><span class="line">[root@node01 god]<span class="comment"># sed "s/\(IPADDR=\(\([0-9]\|[1-9][0-9]\|1[0-9][0-9]\|2[0-4][0-4]\|25[0-5]\)\.\)\&#123;3\&#125;\).*/\1$num/"  -i ifcfg-eth0</span></span><br></pre></td></tr></table></figure>

<p>注意： <code>\.</code> 表示真实的点，不作为正则匹配中任意字符</p>
<h4 id="awk-命令"><a href="#awk-命令" class="headerlink" title="awk 命令"></a>awk 命令</h4><blockquote>
<p>awk是一个强大的文本分析工具。<br>相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。<br>简单来说awk就是把文件逐行的读入，（空格，制表符）为默认分隔符将每行切片，切开的部分再进行各种分析处理。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">awk -F '&#123;pattern + action&#125;' &#123;filenames&#125;</span><br><span class="line">支持自定义分隔符</span><br><span class="line">支持正则表达式匹配</span><br><span class="line">支持自定义变量，数组  a[1]  a[tom]  map(key)</span><br><span class="line">支持内置变量</span><br><span class="line">ARGC               命令行参数个数</span><br><span class="line">ARGV               命令行参数排列</span><br><span class="line">ENVIRON            支持队列中系统环境变量的使用</span><br><span class="line">FILENAME           awk浏览的文件名</span><br><span class="line">FNR                浏览文件的记录数</span><br><span class="line">FS                 设置输入域分隔符，等价于命令行 -F选项</span><br><span class="line">NF                 浏览记录的域的个数*</span><br><span class="line">NR                 已读的记录数*</span><br><span class="line">OFS                输出域分隔符</span><br><span class="line">ORS                输出记录分隔符</span><br><span class="line">RS                 控制记录分隔符</span><br><span class="line">支持函数</span><br><span class="line">print、split、substr、sub、gsub</span><br><span class="line">支持流程控制语句，类C语言</span><br><span class="line">if、while、do/while、for、break、continue</span><br><span class="line"><span class="meta">#</span>--------------------------------------------------------------------------------#</span><br><span class="line">只是显示/etc/passwd的账户:CUT</span><br><span class="line">awk -F':' '&#123;print $1&#125;' passwd</span><br><span class="line">只是显示/etc/passwd的账户和账户对应的shell,而账户与shell之间以逗号分割,而且在所有行开始前添加列名name,shell,在最后一行添加"blue,/bin/nosh"（cut，sed）</span><br><span class="line">awk -F':' 'BEGIN&#123;print "name,shell"&#125; &#123;print $1 "," $7&#125; END&#123;print "blue,/bin/nosh"&#125;' passwd</span><br><span class="line">搜索/etc/passwd有root关键字的所有行</span><br><span class="line">awk  '/root/ &#123; print $0&#125;'   passwd</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ol>
<li><p><code>$0 表示一整行内容</code></p>
</li>
<li><p>代码块{} 外加单引号，不能是双引号，即 <code>&#39;{}&#39;</code></p>
</li>
<li><p>awk 默认以空白、TAB作为分隔符 delimiter，即若以空白、TAB为分隔号，不需要指定 <code>-F</code>参数</p>
</li>
</ol>
<p><strong>统计/etc/passwd文件中，每行的行号，每行的列数，对应的完整行内容</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">awk -F":" 'BEGIN&#123; print "NR\tNF\tContent" &#125; &#123;print NR "\t" NF "\t" $0 &#125;' passwd </span><br><span class="line"><span class="meta">#</span> 结果</span><br><span class="line">NR	NF	Content</span><br><span class="line">1	7	root:x:0:0:root:/root:/bin/bash</span><br><span class="line">2	7	bin:x:1:1:bin:/bin:/sbin/nologin</span><br><span class="line">3	7	daemon:x:2:2:daemon:/sbin:/sbin/nologin</span><br><span class="line"><span class="meta">#</span> ....</span><br></pre></td></tr></table></figure>

<p><strong>打印报表功能</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> awk.txt</span><br><span class="line">Tom	     0   2012-12-11      car     3000</span><br><span class="line">John	 1   2013-01-13      bike    1000</span><br><span class="line">vivi	 1   2013-01-18      car     2800</span><br><span class="line">Tom	     0   2013-01-20      car     2500</span><br><span class="line">John	 1   2013-01-28      bike    3500</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> awk.sh</span><br><span class="line">&#123;</span><br><span class="line">        split($3,date,"-")</span><br><span class="line">        if(date[2] == "01")&#123;</span><br><span class="line">                name[$1] += $5  #把名字作为数组下标，对应的value为工资</span><br><span class="line">        &#125;</span><br><span class="line">        if($2 == "0")&#123;</span><br><span class="line">                role[$1] = "manager"</span><br><span class="line">        &#125;else&#123;</span><br><span class="line">                role[$1] = "worker"</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line">END&#123;</span><br><span class="line">        for (i in name)&#123;</span><br><span class="line">                print i "\t" role[i] "\t" name[i]</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>  使用</span><br><span class="line">[root@node01 god]# awk -f awk.sh awk.txt </span><br><span class="line">vivi	worker	2800</span><br><span class="line">Tom	manager	2500</span><br><span class="line">John	worker	4500</span><br></pre></td></tr></table></figure>

<h2 id="Linux-用户管理"><a href="#Linux-用户管理" class="headerlink" title="Linux 用户管理"></a>Linux 用户管理</h2><table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>id</td>
<td>打印输出有效用户的自身的ID 和 所在组的 ID</td>
</tr>
<tr>
<td>useradd</td>
<td>添加用户</td>
</tr>
<tr>
<td>userdel</td>
<td>删除用户</td>
</tr>
<tr>
<td>groupadd</td>
<td>添加组</td>
</tr>
<tr>
<td>groupdel</td>
<td>删除组</td>
</tr>
<tr>
<td>passwd</td>
<td>设置或修改密码</td>
</tr>
<tr>
<td>sudo *</td>
<td>提升权限</td>
</tr>
<tr>
<td>su</td>
<td>切换用户</td>
</tr>
</tbody></table>
<p><strong>删除用户</strong></p>
<p>若要删除用户，再创建同名用户，需要在创建前删除原 /home 目录和 /var/mail 目录下的内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 /]# userdel god</span><br><span class="line">[root@node01 /]# useradd god</span><br><span class="line">useradd: warning: the home directory already exists.</span><br><span class="line">Not copying any file from skel directory into it.</span><br><span class="line">Creating mailbox file: File exists</span><br><span class="line">[root@node01 /]# rm -rf /home/god/</span><br><span class="line">[root@node01 /]# useradd god</span><br><span class="line">useradd: user 'god' already exists</span><br><span class="line">[root@node01 /]# rm -fr /var/</span><br><span class="line">cache/    empty/    lib/      lock/     mail/     opt/      run/      tmp/      </span><br><span class="line">db/       games/    local/    log/      nis/      preserve/ spool/    yp/       </span><br><span class="line">[root@node01 /]# rm -fr /var/mail/god </span><br><span class="line">[root@node01 /]# useradd god</span><br></pre></td></tr></table></figure>

<h4 id="权限"><a href="#权限" class="headerlink" title="权限"></a>权限</h4><table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>r</td>
<td>读权限 r=4</td>
</tr>
<tr>
<td>w</td>
<td>写权限 w=2</td>
</tr>
<tr>
<td>x</td>
<td>可执行权限 x=1</td>
</tr>
<tr>
<td>usermod</td>
<td>修改用户权限</td>
</tr>
<tr>
<td>chown</td>
<td>修改文件的属主和属组</td>
</tr>
<tr>
<td>chmod</td>
<td>修改文件操作权限 (RWX)  augo</td>
</tr>
</tbody></table>
<p>注意： </p>
<ol>
<li><p>一个文件只能有一个属主和一个属组</p>
</li>
<li><p><strong>文件夹的执行权限 x ，表示用户是否可以进入到该文件夹下</strong></p>
</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">useradd sxt01</span><br><span class="line">passwd sxt01</span><br><span class="line">useradd sxt02</span><br><span class="line">passwd sxt02</span><br><span class="line"></span><br><span class="line">mkdir /var/swapdata</span><br><span class="line">1,权限修正：</span><br><span class="line">chmod  770  swapdata   |  chmod  o-rwx g+rwx   swapdata</span><br><span class="line">2,修正属组</span><br><span class="line">groupadd sxtswap</span><br><span class="line">usermod -a -G sxtswap sxt01</span><br><span class="line">usermod -a -G sxtswap sxt02</span><br><span class="line">chown  root:sxtswap swapdata</span><br><span class="line">chown :sxtswap   ooxx.file</span><br><span class="line">chmod  770 ooxx.file</span><br><span class="line">id  username</span><br></pre></td></tr></table></figure>

<h2 id="Linux-编译安装"><a href="#Linux-编译安装" class="headerlink" title="Linux  编译安装"></a>Linux  编译安装</h2><table>
<thead>
<tr>
<th>执行顺</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>./configure</td>
<td>生成编译依赖关系</td>
</tr>
<tr>
<td>make</td>
<td>编译</td>
</tr>
<tr>
<td>make install</td>
<td>新建文件夹、拷贝文件</td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">1，下载源码包</span><br><span class="line">2，解压缩：tar xf filename</span><br><span class="line">3，cd：vi README</span><br><span class="line">4，./configure</span><br><span class="line">检查操作系统</span><br><span class="line">检查编译环境</span><br><span class="line">yum install gcc</span><br><span class="line">pcre 依赖库</span><br><span class="line">yum search pcre</span><br><span class="line">yum install pcre-devel</span><br><span class="line">openssl</span><br><span class="line">yum install opssl-devel</span><br><span class="line">./configure --help</span><br><span class="line">./configure --prefix=/opt/sxt/nginx   #配置安装路径</span><br><span class="line">5，Makefile</span><br><span class="line">6，make</span><br><span class="line">7，make install</span><br><span class="line">8，cd /opt/sxt/nginx/sbin     ./nginx</span><br><span class="line">9，浏览器访问测试</span><br><span class="line">10，祝君好运~！</span><br></pre></td></tr></table></figure>

<h2 id="Linux-RPM-安装"><a href="#Linux-RPM-安装" class="headerlink" title="Linux RPM 安装"></a>Linux RPM 安装</h2><blockquote>
<p>Redhat提供了rpm管理体系<br>已经编译的软件包：针对不同的平台系统编译目标软件包<br>操作系统维护安装信息<br>软件包包含依赖检查，但还需人为解决</p>
</blockquote>
<p><strong>安装 rpm 软件</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh  xxxx.rpm</span><br></pre></td></tr></table></figure>

<p><strong>rpm 命令使用</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">rpm安装：</span><br><span class="line">-ivh  filename</span><br><span class="line">--prefix</span><br><span class="line">rpm升级：</span><br><span class="line">-Uvh</span><br><span class="line">-Fvh</span><br><span class="line">rpm卸载：</span><br><span class="line">-e PACKAGE_NAME</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> rpm查询</span><br><span class="line">rpm -qa : 查询已经安装的所有包</span><br><span class="line">rpm -q  PACKAGE_NAME: 查询指定的包是否已经安装</span><br><span class="line">rpm -qi PACKAGE_NAME: 查询指定包的说明信息</span><br><span class="line">rpm -ql PACKAGE_NAME: 查询指定包安装后生成的文件列表</span><br><span class="line">rpm -qc PACEAGE_NEME：查询指定包安装的配置文件</span><br><span class="line">rpm -qd PACKAGE_NAME: 查询指定包安装的帮助文件</span><br><span class="line">rpm -q --scripts PACKAGE_NAME: 查询指定包中包含的脚本	</span><br><span class="line">rpm -qf /path/to/somefile: 查询文件是由哪个rpm包安装生成的	</span><br><span class="line">如果某rpm包尚未安装，需查询其说明信息、安装以后会生成的文件</span><br><span class="line">rpm -qpi /PATH/TO/PACKAGE_FILE</span><br><span class="line">rpm -qpl</span><br></pre></td></tr></table></figure>

<h2 id="Linux-YUM-安装"><a href="#Linux-YUM-安装" class="headerlink" title="Linux YUM 安装"></a>Linux YUM 安装</h2><h3 id="yum-命令"><a href="#yum-命令" class="headerlink" title="yum 命令"></a>yum 命令</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">yum命令：</span><br><span class="line">yum repolist</span><br><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br><span class="line">yum update</span><br><span class="line">查询：</span><br><span class="line">yum list</span><br><span class="line">yum search</span><br><span class="line">yum info</span><br><span class="line">安装&amp;卸载：</span><br><span class="line">yum install </span><br><span class="line">remove|erase</span><br><span class="line"></span><br><span class="line">yum命令：分组</span><br><span class="line">yum grouplist</span><br><span class="line">yum groupinfo</span><br><span class="line">yum groupinstall</span><br><span class="line">yum groupremove</span><br><span class="line">yum groupupdate</span><br></pre></td></tr></table></figure>

<h4 id="更换安装为阿里源"><a href="#更换安装为阿里源" class="headerlink" title="更换安装为阿里源"></a>更换安装为阿里源</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 备份</span><br><span class="line">mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 下载阿里 yum 源</span><br><span class="line">curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 更新缓存</span><br><span class="line">yum makecache</span><br></pre></td></tr></table></figure>

<h4 id="本地-yum-源"><a href="#本地-yum-源" class="headerlink" title="本地 yum 源"></a>本地 yum 源</h4><ol>
<li>为当前虚拟机挂载镜像文件</li>
</ol>
<p><img src="http://img.zwer.xyz/blog/20190923144107.png" alt></p>
<ol start="2">
<li>操作</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 挂载 cdrom </span><br><span class="line">mount /dev/cdrom /mnt</span><br><span class="line"></span><br><span class="line">repo：</span><br><span class="line">/etc/yum.repos.d/</span><br><span class="line">[repoID]</span><br><span class="line">baseurl=</span><br><span class="line">http://</span><br><span class="line">file://</span><br><span class="line">ftp://</span><br><span class="line"><span class="meta">#</span>gpgchkeck= 有1和0两个选择，分别代表是否是否进行gpg校验，如果没有这一项，默认是检查的。 </span><br><span class="line">gpgcheck=1/0</span><br><span class="line"><span class="meta">#</span>当某个软件仓库被配置成 enabled=0 时，yum 在安装或升级软件包时不会将该仓库做为软件包提供源。使用这个选项，可以启用或禁用软件仓库。  </span><br><span class="line">enable=0/1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>[base]</span><br><span class="line">name=local</span><br><span class="line">failovermethod=priority</span><br><span class="line">baseurl=file:///mnt</span><br><span class="line">gpgcheck=1</span><br><span class="line">enable=1</span><br></pre></td></tr></table></figure>

<p>注意： <strong>若包名中间包括空格，一定使用双引号括起来</strong></p>
<h4 id="中文显示，查看中文文档"><a href="#中文显示，查看中文文档" class="headerlink" title="中文显示，查看中文文档"></a>中文显示，查看中文文档</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> yum 的 repo 变成aliyun  || 本地DVD</span><br><span class="line">yum grouplist</span><br><span class="line">yum groupinstall "Chinese Support"</span><br><span class="line">echo $LANG</span><br><span class="line">en_US.UTF-8</span><br><span class="line">LANG=zh_CN.UTF-8</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>增加epel的repo：</span><br><span class="line">http://mirrors.aliyun.com</span><br><span class="line"><span class="meta">epel&gt;</span>&gt;&gt;&gt;&gt;help</span><br><span class="line">wget centos6.......</span><br><span class="line"></span><br><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br><span class="line">yum search man-pages</span><br><span class="line">yum install man man-pages man-pages-zh-CN</span><br><span class="line">【【【【 man bash 】】】】</span><br></pre></td></tr></table></figure>

<h2 id="文本流"><a href="#文本流" class="headerlink" title="文本流"></a>文本流</h2><blockquote>
<p>变量<br>引用&amp;命令替换<br>退出状态&amp;逻辑判断<br>表达式<br>流程控制</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">重定向：不是命令</span><br><span class="line">程序自身都有I/O</span><br><span class="line">0：标准输入</span><br><span class="line">1：标准输出</span><br><span class="line">2：错误输出</span><br><span class="line">控制程序I/O位置</span><br><span class="line">一切皆文件</span><br><span class="line">/proc/$$/fd</span><br><span class="line">程序是否处理I/O？</span><br><span class="line">绑定顺序：从左到右</span><br></pre></td></tr></table></figure>

<h4 id="输出重定向"><a href="#输出重定向" class="headerlink" title="输出重定向"></a>输出重定向</h4><table>
<thead>
<tr>
<th>输出重定向</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>1&gt;xxx</code></td>
<td>标准输出覆盖重定向</td>
</tr>
<tr>
<td><code>1&gt;&gt;xxx</code></td>
<td>标准输出追加重定向</td>
</tr>
<tr>
<td><code>2&gt;xxx</code></td>
<td>错误覆盖重定向</td>
</tr>
<tr>
<td><code>2&gt;&gt;xxx</code></td>
<td>错误追加重定向</td>
</tr>
<tr>
<td><code>&gt;&amp;</code>或者<code>&amp;&gt;</code>   xxx</td>
<td>向 xxx 文件添加错误和标准输出信息</td>
</tr>
</tbody></table>
<p>注意： 重定向符号左边都不能包括空格</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 god]# ls /yy 2&gt;error</span><br><span class="line">[root@node01 god]# ll</span><br><span class="line">total 8</span><br><span class="line">-rw-r--r--. 1 root root 140 Sep 22 22:39 a</span><br><span class="line">-rw-r--r--. 1 root root  49 Sep 22 22:40 error</span><br><span class="line">[root@node01 god]# cat error </span><br><span class="line">ls: cannot access /yy: No such file or directory</span><br><span class="line">[root@node01 god]# ls /123 2&gt;&gt;error</span><br><span class="line">[root@node01 god]# cat error</span><br><span class="line">ls: cannot access /yy: No such file or directory</span><br><span class="line">ls: cannot access /123: No such file or directory</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@node01 god]# ls / /suibian 1&gt;ls02.out 2&gt;&amp;1</span><br><span class="line">[root@node01 god]# cat ls02.out</span><br><span class="line">ls: cannot access /suibian: No such file or directory</span><br><span class="line">/:</span><br><span class="line">abc</span><br><span class="line">bin</span><br><span class="line"><span class="meta">#</span> ... 省略</span><br><span class="line">[root@node01 god]# ls / /suibian &gt;&amp; ls01.out</span><br><span class="line">[root@node01 god]# cat ls01.out </span><br><span class="line">ls: cannot access /suibian: No such file or directory</span><br><span class="line">/:</span><br><span class="line">abc</span><br><span class="line">bin</span><br><span class="line">boot</span><br><span class="line"><span class="meta">#</span> ... 省略</span><br></pre></td></tr></table></figure>

<p> 注意： 若一条命令中既包括错误输出，也包括正确输出，则先输出错误输出     </p>
<h4 id="输入重定向"><a href="#输入重定向" class="headerlink" title="输入重定向"></a>输入重定向</h4><table>
<thead>
<tr>
<th>输入重定向</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>&lt;&lt;&lt;</code></td>
<td>从字符串中读取输入</td>
</tr>
<tr>
<td><code>&lt;&lt;E</code></td>
<td>从键盘中读取输入,E表示结束符</td>
</tr>
<tr>
<td><code>&lt;</code></td>
<td>从文件中读取输入</td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 god]# read aaa &lt;&lt;&lt;"HelloWord"</span><br><span class="line">[root@node01 god]# echo $aaa</span><br><span class="line">HelloWord</span><br><span class="line">[root@node01 god]# read aaa&lt;&lt;GG</span><br><span class="line"><span class="meta">&gt;</span> ljasf</span><br><span class="line"><span class="meta">&gt;</span> ajlsdfj;la</span><br><span class="line"><span class="meta">&gt;</span> ;ajdfkl</span><br><span class="line"><span class="meta">&gt;</span> GG  #跟 GG 一样，表示输入退出</span><br><span class="line">[root@node01 god]# echo $aaa</span><br><span class="line">ljasf</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> input.sh 脚本</span><br><span class="line">cat &lt;&lt;AABB</span><br><span class="line">print error info</span><br><span class="line">AABB</span><br><span class="line">echo "you know me .."</span><br><span class="line"><span class="meta">#</span> 执行</span><br><span class="line">source input.sh</span><br><span class="line"></span><br><span class="line">[root@node01 god]# cat 0&lt; /etc/in</span><br><span class="line">init/    init.d/  inittab  inputrc  </span><br><span class="line">[root@node01 god]# cat 0&lt; /etc/inittab </span><br><span class="line"><span class="meta">#</span> inittab is only used by upstart for the default runlevel.</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> ADDING OTHER CONFIGURATION HERE WILL HAVE NO EFFECT ON YOUR SYSTEM.</span><br></pre></td></tr></table></figure>

<h4 id="全重定向"><a href="#全重定向" class="headerlink" title="全重定向"></a>全重定向</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">exec 8&lt;&gt; /dev/tcp/www.baidu.com/80</span><br><span class="line">echo -e "GET / HTTP/1.0\n" &gt;&amp; 8</span><br><span class="line">cat &lt;&amp; 8</span><br></pre></td></tr></table></figure>

<h2 id="Shell-编程"><a href="#Shell-编程" class="headerlink" title="Shell 编程"></a>Shell 编程</h2><h3 id="bash"><a href="#bash" class="headerlink" title="bash"></a>bash</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">shell  bash</span><br><span class="line">解释器，启动器</span><br><span class="line">解释器：</span><br><span class="line">用户交互输入</span><br><span class="line">文本文件输入*</span><br><span class="line">脚本本质：</span><br><span class="line"><span class="meta">#</span>! /bin/bash</span><br><span class="line"><span class="meta">#</span>! /usr/bin/python</span><br><span class="line">读取方式：</span><br><span class="line">当前shell：source/.</span><br><span class="line">新建子shell：/bin/bash  file   /   ./file.sh  《chmod +x file.sh》</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>执行方式</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>source  xxx.sh</td>
<td>在当前 bash 中执行脚本</td>
</tr>
<tr>
<td>./xxx.sh</td>
<td>开启一个子 bash 执行脚本</td>
</tr>
</tbody></table>
<p>注意：在不同 bash 中执行的结果有可能不相同，即要理清父子 bash 之间的关系</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 sh]# echo $$</span><br><span class="line">1132</span><br><span class="line">[root@node01 sh]# source sh01.sh </span><br><span class="line">abc  boot  etc   lib    lost+found  mnt  proc  sbin     share  sys  usr</span><br><span class="line">bin  dev   home  lib64  media       opt  root  selinux  srv    tmp  var</span><br><span class="line">Hello World</span><br><span class="line">1132</span><br><span class="line">init─┬─auditd───&#123;auditd&#125;</span><br><span class="line">     ├─crond</span><br><span class="line">     ├─dbus-daemon───&#123;dbus-daemon&#125;</span><br><span class="line">     ├─master─┬─pickup</span><br><span class="line">     │        └─qmgr</span><br><span class="line">     ├─6*[mingetty]</span><br><span class="line">     ├─rsyslogd───3*[&#123;rsyslogd&#125;]</span><br><span class="line">     ├─sshd───sshd───bash───pstree</span><br><span class="line">     └─udevd───2*[udevd]</span><br><span class="line">[root@node01 sh]# ./sh01.sh </span><br><span class="line">abc  boot  etc	 lib	lost+found  mnt  proc  sbin	share  sys  usr</span><br><span class="line">bin  dev   home  lib64	media	    opt  root  selinux	srv    tmp  var</span><br><span class="line">Hello World</span><br><span class="line">1296</span><br><span class="line">init─┬─auditd───&#123;auditd&#125;</span><br><span class="line">     ├─crond</span><br><span class="line">     ├─dbus-daemon───&#123;dbus-daemon&#125;</span><br><span class="line">     ├─master─┬─pickup</span><br><span class="line">     │        └─qmgr</span><br><span class="line">     ├─6*[mingetty]</span><br><span class="line">     ├─rsyslogd───3*[&#123;rsyslogd&#125;]</span><br><span class="line">     ├─sshd───sshd───bash───bash───pstree</span><br><span class="line">     └─udevd───2*[udevd]</span><br></pre></td></tr></table></figure>

<h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><table>
<thead>
<tr>
<th>类型</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>本地变量</td>
<td>作用于当前 bash 中</td>
</tr>
<tr>
<td>局部变量</td>
<td>local，只作用于当前代码块</td>
</tr>
<tr>
<td>位置变量</td>
<td><code>$1</code>,<code>$2，</code>，从脚本文件后，读取参数</td>
</tr>
<tr>
<td>特殊变量</td>
<td><code>$#</code>: 位置参数个数<br><code>$*</code>: 参数列表，双引号引用为一个字符串<br><code>$@</code>: 参数列表，双引号引用为单独的字符串<br><code>$$</code>:当前 shell 的 PID：接收者<br><code>$BASHPID</code>:真实<br>管道 *<br>$?:上一个命令退出状态<br>    - 0 成功<br>    -other: 失败</td>
</tr>
<tr>
<td>环境变量</td>
<td>- export 定义变量<br>- 导出到子 shell<br>- fork()  Copy On Write  时间复杂度 O(1)<br>适用用于函数<br>unset: 取消变量<br>set: 查看shell 的变量</td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 sh]# num=1</span><br><span class="line">[root@node01 sh]# myfunc()&#123;</span><br><span class="line"><span class="meta">&gt;</span> echo $num</span><br><span class="line"><span class="meta">&gt;</span> echo HelloWorld</span><br><span class="line"><span class="meta">&gt;</span> &#125;</span><br><span class="line">[root@node01 sh]# myfunc</span><br><span class="line">1</span><br><span class="line">HelloWorld</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 本地变量 local</span><br><span class="line">[root@node01 sh]# myfunc()&#123;</span><br><span class="line"><span class="meta">&gt;</span> local fun=1</span><br><span class="line"><span class="meta">&gt;</span> echo $fun</span><br><span class="line"><span class="meta">&gt;</span> echo ok</span><br><span class="line"><span class="meta">&gt;</span> &#125;</span><br><span class="line">[root@node01 sh]# myfunc</span><br><span class="line">1</span><br><span class="line">ok</span><br><span class="line">[root@node01 sh]# echo $fun</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> -------------------------------</span><br><span class="line"><span class="meta">#</span> 位置参数</span><br><span class="line">[root@node01 sh]# cat sh02.sh</span><br><span class="line">echo $1</span><br><span class="line">echo $2</span><br><span class="line">[root@node01 sh]# vi sh02.sh</span><br><span class="line">[root@node01 sh]# source sh02.sh 1 2 </span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 特殊参数</span><br><span class="line">[root@node01 sh]# cat sh02.sh </span><br><span class="line">echo $1</span><br><span class="line">echo $2</span><br><span class="line">echo $&#123;11&#125;</span><br><span class="line">echo "---------"</span><br><span class="line">echo &#123;'position parameters:'&#125;$#</span><br><span class="line">echo $@</span><br><span class="line">[root@node01 sh]# source sh02.sh a b c d e f j h k m n o</span><br><span class="line">a</span><br><span class="line">b</span><br><span class="line">n</span><br><span class="line">---------</span><br><span class="line">&#123;position parameters:&#125;12</span><br><span class="line">a b c d e f j h k m n o</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>查看上一个命令的执行状态</span><br><span class="line">[root@node01 sh]# ls /</span><br><span class="line">abc  bin  boot  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  sbin  selinux  share  srv  sys  tmp  usr  var</span><br><span class="line">[root@node01 sh]# echo $?</span><br><span class="line">0</span><br><span class="line">[root@node01 sh]# ls /asf</span><br><span class="line">ls: cannot access /asf: No such file or directory</span><br><span class="line">[root@node01 sh]# echo $?</span><br><span class="line">2</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 数组使用</span><br><span class="line">[root@node01 sh]# arr=(1 2 3)</span><br><span class="line">[root@node01 sh]# echo $arr[1]</span><br><span class="line">1[1]</span><br><span class="line">[root@node01 sh]# echo $&#123;arr[1]&#125;</span><br><span class="line">2</span><br><span class="line">[root@node01 sh]# echo $&#123;arr[0]&#125;</span><br><span class="line">1</span><br><span class="line">[root@node01 sh]# echo $&#123;arr[2]&#125;</span><br><span class="line">3</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 变量与其他字符串的拼接，需要使用花括号 &#123;&#125;，标识为变量</span><br><span class="line">[root@node01 sh]# num=1</span><br><span class="line">[root@node01 sh]# echo $num1231</span><br><span class="line"></span><br><span class="line">[root@node01 sh]# echo $&#123;num&#125;111</span><br><span class="line">1111</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 管道--管道两边分为在两个子 bash 中，  子 bash 可以使用父 bash 中的引用</span><br><span class="line">[root@node01 sh]# dd=1</span><br><span class="line">[root@node01 sh]# dd=10 | echo $dd</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> export 导入不共享</span><br><span class="line">[root@node01 sh]# cat sh04.sh </span><br><span class="line">echo $k</span><br><span class="line">echo "-------------"</span><br><span class="line">sleep 10</span><br><span class="line">echo $k</span><br><span class="line">[root@node01 sh]# export k=5</span><br><span class="line">[root@node01 sh]# ./sh04.sh &amp;  # $ 表示在后台运行</span><br><span class="line">[1] 1729</span><br><span class="line">[root@node01 sh]# 5</span><br><span class="line">-------------</span><br><span class="line">^C</span><br><span class="line">[root@node01 sh]# k=8</span><br><span class="line">[root@node01 sh]# 5</span><br><span class="line">^C</span><br><span class="line">[1]+  Done                    ./sh04.sh</span><br></pre></td></tr></table></figure>

<p>注意： </p>
<ol>
<li>数组元素之间通过空格分隔，使用逗号分号，bash 会把数组整体当做字符串使用</li>
<li>export 导出非共享<h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><blockquote>
<p>双引号：弱引用，参数扩展<br>单引号：强引用，不可嵌套<br>花括号扩展不能被引用<br>命令执行前删除引用</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 sh]# kk=12</span><br><span class="line">[root@node01 sh]# echo "$kk"</span><br><span class="line">12</span><br><span class="line">[root@node01 sh]# echo '$kk'</span><br><span class="line"><span class="meta">$</span>kk</span><br><span class="line"><span class="meta">#</span> 花括号扩展不能被引用</span><br><span class="line">[root@node01 b]# cp  "/etc/&#123;passwd,inittab&#125;" ./</span><br><span class="line">cp: cannot stat `/etc/&#123;passwd,inittab&#125;': No such file or directory</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="命令替换"><a href="#命令替换" class="headerlink" title="命令替换"></a>命令替换</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">反引号：`ls -l /`</span><br><span class="line"><span class="meta">$</span>(ls -l /)</span><br><span class="line">可以嵌套</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 sh]# echo "`echo 123`"</span><br><span class="line">123</span><br><span class="line"></span><br><span class="line">[root@node01 sh]# abc=$(echo $(echo "sxt"))</span><br><span class="line">[root@node01 sh]# echo $abc</span><br><span class="line">sxt</span><br><span class="line"></span><br><span class="line">[root@node01 sh]# abc=$(ls -l /)</span><br><span class="line">[root@node01 sh]# echo $abc</span><br><span class="line">total 98 drwxrw-r-x. 3 root root 4096 Sep 22 13:53 abc dr-xr-xr-x. 2 root root 4096 Sep 22 21:34 bin dr-xr-xr-x. 5 root root 1024 Sep 21 19:29 boot drwxr-xr-x. 18 root root 3680 Sep 22 21:45 dev drwxr-xr-x. 76 root root 4096 Sep 22 21:45 etc drwxr-xr-x. 4 root root 4096 Sep 22 13:04 home dr-xr-xr-x. 8 root root 4096 Sep 22 14:16 lib dr-xr-xr-x. 10 root root 12288 Sep 22 21:34 lib64 drwx------. 2 root root 16384 Sep 21 19:28 lost+found drwxr-xr-x. 2 root root 4096 Sep 23 2011 media drwxr-xr-x. 2 root root 4096 Sep 23 2011 mnt drwxr-xr-x. 2 root root 4096 Sep 23 2011 opt dr-xr-xr-x. 87 root root 0 Sep 22 21:45 proc dr-xr-x---. 5 root root 4096 Sep 23 03:26 root dr-xr-xr-x. 2 root root 12288 Sep 22 17:58 sbin drwxr-xr-x. 7 root root 0 Sep 22 21:45 selinux drwxrwx---. 2 root share 4096 Sep 22 13:51 share drwxr-xr-x. 2 root root 4096 Sep 23 2011 srv drwxr-xr-x. 13 root root 0 Sep 22 21:45 sys drwxrwxrwt. 3 root root 4096 Sep 23 02:02 tmp drwxr-xr-x. 14 root root 4096 Sep 22 17:50 usr drwxr-xr-x. 17 root root 4096 Sep 21 19:28 var</span><br></pre></td></tr></table></figure>

<h3 id="逻辑判断"><a href="#逻辑判断" class="headerlink" title="逻辑判断*"></a>逻辑判断*</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">退出状态</span><br><span class="line">echo $?</span><br><span class="line">逻辑判断</span><br><span class="line">command1 &amp;&amp; command2</span><br><span class="line">command1 || command2</span><br></pre></td></tr></table></figure>

<h3 id="表达式"><a href="#表达式" class="headerlink" title="表达式"></a>表达式</h3><h4 id="算术表达式"><a href="#算术表达式" class="headerlink" title="算术表达式"></a>算术表达式</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">let  算术运算表达式</span><br><span class="line">let  C=$A+$B</span><br><span class="line"><span class="meta">$</span>[算术表达式]</span><br><span class="line">C =$[$A+$B]</span><br><span class="line"><span class="meta">$</span>((算术表达式))</span><br><span class="line">C=$(($A+$B))</span><br><span class="line">expr  算术表达式  </span><br><span class="line">注意：表达式中各操作数及运算符之间要有空格。而且要使用命令引用</span><br><span class="line">C=`expr $A + $B`</span><br><span class="line">help let</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 sh]# a=1</span><br><span class="line">[root@node01 sh]# b=2</span><br><span class="line">[root@node01 sh]# let c=$a+$b</span><br><span class="line">[root@node01 sh]# echo $c</span><br><span class="line">3</span><br><span class="line">[root@node01 sh]# c=3</span><br><span class="line">[root@node01 sh]# d=4</span><br><span class="line">[root@node01 sh]# e=$(($c+$d))</span><br><span class="line">[root@node01 sh]# echo $e</span><br><span class="line">7</span><br><span class="line">[root@node01 sh]# j=1</span><br><span class="line">[root@node01 sh]# k=2</span><br><span class="line">[root@node01 sh]# c=$((j+k))</span><br><span class="line">[root@node01 sh]# echo $c</span><br><span class="line">3</span><br><span class="line"></span><br><span class="line">[root@node01 sh]# echo $a</span><br><span class="line">2</span><br><span class="line">[root@node01 sh]# ((a++))</span><br><span class="line">[root@node01 sh]# echo $a</span><br><span class="line">3</span><br></pre></td></tr></table></figure>

<h4 id="条件表达式"><a href="#条件表达式" class="headerlink" title="条件表达式"></a>条件表达式</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[  expression  ]</span><br><span class="line">test expression</span><br><span class="line">[[ expression ]]</span><br><span class="line">help test</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 sh]# test -a /etc/adf</span><br><span class="line">[root@node01 sh]# echo $?</span><br><span class="line">1</span><br><span class="line">[root@node01 sh]# test -a /etc/password</span><br><span class="line">[root@node01 sh]# echo $?</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line">[root@node01 sh]# [ $a -gt $b ]</span><br><span class="line">[root@node01 sh]# echo $?</span><br><span class="line">0</span><br><span class="line"></span><br><span class="line">[root@node01 sh]# [3 -gt 2]</span><br><span class="line">-bash: [3: command not found</span><br><span class="line">[root@node01 sh]# [ 3 -gt 2 ]</span><br><span class="line">[root@node01 sh]# echo $?</span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<p><em>注意： 靠近 [] ，需要有空格间隔</em></p>
<h4 id="添加用户脚本"><a href="#添加用户脚本" class="headerlink" title="添加用户脚本"></a>添加用户脚本</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>添加用户</span><br><span class="line"><span class="meta">#</span>用户密码同用户名</span><br><span class="line"><span class="meta">#</span>静默运行脚本</span><br><span class="line"><span class="meta">#</span>避免捕获用户接口</span><br><span class="line"><span class="meta">#</span>程序自定义输出</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>! /bin/bash</span><br><span class="line">[ ! $# -eq 1 ] &amp;&amp; echo "args error ! " &amp;&amp; exit 3</span><br><span class="line">id $1 &gt;&amp;/dev/null &amp;&amp; echo "user exits" &amp;&amp; exit 4</span><br><span class="line">useradd $1 &gt;&amp; /dev/null &amp;&amp; echo $1 | passwd --stdin $1 &gt;&amp; /dev/null &amp;&amp; echo "useradd user success!" &amp;&amp; exit 0</span><br><span class="line">echo "don't know, user add error!"</span><br></pre></td></tr></table></figure>

<h3 id="流程控制"><a href="#流程控制" class="headerlink" title="流程控制"></a>流程控制</h3><h4 id="if"><a href="#if" class="headerlink" title="if"></a>if</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[test06@node01 sh]$ if [ 3 -gt 1 ]; then echo ok; fi</span><br><span class="line">ok</span><br><span class="line">[test06@node01 sh]$ a=1</span><br><span class="line">[test06@node01 sh]$ b=2</span><br><span class="line">[test06@node01 sh]$ if [ $b -lt $a ];then echo ok;elif [ $b -gt $a ];then echo ojbk;fi</span><br><span class="line">ojbk</span><br><span class="line">[test06@node01 sh]$ if [ $b -lt $a ];then echo lt;else echo gt;fi</span><br><span class="line">gt</span><br></pre></td></tr></table></figure>

<h4 id="while"><a href="#while" class="headerlink" title="while"></a>while</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[test06@node01 sh]$ while ls /;do echo ok;break;done</span><br><span class="line">abc  boot  etc   lib    lost+found  mnt  proc  sbin     share  sys  usr</span><br><span class="line">bin  dev   home  lib64  media       opt  root  selinux  srv    tmp  var</span><br><span class="line">ok</span><br><span class="line">[test06@node01 sh]$ a=1</span><br><span class="line">[test06@node01 sh]$ while [ $a -le 5 ];do echo $a;((a++));done</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td></tr></table></figure>

<h4 id="for"><a href="#for" class="headerlink" title="for"></a>for</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[test06@node01 sh]$ for ((ab=1;ab&lt;5;ab++));do echo ab=$ab;done</span><br><span class="line">ab=1</span><br><span class="line">ab=2</span><br><span class="line">ab=3</span><br><span class="line">ab=4</span><br><span class="line">[test06@node01 sh]$ for i in 1 2 3 4 5;do echo $i;done</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 用户给定路径</span><br><span class="line"><span class="meta">#</span> 输出文件大小最大的文件</span><br><span class="line"><span class="meta">#</span> 递归子目录</span><br><span class="line"><span class="meta">#</span>! /bin/bash</span><br><span class="line">oldIFS=$IFS</span><br><span class="line">IFS=$'\n'</span><br><span class="line">for i in `du -a $1 | sort -nr`;do</span><br><span class="line">        filename=`echo $i | awk '&#123;print $2&#125;'`</span><br><span class="line">        if [ -f $filename ];then</span><br><span class="line">                echo $filename</span><br><span class="line">                break;</span><br><span class="line">        fi</span><br><span class="line">done</span><br><span class="line">IFS=$oldIFS</span><br></pre></td></tr></table></figure>

<p>注意: 变量的赋值等于号前面两边不能有空格，bash 对空格敏感</p>
<h4 id="循环遍历文件输出"><a href="#循环遍历文件输出" class="headerlink" title="循环遍历文件输出"></a>循环遍历文件输出</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>! /bin/bash</span><br><span class="line">oldIFS=$IFS</span><br><span class="line">IFS=$'\n'</span><br><span class="line">num=0</span><br><span class="line">for i in `cat file.txt`;do</span><br><span class="line">        echo $i</span><br><span class="line">        ((num++));</span><br><span class="line">done</span><br><span class="line"><span class="meta">#</span>! /bin/bash</span><br><span class="line">oldIFS=$IFS</span><br><span class="line">IFS=$'\n'</span><br><span class="line">num=0</span><br><span class="line">for i in `cat file.txt`;do</span><br><span class="line">        echo $i</span><br><span class="line">        ((num++));</span><br><span class="line">done</span><br><span class="line">echo "num:$num"</span><br><span class="line">IFS=$oldIFS</span><br><span class="line">echo "---------------"</span><br><span class="line">lines=`cat file.txt | wc -l`</span><br><span class="line">for ((i=1;i&lt;=lines;i++));do</span><br><span class="line">        echo `head -$i file.txt | tail -1`</span><br><span class="line">        ((line++))</span><br><span class="line">done</span><br><span class="line">echo "line:$line"</span><br><span class="line">echo "---------------"</span><br><span class="line">num=0</span><br><span class="line">while  read line ;do</span><br><span class="line">        echo $line</span><br><span class="line">        ((num++ ))</span><br><span class="line">done &lt; file.txt</span><br><span class="line">echo "num:$num"</span><br><span class="line">echo "-----------------"</span><br><span class="line">num=0</span><br><span class="line">cat file.txt | while  read line;do</span><br><span class="line">        echo $line</span><br><span class="line">        ((num++))</span><br><span class="line">done</span><br><span class="line">echo "num:$num"</span><br></pre></td></tr></table></figure>


        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://zwer.xyz/2019/09/02/20190902大数据入门/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zwer">
      <meta itemprop="description" content="记录学习的日常">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zwer 的博客空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/09/02/20190902大数据入门/" class="post-title-link" itemprop="url">大数据入门</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-09-02 00:00:00" itemprop="dateCreated datePublished" datetime="2019-09-02T00:00:00+08:00">2019-09-02</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-09 21:30:15" itemprop="dateModified" datetime="2019-10-09T21:30:15+08:00">2019-10-09</time>
              </span>
            
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="人工智能真来了吗？"><a href="#人工智能真来了吗？" class="headerlink" title="人工智能真来了吗？"></a>人工智能真来了吗？</h2><blockquote>
<p>来了，真滴来了。</p>
</blockquote>
<p>Example：</p>
<ul>
<li>谷歌、百度的无人汽车</li>
<li>高铁站出入检票站</li>
<li>杭州主要干道由阿里巴巴的人工智能（ET）管理</li>
</ul>
<h3 id="人工智能三要素"><a href="#人工智能三要素" class="headerlink" title="人工智能三要素"></a>人工智能三要素</h3><ul>
<li>硬件（计算机硬件的计算速度提升和计算成本下降）</li>
<li>算法（机械学习算法、深度学习算法）</li>
<li>数据（特指大数据）</li>
</ul>
<h3 id="人工智能的发展阶段"><a href="#人工智能的发展阶段" class="headerlink" title="人工智能的发展阶段"></a>人工智能的发展阶段</h3><p><img src="http://img.zwer.xyz/blog/20190902192559.png" alt></p>
<h3 id="人工智能的概念"><a href="#人工智能的概念" class="headerlink" title="人工智能的概念"></a>人工智能的概念</h3><p>李开复：大数据+深度学习=人工智能</p>
<h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2>
        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
  </div>

  


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">zwer</p>
  <div class="site-description" itemprop="description">记录学习的日常</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
  </nav>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zwer</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.4.0</div>

        












        
      </div>
    </footer>
  </div>

  


  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.0"></script><script src="/js/motion.js?v=7.4.0"></script>
<script src="/js/schemes/muse.js?v=7.4.0"></script>
<script src="/js/next-boot.js?v=7.4.0"></script>



  





















  

  

  

</body>
</html>
